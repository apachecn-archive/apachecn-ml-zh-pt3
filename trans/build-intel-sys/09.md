# 9.从经验中获取数据

智能创造者可以处理各种数据，甚至是劣质数据。但是当他们有好的数据时，他们的工作就容易多了——他们创造的情报的潜力也大得多。理想的智能体验将控制用户和智能系统之间的交互，以便这些交互的记录使得创建高质量的智能变得容易。

在探索如何通过智能体验从用户那里获取数据之前，让我们考虑另一种选择:你可以自己收集数据。传统上，机器学习系统有一个数据收集阶段。也就是说，如果你想建立一个计算照片中奶牛数量的智能，你就要出去拍很多奶牛的照片。你会从一个农场到另一个农场，拍摄不同情况下的奶牛。你可以给奶牛摆姿势，这样你就能拍到它们好的一面和坏的一面；他们的脸和他们的…其他部位。你会拍灌木丛后面的奶牛。你可以在晴天、阴天、晚上拍摄奶牛躺下、奔跑、吃草、睡觉、打哈欠的照片……一个传统的计算机视觉系统可能需要数万张不同的奶牛照片。如果有更多的照片，情况会变得更好——成百上千或上百万的照片可能会有所帮助。一旦你有了所有的数据，你就需要给它贴上标签。也就是说，你会付钱给很多人来看所有这些奶牛图片，并在所有的奶牛周围画圈圈——很有趣！

这可能会非常昂贵。数据收集和标记可能是传统机器学习系统的主要成本。正因为如此，设计利用用户及其与智能系统的交互来产生具有正确属性的数据以创造智能的体验具有很大的价值。正确地做到这一点，可以在许多情况下使用智能和机器学习，而使用手动数据收集会非常昂贵。

本章首先举例说明从经验中收集数据意味着什么，以及各种方法如何影响所得数据的质量。然后，我们将探索使数据有利于智能创造的属性，以及一些用于捕获用户对数据的结果(或意见)的选项。

## 一个例子:TeamMaker

让我们考虑一个例子:一个为篮球联盟创建团队而设计的智能系统——我们称之为 TeamMaker。每个球员都被输入到这个系统中，还有一些基本的统计数据:身高，经验，位置，也许还有一些关于他们投篮的数据。然后系统会将玩家分成不同的团队。如果球队实力相当，联赛将会很有趣。如果球队不平衡，联赛可能会很无聊。一个团队总是会赢，而其他人会觉得自己是失败者。争斗将会开始，街道上的暴乱，歇斯底里…

所以我们最好把这件事办好。

我们需要建立一种体验，收集关于系统创建的团队的有用反馈，以便智能可以随着时间的推移而改进(并建议更好的团队)。

### 简单的互动

一种方法是让用户更正团队，并使用更正来提高智能。

例如，TeamMaker 可能会产生“建议的团队”作为起点。这些提议可以提交给一个人——联盟专员——来纠正任何问题。也许情报部门搞错了，把所有最好的球员放在一个队里。然后专员可以干预并调动一些球员。每当专员移动一名球员，TeamMaker 就会获得训练数据，以使情报更好。几个赛季后，情报可能会很好，专员不需要再做任何改变。

但是，说实话，这种篮球队创建系统听起来很蹩脚。谁愿意用一个工具做团队，然后无论如何都要手工做？如果专员不向团队提供任何更正，这种方法可能会失败，因为:

*   听起来很无聊。
*   他们没有信心打败机器。
*   他们实际上不懂怎么打篮球，所以他们做出让事情变得更糟的纠正。
*   他们在离线状态下进行修改，根本不需要在 TeamMaker 中输入。

缓慢或不规则的互动会限制智力发展的速度，并限制其最终潜力。一个好的体验将建立交互，为用户提供显而易见的价值，并且用户可以做得很好。

### 变得有趣

另一种方法是让使用和智能之间的联系变得更有趣。用户真正想做的事情，并且被激励去做正确的事情。

例如，TeamMaker 可以组成团队，但它也可以支持赌博。大多数下注的人都想赢(因为大多数人在乎钱)，所以他们会试着赌最好的球队——而不会赌明显的输家。因此 TeamMaker 可以使用赌注的分布来计算它是否在组建团队方面做得很好。如果赌注严重偏向(或远离)其中一个团队，TeamMaker 可以了解到它使用了错误的因素来平衡团队。下次会做得更好。

这种基于投注的互动是对基于团队调整的互动系统的改进，应该会导致每个赛季更多的数据和更多提高智能的机会，并且应该会更快地产生更好的智能系统。

但是基于赌博互动的数据并不完美。例如，有些人可能只为自己的球队下注，即使很明显他们赢不了。或者也许更好的人对篮球一无所知，并打赌要挑起一些善意的办公室竞争。(或者打赌是非法的或违背你的道德的，所以作为一个开发者，你根本不想使用基于打赌的与 TeamMaker 的交互…)这些类型的问题会导致偏见，而偏见会导致智慧误入歧途。当智能从有偏见的博彩数据中学习时，产生的球队将不会为创建一个有竞争力的联盟而优化，他们将为…其他东西而优化。

当用户有一个不同于智能系统的目标时，来自他们交互的数据可能是误导的。一个好的体验将会把使用和智力结合起来，以获得对成功的无偏见的观察。

### 连接到结果

另一种方法是将智力与结果直接联系起来。不需要人的判断，只需要事实。当一个团队赢得每一场比赛时，情报部门知道它做错了什么。当所有的游戏都结束时，智能可以学习它做了正确的事情。

要使这种方法奏效，必须有人主动将所有分数输入 TeamMaker。因此，也许 TeamMaker 围绕这一点创造了一些有趣的功能，如与赌博、排行榜或日程安排相结合。每次游戏结束，人们可能会聚集在他们的电脑前，只是为了看看排名如何变化，谁赢了钱，谁失去了自尊。

随着游戏的进行，用户输入关于哪些球队赢了，哪些比赛很接近，以及哪些比赛被淘汰的统计数据，TeamMaker 拥有提高智能所需的一切。如果有一个从来没有输过的团队，它可以了解这个团队的特别之处，并避免在未来这样做。下个赛季 TeamMaker 会做得更好，创造更可能平衡的比赛，而不太可能有不可阻挡的(或无望的)团队。

当经验可以直接追踪期望的结果时，它可以产生最有用的情报。

## 好数据的属性

为了解决困难的、大规模的、开放式的、随时间变化的问题，你将需要数据——大量的数据。但不是任何数据都可以。为了建立智能，你需要有特定属性的数据。最佳数据将:

*   包含互动的背景、采取的任何行动以及结果。
*   充分了解您的用户想用智能系统做什么。
*   反映与系统的真实互动(而不是对人们如何互动的猜测或调查)。
*   很少(或没有)偏见。
*   避免反馈，因为情报会影响数据，而数据又会影响情报，进而影响数据…
*   足够大，与问题相关。(为难题创造智能可能需要难以置信的大量数据。)

实现所有这些属性并不容易。事实上，除非您在设计中明确解决了这些属性中的每一个，否则您不太可能获得有效创建智能所需的数据。

### 背景、行动和结果

从数据中创造智能的基本要求是了解:

1.  当智能被调用时发生了什么的上下文。
2.  因此而采取的任何行动。
3.  互动的结果，特别是结果是积极的还是消极的。

例如:

*   自动驾驶汽车需要知道车上所有传感器看到了什么(上下文)，人类司机在那种情况下可能会做的事情(动作)，以及汽车最终是否会撞车或被按喇叭(结果)。
*   书籍推荐系统需要知道用户已经阅读了哪些书籍，他们喜欢这些书籍的程度(上下文)，可能会向用户推荐哪些书籍，用户是否购买了其中的任何一本书(操作)，以及用户最终喜欢哪本书(结果)。
*   反恶意软件系统需要知道用户下载了什么文件，他们从哪里得到的(上下文)，他们是否安装了它(操作)，以及他们的机器最终是否被感染(结果)。

一个理想的智能体验将为用户和智能创造足够的环境来做出好的决策。例如:如果自动汽车除了速度计之外没有任何传感器，那么知道用户对方向盘做了什么就没有帮助——没有智能可以仅根据速度来学习如何转向。

### 良好的覆盖面

数据应包含对情报部门需要运作的所有情况的观察。例如:

*   如果系统需要自动化灯光，数据应包含控制灯光的环境、动作和结果:
    *   白天。
    *   晚上。
    *   在冬天。
    *   夏天的时候。
    *   在夏令时。
    *   大量使用的灯。
    *   很少使用的灯。
    *   诸如此类。
*   如果灯需要在世界上 50 个不同的国家工作，数据应该包含在所有这些情况下来自这 50 个国家的观察结果。
*   如果系统需要在矿井中工作，数据应该包含矿井中使用的灯的观察结果。
*   如果系统需要在空间站上工作，数据应该包含对空间站中使用的灯的观察。

一个没有接受过训练(或评估)的情报人员很可能会犯错误，而且是疯狂的错误。

智能系统在其生命周期中将被期望在新的环境中工作。总会有新书、电影、歌曲、网页、文档、程序、帖子、用户等等。有效的智能体验将能够使用户充满信心地进入这些新的环境，在收集数据时所犯的错误将具有低成本，并且所收集的数据的价值将是高的。

### 真实用法

最好的数据将来自用户做他们真正关心的事情。例如:

*   驾驶汽车模拟器的用户可能会做出他们在驾驶真实汽车时不会做出的决定(当他们命悬一线时)。
*   告诉你他们喜欢什么书的用户可能会谈论文学经典(因为他们试图给你留下深刻印象)，但他们可能永远不会真正阅读这些书。
*   当被问及将文件安装在实验室计算机或他们母亲的计算机上是否安全时，用户可能会给出非常不同的答案。

将真实用户与他们关心的交互联系起来，可以确保产生的数据是真实的，并且从这些数据中构建的智能最有可能给其他用户带来他们真正想要的东西。

### 公正的

当体验影响了用户的交互类型，或者影响了用户给出的反馈类型时，就会产生偏见。

偏见的一个常见来源是不同类型的结果以不同的比率报道。

考虑一个垃圾邮件过滤程序。如果垃圾邮件到达用户的收件箱，它就在他们面前。他们可能会注意到这一点，并可能按下“这是垃圾”按钮，并生成关于坏结果的有用数据。另一方面，如果过滤器删除了个人邮件，用户可能永远不会注意到。

在这种情况下，在设计体验时所做的选择引入了偏见，并使结果数据对构建智能的用处大大降低。

偏见的另一个潜在来源是，对交互有强烈情感(好的或坏的)的用户比有中立观点的用户更有可能给出反馈。

偏见的另一个来源是当体验鼓励用户做出某些选择。例如，当体验在列表中呈现选择时，用户更有可能选择列表中的第一个项目(而不太可能选择根本不在列表中的项目)。

### 不包含反馈回路

经验和智慧会相互影响，有时是负面的影响。

例如，如果用户体验的某个部分变得更加突出，用户就会与它进行更多的交互。如果智能从这些交互中学习，它可能会认为用户更喜欢这个动作(当他们不喜欢它时，他们只是因为用户体验的改变而更容易注意到它)。

相反，如果智能出错并开始抑制用户喜欢的动作，用户将看不到该选项。他们会停止选择动作(因为他们不能)。该动作将从数据中消失。智能会认为用户不再喜欢这个选项。但这将是错误的…

以下是一些处理反馈的方法:

*   包括用户在记录数据的上下文中看到了什么。如果一个选项以比另一个更大的字体出现，记录它的上下文。如果某些选项被取消，请在上下文中记录下来。
*   在用户看到的内容中加入一点随机性，例如切换某些选项的顺序。这有助于在更广泛的情况下收集数据，并且有助于识别反馈可能正在发生。
*   记录用户在上下文中选择选项所付出的努力。例如，如果用户必须手动发出命令(因为它在智能体验中被抑制)，智能应该知道它犯了一个代价高昂的错误。如果用户不得不浏览许多页面的内容来找到他们想要的选项，智能应该知道。

### 规模

为了改进，必须使用智能系统。这意味着智能体验必须突出，使用起来必须有趣，必须容易找到，必须是用户经常做的事情。

考虑两个选择:一个新的智能系统和一个已建立的智能系统。

新的智能系统可能不会有很多用户。这意味着智能体验必须是用户将要做的事情的核心，所以他们会定期与它进行交互。在这些情况下，智能体验将需要鼓励交互，使之有趣，甚至可能改变整个产品，将智能交互放在前面和中心。

建立起来的智能系统将会有更多的用途。这意味着智能体验可能更加微妙。它们可以放在较少用户看到的地方。这并不意味着它们没有价值——它们可能正在解决非常重要的问题，但是用户每周或每月都会遇到这些问题，而不是每天都会遇到。

对于某些上下文，系统:

*   每天产生数十次交互，基本上对验证或提高智力没用。
*   每天生成数百个交互可能会验证智能并产生一些简单的智能。
*   每天生成数千或数万次交互，当然可以验证智能系统，并为许多困难的开放式问题提供智能。
*   每天生成数十万或数百万次交互，可能拥有大多数任务所需的所有数据。

有效的智能体验将吸引用户，让他们参与进来，为收集数据和产生有趣的情报奠定基础。

## 理解结果的方法

当用户和智能之间发生交互时，并不总是很容易理解结果是积极的还是消极的。例如，在一个音乐推荐系统中——用户按下“下一首”按钮是因为他们讨厌这首歌(智能弄错了)还是因为他们看到下一首歌出现了，他们真的很喜欢这首歌(智能弄错了)？

最好的智能体验是为了让结果显而易见——也就是说，除了使用产品之外，不需要用户做任何事情。但这并不总是可能的。即使在可能的情况下，拥有一个支持来确保隐式数据具有创建智能的所有正确属性也是有用的。理解结果的方法包括:

*   隐性观察
*   用户评级
*   问题报告
*   增加
*   用户分类

许多大型智能系统使用所有这些方法来尽可能多地了解用户的结果。

### 隐性结果

理想的体验将产生良好、有用的数据，而不需要任何特殊的用户操作。用户只需使用系统就能产生数据，而这些数据将具备发展智能所需的所有特性。

例如，当用户将恒温器设置为 72 度时，他们希望智能做什么就很清楚了。或者当用户购买产品或某些内容时，很明显他们对此感兴趣。

通常很难确切地知道如何解释用户的行为。用户可能不会花时间来做出完美的决策，因此数据呈现给他们的方式可能会影响他们的结果。例如，他们可能会选择五部推荐电影中的一部，因为这是当时对他们来说绝对最好的电影，或者因为他们不想再看更多的选择。

正因为如此，实现完全隐式的数据收集系统是非常困难的，需要仔细的协调和减少体验，以便可以有效地解释使用。

### 等级

用户评级和评论是非常好的数据来源。例如，设计允许用户:

*   用 1-5 颗星评价他们消费的内容。
*   对特定的互动给予肯定或否定的评价。
*   留下一些简短的文字描述他们的经历。

用户习惯于留下评级，许多用户喜欢这样做，感觉他们在帮助别人或个性化他们的体验。

但是评级也面临一些挑战:

1.  用户并不总是对所有东西都进行评级。他们可能不愿意付出努力。
2.  互动和评级之间可能会有一段时间。用户可能不记得到底发生了什么，或者他们可能不把他们的结果归因于交互。
3.  评级可能无法捕捉到智能优化的内容。比如考虑这两个问题:这本书有多好？那是昨天向你推荐的那本书吗？
4.  不同用户群的评分各不相同——一个国家的五星与其他国家的五星并不相同。
5.  不频繁的互动不会得到很多评价，也很难了解。

### 报告

体验可以让用户报告出了问题。例如，许多电子邮件系统有一个“报告为垃圾邮件”按钮，用于接收到达收件箱的垃圾邮件。

通过报告收集的数据明显有偏差，因为它捕捉的唯一结果是坏的(当情报出错时)，用户不会报告每个问题。例如，用户可能会点击他们看到的 10%的垃圾邮件的“报告为垃圾邮件”，而忽略或删除其余的垃圾邮件。

因此，来自报告的数据很难用作创建情报的唯一来源。然而，报告可以非常有效地验证智力，并调整体验以控制智力低下的负面影响。

### 增加

升级是一种代价高昂的报告形式，当用户非常不高兴而联系客户支持(或访问支持论坛等)时，就会发生这种情况。升级类似于报告，但不在主要产品体验范围内。并且它们通常代表非常不开心的用户和重要的错误。

升级往往是混乱和不集中的。遇到问题的用户并不总是知道系统的哪个部分导致了问题。他们不会用与其他报告问题的用户相同的术语来表达问题。

因此，对升级进行分类并使用它们来提高智能可能会很困难，而且成本很高——它们更适合于识别大问题，而不是完善系统。

一般来说，最好是允许用户在环境中报告问题(在问题发生时，通过在线报告体验)，这样系统就可以捕获导致不良结果的相关环境和操作。

### 用户分类

你可以在用户与你的系统交互的背景下，使用特定的(小心控制的)问题简单地询问用户他们的结果。有点像调查。想象一下:

*   使用灯光自动化系统，每三个月它会说一次:为了改进我们的产品，我们想知道——现在你喜欢灯开着还是关着？
*   使用一个照片编辑程序，在润色了一百张照片后，它说:请帮助改进这个程序。您正在处理的图像中有人脸吗？

分类可以产生非常集中的数据来提高智力。也可以不引人注目，例如通过限定问题:

*   每一千次互动中的一个问题。
*   给那些自愿帮忙的用户。
*   给那些没有注册高级服务的用户。
*   诸如此类。

## 摘要

智能体验在获取增长智能的数据方面起着至关重要的作用。如果智能体验没有明确地被设计为产生用于创造智能的好数据，那么它几乎肯定会产生用于创造智能的差(或无用)数据。

当用户经常与智能交互时，当他们在交互中感受到价值时，当他们拥有正确的信息来做出好的决策时，体验会产生更好的数据。

数据在以下情况下最有用:

*   包含互动的背景、采取的行动和结果。
*   涵盖了智能系统的所有应用场合。
*   代表真实的使用情况，也就是用户关心的交互。
*   包含公正的数据。
*   包含足够的信息来识别和打破反馈循环。
*   根据问题的复杂性生成有意义的数据量。

最有效的数据来自隐性交互，用户通过使用产品自然地表达他们的意图和对结果的看法。

当隐性互动不够充分时，了解结果的其他方法包括:

*   允许用户明确地对他们拥有的内容或交互进行评级。
*   允许用户直接从用户体验中报告问题。
*   为用户提供支持途径，以报告大规模、高成本的问题。
*   要求用户回答特别缩减的问题(不经常)。

许多智能系统使用所有这些方法。他们的大部分数据可能来自隐式交互，但其他技术将可用于监控和确保隐式数据是高质量的(没有开始产生偏差或反馈)。

在不给用户增加负担的情况下，创造一种产生优秀数据的体验是很难的，而这对于构建优秀的智能系统是非常重要的。

## 供思考…

阅读完本章后，您应该:

*   知道如何创造经验，收集评估和发展智力所需的数据。
*   了解从用户那里收集这些数据的选项，从不需要明确用户操作的选项到需要大量用户参与的选项。

你应该能够回答这样的问题:

*   想象一个你经常使用的智能服务，它似乎在暗中收集所有的数据。如何改变它以利用用户分类？
*   想象一个智能系统来帮助你最喜欢的爱好。当它做错事时，想一个隐式的方法来收集“好数据”。现在，想一想在相同情况下收集数据的另一种方法，这种方法表达了用户对错误的不同解释(例如，可能情报是正确的，但用户出于其他原因不想执行建议的操作)。