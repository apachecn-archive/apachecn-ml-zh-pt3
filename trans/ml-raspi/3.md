# 3.ML 数据模型探索:第 2 部分

本章是上一章开始的关于基本 ML 数据模型的讨论和演示的延续。在前一章的开始，我提出了十个数据模型，它们是

*   线性回归

*   逻辑回归

*   k 近邻分类器

*   高斯天真[贝叶斯](http://scholar.google.com/scholar%253Fq%253DGaussian%252BNaive%252BBayesian%2526hl%253Den%2526as_sdt%253D0%2526as_vis%253D1%2526oi%253Dscholart)

*   决策树分类器

*   主成分分析

*   线性判别分析

*   支持向量机

*   学习矢量量化

*   装袋和随机森林

前五个在前一章中已经介绍过了，而剩下的五个将在本章中介绍。请不要因为讨论顺序而推断模型的相对重要性。在每种情况下，我都会具体讨论何时以及如何使用每种模型。

## 主成分分析

主成分分析(PCA)是一种强大的算法，用于线性变换和降维。它通常用于许多领域，包括计算机视觉应用和金融交易。

使用 PCA 算法的主要目的是通过将一个大的变量集转换成一个较小的变量集来降低数据维数，该较小的变量集仍然包含大数据集中存在的大部分信息。归结为几个词，主成分分析创造了小数据集，更容易处理和促进数据分析，并与其他 ML 算法更兼容。总之，主成分分析的中心思想是减少数据集中的变量数量，同时保留尽可能多的信息。PCA 还执行数据压缩功能，我在代码说明部分对此进行了描述。

PCA 算法倾向于使用较少的存储器，因为它在计算上是高效的。此外，PCA 具有良好的可视化功能，有助于用户理解最终结果。

尝试执行 PCA 时，应遵循六个步骤:

1.  将数据标准化。

2.  使用标准化数据创建协方差矩阵。

3.  使用生成的矩阵计算特征向量(主成分)及其相应的特征值。或者，可以应用奇异向量分解(SVD)。

4.  按 its 降序排列特征值，并选择能够解释数据中最大方差的 *k* 个特征向量(较大的特征值意味着该特征能够解释更多的方差)。

5.  创建新的投影矩阵 w。

6.  通过 W 变换原始数据集 X 以获得 k 维子空间 y

我意识到在前面的过程中有一些奇怪和未知的术语可能会使一些读者感到困惑和害怕。不用担心；它们将在下面的讨论和演示中进行讨论和澄清。

### PCA 脚本讨论

本演示的第一步是加载数据集，将使用该数据集。我将使用的数据集是经典的 Iris 数据集，我在前一章中使用过。它可从以下网站获得。该文件具有扩展数据。你只需要把扩展名改成 csv 就可以了。

`https://archive.ics.uci.edu/ml/datasets/Iris`

下载文件后，请确保删除第一行，其中包含原始列标题。如果不这样做，脚本将会失败。

这个鸢尾数据集包含来自三个不同物种的 150 朵鸢尾花的测量值。

Iris 数据集中的三个类是

1.  Iris setosa (n = 50)

2.  iris versioncolor(n = 50)

3.  弗吉尼亚虹膜(n = 50)

每个类中的四个功能是

1.  萼片长度，单位为厘米

2.  萼片宽度，单位为厘米

3.  花瓣长度(厘米)

4.  花瓣宽度(厘米)

以下是一个名为 pcaDemo.py 的 Python 脚本的完整列表，该脚本将通过可视化完成完整的 PCA 分析。我还根据需要为这些代码部分提供了额外的解释性注释。该脚本可从该书的配套网站获得:

```
# Import required libraries
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from sklearn import decomposition
from sklearn.preprocessing import scale
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

df = pd.read_csv('iris.csv', header=None, sep=',')
df.columns=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']
df.dropna(how="all", inplace=True) # Drops empty line at EOF
# Show the first 5 records
print(df.head())

f, ax = plt.subplots(1, 4, figsize=(10,5))
vis1 = sns.distplot(df['sepal_length'],bins=10, ax= ax[0])
vis2 = sns.distplot(df['sepal_width'],bins=10, ax=ax[1])
vis3 = sns.distplot(df['petal_length'],bins=10, ax= ax[2])
vis4 = sns.distplot(df['petal_width'],bins=10, ax=ax[3])
plt.show()

# split data table into data X and class labels y
X = df.ix[:,0:4].values
y = df.ix[:,4].values

# Standardize the data
X_std = StandardScaler().fit_transform(X)

# Compute the covariance matrix
mean_vec = np.mean(X_std, axis=0)
cov_mat = (X_std -mean_vec).T.dot(X_std - mean_vec) / (X_std.shape[0] - 1)
print('Covariance matrix \n%s' %cov_mat)

# Compute the Eigenvectors and Eigenvalues
cov_mat = np.cov(X_std.T)
eig_vals, eig_vecs = np.linalg.eig(cov_mat)
print('Eigenvectors \n%s' %eig_vecs)
print('Eigenvalues \n%s' %eig_vals)

eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]
eig_pairs.sort()
eig_pairs.reverse()
print('Eigenvalues in descending order:')
for i in eig_pairs:
    print(i[0])

# Compute the Eigenvalue ratios
tot = sum(eig_vals)
var_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)]
cum_var_exp = np.cumsum(var_exp)
print('Eigenvalue ratios:%s' %cum_var_exp)

#Create the W matrix

matrix_w = np.hstack((eig_pairs[0][1].reshape(4,1),
                      eig_pairs[1][1].reshape(4,1)))
print('Matrix W:\n', matrix_w)

# Transform the X_std dataset to the sub-space Y
Y = X_std.dot(matrix_w)
features = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']

# Create a scatter plot for PC1 vs PC2
x = df.loc[:,features].values

x = StandardScaler().fit_transform(x)

pca = PCA(n_components=2)

principalComponents = pca.fit_transform(x)

principalDf = pd.DataFrame(data=principalComponents, columns=['principal component 1','principal component 2'])
finalDf = pd.concat([principalDf, df[['class']]], axis=1)

fig = plt.figure(figsize=(8,8))
ax = fig.add_subplot(1,1,1)
ax.set_xlabel('Principal Component 1', fontsize=15)
ax.set_ylabel('Principal Component 2', fontsize=15)
ax.set_title('2 Component PCA', fontsize=20)
targets = ['setosa', 'versicolor', 'virginica']
colors = ['r', 'g', 'b']
for target, color in zip(targets, colors):
    indicesToKeep = finalDf['class'] == target

    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1'], finalDf.loc[indicesToKeep, 'principal component 2'], c=color, s=50)

ax.legend(targets)
ax.grid
plt.show()

```

下面的讨论详细阐述了这个脚本的各个部分发生了什么。我还没有评论那些我认为你应该已经能够轻松阅读和理解的部分，比如库导入部分。此外，为了节省空间，我将只显示代码段的开头和结尾，除非代码只有三行或更少。不要忘记确保下载文件的扩展名是 csv。

```
df = pd.read_csv('iris.csv', header=None, sep=',')
.
.
print(df.head())

```

在这段代码中，首先从当前目录下的 CSV 文件中创建一个名为`df`的 Pandas 数据帧。然后对列名(属性)进行初始化，做一些整理工作，然后显示标题或前五条记录，以确保正确创建了数据帧。

```
f, ax = plt.subplots(1, 4, figsize=(10,5))
.
.
plt.show()

```

这段代码为前四个属性创建了一系列单变量图。查看原始数据分布总是一个好主意，这样可以更好地理解您正在处理的内容。这些图显示在结果部分。

```
# split data table into data X and class labels y
X = df.ix[:,0:4].values
y = df.ix[:,4].values

```

在标准化发生之前，需要将数据分成名为`X`的属性集和名为`y`的类标签集。

```
X_std = StandardScaler().fit_transform(X)

```

该代码代表 PCA 过程中的第一步，即标准化输入数据。如果查看输入数据集，您会很快意识到数据具有不同的比例。标准化数据有助于最大化主成分(特征向量)的数据方差。在没有标准化的情况下，当计算协方差时，与 0 到 10 范围内的变量相比，0 到 100 范围内的变量将具有过度的影响。标准化减少了在分析中引入任何无意偏差的机会。通用标准化等式为

![$$ z=\frac{value- mean}{standard\ deviation} $$](../images/482214_1_En_3_Chapter/482214_1_En_3_Chapter_TeX_Equa.png)

在这种情况下，所有数据都转换到一个单位标度上，平均值为 0，方差和标准差为 1。对于许多不同的最大似然算法，单位尺度变换通常有助于获得最佳性能。

```
mean_vec = np.mean(X_std, axis=0)
cov_mat = (X_std -mean_vec).T.dot(X_std - mean_vec) / (X_std.shape[0] - 1)
print('Covariance matrix \n%s' %cov_mat)

```

PCA 过程的第 2 步是实例化协方差矩阵。协方差矩阵是一个 *n* × *n* 对称矩阵(其中 *n* 是维数)，它具有与所有可能的初始变量对相关联的所有协方差的条目。请注意，此计算中使用了标准化数据集。顺便说一下，标准化数据集的协方差等价于同一数据集的相关矩阵。这意味着数据集相关矩阵可以代替协方差矩阵用于 PCA 过程。

关于协方差矩阵的两个事实也有助于您的理解:

*   正值意味着两个变量一起增加或减少。这也称为相关。

*   负值意味着一个变量增加，另一个变量减少。这也被称为反向相关。

    ```
    cov_mat = np.cov(X_std.T)
    .
    .
    print('Eigenvalues \n%s' %eig_vals)

    ```

PCA 过程的第 3 步是计算与输入数据集相关的特征向量和特征值。这些计算可以通过三种方式之一完成:

*   使用协方差矩阵

*   使用相关矩阵

*   使用奇异值分解(SVD)

当属性值相似时，通常使用协方差矩阵，当属性值在不同的尺度上时，通常使用相关矩阵。不过我前面解释过，标准化协方差矩阵也等价于相关矩阵，所以基本上两个矩阵都可以用。在此代码中，使用协方差矩阵是因为数据已经标准化，并且计算协方差矩阵比计算相关矩阵更容易。

numpy 库使得计算特征向量和特征值变得很容易。`np.linalg.eig(cov_mat)`方法将这些作为两个名为`eig_vecs`和`eig_vals`的列表返回。特征向量和特征值总是成对的，这意味着向量总是有值的。

要认识到的一个关键点是`eig_vecs`是主要成分。主成分是由原始变量的线性组合或混合构成的新变量。这些新变量是不相关的，原始变量包含的大部分信息被压缩到前几个主成分中。这就是为什么 PCA 经常被描述为一种数据压缩算法。需要强调的一点是，主成分没有任何现实意义，因为它们是由原始数据集变量的线性组合构建的。从几何角度来看，主要成分如下:

> *主成分表示解释最大方差的数据方向(即向量)。*

向量携带的方差越大，数据点沿向量的分散就越大。此外，沿向量的离差越大，它携带的信息就越多。为了简化这个概念，只需将主成分视为新的轴，这些轴提供了查看和评估数据的最佳角度，以便更好地看到观察结果之间的差异。

按照特征值从高到低的顺序对特征向量进行排序，得到了重要性顺序的主分量。

最后，SVD 算法是另一种计算特征向量和特征值的有效方法。

```
eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in
.
.
for i in eig_pairs:
    print(i[0])

```

这是 PCA 过程中的步骤 4，按照特征值的顺序对特征向量进行排序，从最高到最低，从而按照重要性的顺序产生主分量。具有最低特征值的特征向量包含关于固有数据分布的最少量的信息。

```
tot = sum(eig_vals)
.
.
print('Eigenvalue ratios:%s' %cum_var_exp)

```

该代码部分创建了每个特征向量对总方差的累积影响列表。用户应该使用这个列表来确定最佳 k 值。您将很快在结果部分看到，k = 2 的值占数据集中方差的 95%以上。这是一个很好的结果，因为数据可以很容易地可视化。

```
#Create the W matrix
matrix_w = np.hstack((eig_pairs[0][1].reshape(4,1),
                      eig_pairs[1][1].reshape(4,1)))
print('Matrix W:\n', matrix_w)

```

这段代码是第 5 步，它创建了最后一步所需的 **W 矩阵**。

```
# Transform the X_std dataset to the sub-space Y
Y = X_std.dot(matrix_w)

```

这是 PCA 过程中的第六步，也是最后一步，其中标准化数据集被转换到名为矩阵 y 的 k 维子空间中。

```
x = df.loc[:,features].values
.
.
plt.show()

```

此代码部分创建了一个散点图，显示了针对主成分 1 和 2 绘制的数据点。该图为用户提供了一种很好的方式来可视化任何潜在数据模式的数据，这些潜在数据模式使用普通的 2D 特征散点图无法观察到。回想一下，原始数据集有四个特征，现在已通过 PCA 算法简化为 2D，从而可以创建此图。像这样的图是使用 PCA 进行数据建模的主要原因之一。

#### PCA 演示

首先确保 iris.csv 文件与脚本在同一个目录中，并且 csv 文件中的第一条记录已经被删除，就像我前面讨论的那样。通过输入以下命令运行脚本:

```
python pcaDemo.py

```

图 [3-1](#Fig1) 显示了运行该脚本产生的单变量图。

![../images/482214_1_En_3_Chapter/482214_1_En_3_Fig1_HTML.jpg](../images/482214_1_En_3_Chapter/482214_1_En_3_Fig1_HTML.jpg)

图 3-1

单变量图

这些图清楚地表明萼片值更倾向于高斯分布，而花瓣值更倾向于多峰分布。在考虑将合适的数据模型用于该数据集时，应该记住这些观察结果。这两种分布都与 PCA 数据模型兼容。

图 [3-2](#Fig2) 显示了脚本的数值结果。

![../images/482214_1_En_3_Chapter/482214_1_En_3_Fig2_HTML.jpg](../images/482214_1_En_3_Chapter/482214_1_En_3_Fig2_HTML.jpg)

图 3-2

数字结果

虽然临时结果是有用的，但要仔细检查的关键结果是特征值比率列表。该列表显示了与四个主成分或特征向量相关的累积方差百分比。请注意，列表中的第二个值是 95.8%，这意味着前两个主成分占测量方差的 95%以上。这意味着只有两个向量负责承载大部分数据集信息。这意味着 k = 2。这是一个很好的结果，它将允许创建一个非常精简的矩阵，该矩阵仍将表示原始数据集中包含的大部分信息。

表 [3-1](#Tab1) 从图中显示协方差矩阵，让我评论几个你应该知道的概念。

表 3-1

协方差矩阵

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"> <col class="tcol5 align-left"></colgroup> 
|   | 

萼片长度

 | 

萼片宽度

 | 

花瓣长度

 | 

花瓣宽度

 |
| --- | --- | --- | --- | --- |
| 萼片长度 | One | –0.11 | Zero point eight eight | Zero point eight two |
| 萼片宽度 | –0.11 | One | –0.42 | –0.36 |
| 花瓣长度 | Zero point eight eight | –0.42 | One | Zero point nine seven |
| 花瓣宽度 | Zero point eight two | –0.36 | Zero point nine seven | One |

首先要知道的是，每个表值也是相交要素之间的相关系数。主对角线由全 1 组成，因为这是自相关系数或对同一变量计算相关性的结果。第二个事实是，相关性是一个分布函数，这意味着变量的顺序不是结果中的一个因素。这导致了一个完美的对称矩阵，你可以从检查表格中看到。

表中有几个高相关值(忽略对角线)，这表明数据集包含大量冗余信息。这一结果也意味着主成分分析将提供对数据集中存在的任何隐藏或潜在模式的进一步了解，这应该是用户感兴趣的。

图 [3-3](#Fig3) 很重要，因为它确实显示了这个集合中隐藏的模式。

![../images/482214_1_En_3_Chapter/482214_1_En_3_Fig3_HTML.jpg](../images/482214_1_En_3_Chapter/482214_1_En_3_Fig3_HTML.jpg)

图 3-3

主成分散点图

该图是前两个主成分的散点图，这两个主成分贡献了数据集中包含的几乎 96%的信息。你应该很容易观察到 Setosa 物种与其他两个物种截然不同。其余两个物种的数据点聚类是相邻的，但仍可相互区分。我知道从书上的灰度图像中观察这个几乎是不可能的，但是相信我的话，星团确实是相邻的。使用传统的 2D 散点图根本不可能观察到这些结果，因为您可以通过查看第 [2](2.html) 章的 Iris 数据集图来亲自观察。

#### 何时使用 PCA

我认为增加一个关于何时使用 PCA 的简短部分是个好主意。当有理由怀疑数据集可能包含使用常规 2D 可视化技术时不容易观察到的隐藏或潜在模式时，PCA 将是合适的数据模型选择。

每当需要降维时，PCA 也是有用的。这种减少与下列情况密切相关:

*   高维数据的可视化。

*   降噪。通常，高阶主成分只对数据中的微小变化负责。

*   用于预处理将与其他 ML 算法一起使用的数据。这些算法可以包括那些对于较小维度的数据集运行得更好的算法。

*   有助于减少数据集中的相关性。相关数据并没有增加多少可用的信息，却大大增加了计算效率。

## 线性判别分析

线性判别分析(LDA)非常类似于主成分分析(PCA)，我在上一节中讨论过。一个很大的区别是，PCA 寻求确定那些使数据中的方差最大化的轴或主成分，而 LDA 寻求那些使类之间的分离最大化的轴。我强烈建议您在阅读 LDA 部分之前先阅读 PCA 部分，因为我将在这些部分中使用我在 PCA 部分中首次介绍和解释的术语，而不做任何解释。

LDA 和 PCA 一样，是一种降维算法，但是是有监督的。我很快会谈到在这种情况下什么是有监督的。LDA 将数据集投影到低维空间，同时增加类的可分性。增加的类可分离性降低了过度拟合发生的概率。LDA 还提高了计算效率。限制过拟合的能力使 LDA 比 PCA 算法具有明显的优势。

因为 PCA 和 LDA 看起来非常相似，所以我在图 [3-4](#Fig4) 中强调了这两种算法之间的一些显著差异。

![../images/482214_1_En_3_Chapter/482214_1_En_3_Fig4_HTML.jpg](../images/482214_1_En_3_Chapter/482214_1_En_3_Fig4_HTML.jpg)

图 3-4

PCA 和 LDA 的区别

PCA 是一种“无监督”算法，因为它不使用类别标签，主要目的是计算将最大化数据集中方差的轴或主成分。另一方面，LDA 是“受监督的”,并使用类数据来计算轴或线性判别式，以最大化多个类之间的分离。

LDA 过程包括五个步骤。这些是

1.  计算数据集中不同类的 d 维均值向量，其中 d 是特征空间的维数。

2.  计算类间和类内散布矩阵。

3.  计算散布矩阵的特征向量和成对特征值。

4.  选择前 k 个特征值对应的 k 个特征向量，形成 d×k 维的变换矩阵。

5.  通过变换矩阵将 d 维特征空间 X 变换到 k 维特征空间 X_lda。

### LDA 脚本讨论

本演示将使用 PCA 演示中使用的相同 Iris 数据集。但是，与 PCA 脚本相比，该脚本将自动加载数据集。

下面是一个名为 ldaTest.py 的 Python 脚本的完整列表，它将完成一个完整的可视化 LDA。我想指出这个脚本中的一个附加特性。在脚本的末尾，我演示了如何只使用 sklearn LDA 模块来执行 LDA，而不像前面的脚本部分那样遍历所有步骤。

像往常一样，我还会根据需要为这些代码部分提供额外的解释性注释。该脚本可从该书的配套网站获得:

```
#Import required libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

np.set_printoptions(precision=4)

#Read dataset
file_path = "https://raw.githubusercontent.com/bot13956/linear-discriminant-analysis-iris-dataset/master/iris.data.csv"
df = pd.read_csv(file_path, header=None)
df.head()

#Encode categorical class labels
from sklearn.preprocessing import LabelEncoder
class_le = LabelEncoder()
y = class_le.fit_transform(df[4].values)

#Standardize features
stdsc = StandardScaler()
X_train_std = stdsc.fit_transform(df.iloc[:,range(0,4)].values)

# Construct within-class covariant scatter matrix S_W
S_W = np.zeros((4,4))
for i in range(3):
    S_W += np.cov(X_train_std[y==i].T)

#Construct between-class scatter matrix S_B
N=np.bincount(y) # number of samples for given class
vecs=[]
[vecs.append(np.mean(X_train_std[y==i],axis=0)) for i in range(3)] # class means
mean_overall = np.mean(X_train_std, axis=0) # overall mean
S_B=np.zeros((4,4))
for i in range(3):
    S_B += N[i]*(((vecs[i]-mean_overall).reshape(4,1)).dot(((vecs[i]-mean_overall).reshape(1,4))))

# Compute sorted eigenvalues and eigenvectors of

# inverse(S_W)dot(S_B)
eigen_vals, eigen_vecs = np.linalg.eig(np.linalg.inv(S_W).dot(S_B))
eigen_pairs = [(np.abs(eigen_vals[i]), eigen_vecs[:,i]) for i in range(len(eigen_vals))]
eigen_pairs = sorted(eigen_pairs,key=lambda k: k[0], reverse=True)
print('Eigenvalues in decreasing order:\n')
for eigen_val in eigen_pairs:
    print(eigen_val[0])

# Plot the main LDA components
tot = sum(eigen_vals.real)
discr = [(i / tot) for i in sorted(eigen_vals.real, reverse=True)]
cum_discr = np.cumsum(discr)
plt.bar(range(1, 5), discr, width=0.2,alpha=0.5, align="center",label='individual "discriminability"')
plt.step(range(1, 5), cum_discr, where="mid",label='cumulative "discriminability"')
plt.ylabel('Discriminant ratio')
plt.xlabel('Linear Discriminants')
plt.ylim([-0.1, 1.1])
plt.legend(loc='best')
plt.show()

#Project original features onto the new feature

space
W=np.hstack((eigen_pairs[0][1][:, ].reshape(4,1),eigen_pairs[1][1][:, ].reshape(4,1))).real
X_train_lda = X_train_std.dot(W)

# List and plot transformed features in LDA sub-space
data=pd.DataFrame(X_train_lda)
data['class']=y
data.columns=["LD1","LD2","class"]
data.head()
markers = ['s', 'x','o']
sns.lmplot(x="LD1", y="LD2", data=data, markers=markers,fit_reg=False, hue="class", legend=False)
plt.legend(loc='upper center')
plt.show()

#LDA implementation using scikit-learn
lda = LinearDiscriminantAnalysis(n_components=2)
X_train_lda = lda.fit_transform(X_train_std, y)

# List and plot the scikit-learn LDA results
data=pd.DataFrame(X_train_lda)
data['class']=y
data.columns=["LD1","LD2","class"]
data.head()
markers = ['s', 'x','o']
colors = ['r', 'b','g']
sns.lmplot(x="LD1", y="LD2", data=data, hue="class", markers=markers,fit_reg=False,legend=False)
plt.legend(loc='upper center')
plt.show()

```

以下是关于前面脚本中各种代码段的解释性讨论，这些代码段引入了 PCA 部分中未涉及的新概念。此外，为了节省空间，我将只显示代码段的开头和结尾，除非代码只有三行或更少。

```
from sklearn.preprocessing import LabelEncoder
class_le = LabelEncoder()
y = class_le.fit_transform(df[4].values)

```

类字符串值被转换成数值，以便在脚本中更容易处理。sklearn `LabelEncoder`模块完成这项任务。

```
S_W = np.zeros((4,4))
for i in range(3):
    S_W += np.cov(X_train_std[y==i].T)

```

创建一个代表类内协方差的 4×4 矩阵 S_W。

```
N=np.bincount(y) # number of samples for given class
.
.
mean_overall).reshape(4,1)).dot(((vecs[i]-mean_overall).reshape(1,4))))

```

创建一个代表类间协方差的 4 x 4 矩阵 S_W。

```
eigen_vals, eigen_vecs = np.linalg.eig(np.linalg.inv(S_W).dot(S_B))
.
.
for eigen_val in eigen_pairs:
    print(eigen_val[0])

```

计算和排序特征向量和特征值。排序后的特征值也在屏幕上列出。

```
tot = sum(eigen_vals.real)
.
.
plt.show()

```

绘制了主要的 LDA 组件。

```
W=np.hstack((eigen_pairs[0][1][:, ].reshape(4,1),eigen_pairs[1][1][:, ].reshape(4,1))).real
X_train_lda = X_train_std.dot(W)

```

将原始特征投影到新的特征空间。

```
data=pd.DataFrame(X_train_lda)
.
.
plt.show()

```

将变换后的特征绘制到 LDA 子空间中。

```
lda = LinearDiscriminantAnalysis(n_components=2)
X_train_lda = lda.fit_transform(X_train_std, y)

```

使用 scikit-learn 实现 LDA。

```
data=pd.DataFrame(X_train_lda)
.
.
plt.show()

```

绘制 scikit-learn LDA 结果。

#### LDA 演示

通过输入以下命令运行脚本:

```
python ldaTest.py

```

图 [3-5](#Fig5) 显示了运行这个脚本得到的分类特征值。您可以清楚地看到，前两个值是唯一的重要值，这也证实了虹膜数据集的 PCA 结果。

![../images/482214_1_En_3_Chapter/482214_1_En_3_Fig5_HTML.jpg](../images/482214_1_En_3_Chapter/482214_1_En_3_Fig5_HTML.jpg)

图 3-5

分类特征值

图 [3-6](#Fig6) 是线性判别式的相对幅度图。

![../images/482214_1_En_3_Chapter/482214_1_En_3_Fig6_HTML.jpg](../images/482214_1_En_3_Chapter/482214_1_En_3_Fig6_HTML.jpg)

图 3-6

线性判别式的相对幅度图

由于第一个线性判别式与其他三个线性判别式相比具有巨大的值，所以该图非常倾斜。它比第二线性判别式大 99%以上，在图中显示为直线而不是条形。剩下的一个可以忽略不计，无法绘制，你可以通过检查图 [3-5](#Fig5) 的特征值来辨别。

图 [3-7](#Fig7) 是变换后的虹膜数据集与前两个线性判别式的关系图。

![../images/482214_1_En_3_Chapter/482214_1_En_3_Fig7_HTML.jpg](../images/482214_1_En_3_Chapter/482214_1_En_3_Fig7_HTML.jpg)

图 3-7

变换后的虹膜数据集的图

从该图中得到的重要信息是，现在由该图中的数字表示的每个虹膜类别沿着线性判别 1 (LD1)轴明显分开。当应用 LDA 算法时，这总是最佳结果。您应该将该图与 PCA 部分的图 [3-3](#Fig3) 进行比较，以查看它们之间的接近程度。从我的视觉解释来看，我会说 LDA 图比 PCA 图显示了更多的类之间的分离，但这是一个侥幸的机会。

图 [3-8](#Fig8) 是使用 sklearn LDA 模块的结果图。

![../images/482214_1_En_3_Chapter/482214_1_En_3_Fig8_HTML.jpg](../images/482214_1_En_3_Chapter/482214_1_En_3_Fig8_HTML.jpg)

图 3-8

sklearn LDA 模块的结果图

您可以考虑将本模块作为一个单步流程来使用，因为并非所有的中期结果都是现成的。尽管如此，绘制的结果是完全可以接受的，并且与通过遵循逐步过程获得的结果非常接近。

#### 主成分分析和线性判别分析的比较

我创建了图 [3-9](#Fig9) ，这是一个并排显示图 [3-3](#Fig3) 和 [3-7](#Fig7) 的复合图，以突出两个主题算法之间的异同。

![../images/482214_1_En_3_Chapter/482214_1_En_3_Fig9_HTML.jpg](../images/482214_1_En_3_Chapter/482214_1_En_3_Fig9_HTML.jpg)

图 3-9

PCA 和 LDA 比较图

图 [3-9](#Fig9) 证实了已经讨论过的内容。PCA 解释了整个数据集中最大的差异，而 LDA 给出了解释各个类之间最大差异的轴。

## 支持向量机

支持向量机(SVN)数据模型侧重于分类，在较小程度上侧重于预测。SVM 的主要目标是确定能够将数据分割成至少两个维度(2D)的最佳或最优边界。当处理不止 2D 时，分裂边界称为分离超平面。“最佳”超平面是在支持向量之间创建最宽边界的超平面。超平面通常也称为决策边界。

我认为传达 SVM 基本概念的最佳方式是通过直观的讨论和图形的结合。支持向量机可以用纯粹的数学术语来描述，但是数学很快变得复杂并且明显不直观。

最初的讨论只涉及线性 SVM 数据模型。在演示的第一部分之后，我将介绍非线性 SVM 模型。

我将从一个只有六个数据点的简单图开始，它被分成两类，每类三个点。图 [3-10](#Fig10) 显示了这些数据点。

![../images/482214_1_En_3_Chapter/482214_1_En_3_Fig10_HTML.jpg](../images/482214_1_En_3_Chapter/482214_1_En_3_Fig10_HTML.jpg)

图 3-10

示例数据点

如果一个新的数据点被添加到图中，它将被直观地归类为属于它最接近的类。当然，应用 KNN 数据模型可以轻松完成这项任务。使用 KNN 模型的问题是必须为每个数据点计算欧几里德距离。对于这个微小的数据集来说，这不是问题；然而，KNN 在处理大型数据集时不能很好地扩展，尽管它相当可靠和准确。SVM 改变了整个视点，因为它最适合超平面来划分数据集。一旦计算出决策边界，任何新数据都将根据其边界位置自动分类。决策边界保持固定，除非数据集被重新训练。这意味着 SVM 可以轻松扩展以容纳新数据，这与 KNN 模式不同。

现在自然的问题是如何确定最佳分割超平面？如图 [3-11](#Fig11) 所示，可以“翻白眼”。

![../images/482214_1_En_3_Chapter/482214_1_En_3_Fig11_HTML.jpg](../images/482214_1_En_3_Chapter/482214_1_En_3_Fig11_HTML.jpg)

图 3-11

“眼球状”超平面

这条分割线，从技术上讲是超平面的 2D 投影，看起来差不多是对的。然而，新的问题是如何找到支持向量？找到支持向量的关键是认识到最接近决策边界的类数据点也将是支持向量的一部分。图 [3-12](#Fig12) 显示了本例中 SVM 支持向量的图形渲染。

![../images/482214_1_En_3_Chapter/482214_1_En_3_Fig12_HTML.jpg](../images/482214_1_En_3_Chapter/482214_1_En_3_Fig12_HTML.jpg)

图 3-12

支持向量

接下来创建贯穿支持向量数据点的最大分离线。决策边界的位置由总宽度 *W* 决定，如图 [3-13](#Fig13) 所示。

![../images/482214_1_En_3_Chapter/482214_1_En_3_Fig13_HTML.jpg](../images/482214_1_En_3_Chapter/482214_1_En_3_Fig13_HTML.jpg)

图 3-13

总宽度测定

现在，只需将 *W* 除以 2，决策边界的位置就固定了。如图 [3-14](#Fig14) 所示。

![../images/482214_1_En_3_Chapter/482214_1_En_3_Fig14_HTML.jpg](../images/482214_1_En_3_Chapter/482214_1_En_3_Fig14_HTML.jpg)

图 3-14

确定决策边界的位置

图 [3-15](#Fig15) 是 SVM 模型的直观图形，显示了支持向量和决策边界之间的最大距离。

![../images/482214_1_En_3_Chapter/482214_1_En_3_Fig15_HTML.jpg](../images/482214_1_En_3_Chapter/482214_1_En_3_Fig15_HTML.jpg)

图 3-15

直观的图表显示了最大化的距离

看图，现在可以说，判定边界/分离超平面左边的任何点都在黑点类中，而右边的任何数据点都在红色加号类中。

前面是对 SVM 的简单介绍，没有使用数学或代码。下面的演示展示了如何以有益的方式使用 SVM。

### SVM 演示–第 1 部分

这次演示使用了 sklearn 的 SVM 模块。因此，不需要像本章前面的数据模型那样一步一步地开发代码。该代码使用另一个经典数据集，名为乳腺癌威斯康星州(诊断)数据集。这是一个多变量数据集，有 30 个属性，取自 569 例乳腺癌针吸活检。这些属性是健康细胞和恶性细胞的细胞描述。从本质上讲，数据集中涉及两类人，一类是有恶性细胞的患者，另一类是没有恶性细胞的患者。这个数据集是 sklearn 有机数据集的一部分，不需要做显式下载。数据集直接导入到脚本中。

这个 SVM 演示的最终目标是确定一个测试记录在给定一组特定属性的情况下是健康的还是不健康的概率。

这个脚本被命名为 svmDemo1.py，可以从本书的配套网站上获得。我没有包括任何额外的评论，因为脚本很短，我认为包括的评论足以解释代码。

```
# Import required libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import classification_report

# Import dataset into a variable named 'cancer'
from sklearn.datasets import load_breast_cancer
cancer = load_breast_cancer()

# Load input features as a DataFrame
df_features = pd.DataFrame(cancer['data'], columns = cancer['feature_names'])

# Add output variable 'target' into a DataFrame
df_target = pd.DataFrame(cancer['target'], columns = ['Cancer'])

# Display the first 5 records
print(df_features.head())

# Split the dataset, 70% to train, 30% to test
X_train, X_test, y_train, y_test = train_test_split(df_features, np.ravel(df_target), test_size=0.30, random_state=101)

# Instantiate the SVC model. SVC is the sklearn classifier name.
model = SVC()

# Train the model using the fit method
model.fit(X_train, y_train)

# Test the model using the test dataset
predictions = model.predict(X_test)

# Display the prediction results

print(classification_report(y_test, predictions))

```

通过输入以下命令运行脚本:

```
python svmDemo1.py

```

图 [3-16](#Fig16) 显示了运行脚本的结果。

![../images/482214_1_En_3_Chapter/482214_1_En_3_Fig16_HTML.jpg](../images/482214_1_En_3_Chapter/482214_1_En_3_Fig16_HTML.jpg)

图 3-16

svmDemo1 结果

您应该注意的第一件事是 head 结果，它显示了数据集中前五条记录的一部分。有 30 个属性，这意味着这是一个线性超平面试图分离的高维数据集。这个事实本身就应该给你敲响警钟。几乎不可能想象出任何一个平面可以有效地分离这么多的数据点，尤其是在许多数据点具有相似规模的情况下。这一现实在加权平均值为 0.38 的预测结果中得到证实。这是一个令人沮丧的结果，意味着只有 38%的测试数据被正确预测。从长远来看，你可以通过抛硬币来做得更好。如何改善这一结果？答案包含在下面的讨论中。

### SVM 演示–第二部分

在 SVM 有一种被称为内核“技巧”的技术，它是为处理高维数据集而开发的，例如本演示中使用的乳腺癌数据集。从某种意义上来说，这个技巧并不是一个“卑鄙”或“狡猾”的技巧，而只是为了适应高维数据集。当数据点在 p 维或有限空间中不可线性分离时，建议将该空间映射到更高维的空间中。然后，可以使用核技巧来构建定制的非线性超平面。每个 SVM 核都有一个非线性核函数。该函数有助于建立高维特征空间。已经开发了许多内核，目前正在研究其他内核。这是一个极其活跃的研究领域。

我将使用直观/图形化的方法来解释非线性内核，就像我对基本 SVM 概念所做的那样，因为这个主题的基础数学太复杂和详细，不包括在本书中。

在图 [3-17](#Fig17) 中，左手边有 *x* 和 *o* 数据点，对于 2D 的情况，这些数据点明显不能被线性平面或直线分开。然而，如果数据点被一些 function∅变换，它们可以容易地被分离，如图的右侧所示。

![../images/482214_1_En_3_Chapter/482214_1_En_3_Fig17_HTML.jpg](../images/482214_1_En_3_Chapter/482214_1_En_3_Fig17_HTML.jpg)

图 3-17

转换数据集

主要思想是通过将原始数据集映射到更高维的空间来改进类线性分离。在图 [3-18](#Fig18) 中，图左上方的原始数据点不能用一个线性函数分开。它们可以在被二次函数映射后被分离，这可以通过右侧的图观察到。

![../images/482214_1_En_3_Chapter/482214_1_En_3_Fig18_HTML.jpg](../images/482214_1_En_3_Chapter/482214_1_En_3_Fig18_HTML.jpg)

图 3-18

由二次函数转换的数据集

图 [3-19](#Fig19) 提出了另一个问题，其中决策边界并不明显。问题是可以用什么决策函数来分离这些数据点？

![../images/482214_1_En_3_Chapter/482214_1_En_3_Fig19_HTML.jpg](../images/482214_1_En_3_Chapter/482214_1_En_3_Fig19_HTML.jpg)

图 3-19

有问题的数据集

这个问题的答案是使用极坐标，如图 [3-20](#Fig20) 所示。

![../images/482214_1_En_3_Chapter/482214_1_En_3_Fig20_HTML.jpg](../images/482214_1_En_3_Chapter/482214_1_En_3_Fig20_HTML.jpg)

图 3-20

已解决有问题的数据集

SVM 有以下解决非线性数据集问题的内核:

多项式内核——这个内核实现了这个等式

![$$ K\left({x}_i,{x}_j\right)={\left({x}_i\ast {x}_j+1\right)}^p $$](../images/482214_1_En_3_Chapter/482214_1_En_3_Chapter_TeX_Equb.png)

其中 *p* =可调参数。还要注意，计算 *K* 只需要对原始点积进行 1 次加法和 1 次幂运算。

径向基函数(RBF)——这个内核实现了这个等式

![$$ K\left({x}_i,{x}_j\right)={e}^{-\frac{{\left|{x}_i-{x}_j\right|}^2}{2\ast {\sigma}^2}} $$](../images/482214_1_En_3_Chapter/482214_1_En_3_Chapter_TeX_Equc.png)

rbf 也称为高斯函数。图 [3-21](#Fig21) 显示了高斯函数在示例数据集上的应用。

![../images/482214_1_En_3_Chapter/482214_1_En_3_Fig21_HTML.jpg](../images/482214_1_En_3_Chapter/482214_1_En_3_Fig21_HTML.jpg)

图 3-21

高斯函数应用

Sigmoid 函数——这是 sigmoid 函数，在其他数据模型中也用作激活函数。

以下脚本名为 svmDemo2.py，可从本书的配套网站获得。清单只显示了额外的代码，这些代码必须附加到现有的 svmDemo1.py 脚本中。我在代码后面加入了一些解释性的注释。

```
# Gridsearch
param_grid = {'C':[0.1, 1, 10, 100, 1000], 'gamma':[1, 0.1, 0.01, 0.001, 0.0001], 'kernel':['rbf']}

from sklearn.model_selection import GridSearchCV
grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=3)
grid.fit(X_train, y_train)
print('\n')
print('The best parameters are ', grid.best_params_)
grid_predictions = grid.predict(X_test)

from sklearn.metrics import classification_report
print(classification_report(y_test, grid_predictions))

```

这些是关于这个脚本中包含的新代码的解释性注释。

```
param_grid = {'C':[0.1, 1, 10, 100, 1000], 'gamma':[1, 0.1, 0.01, 0.001, 0.0001], 'kernel':['rbf']}

```

在该语句中设置了三个重要的 SVM 参数`kernel`、`C`和`gamma`。`kernel`参数有以下选项:

*   线性–当数据集适合线性超平面分离时使用

*   RBF–非线性超平面

*   多元非线性超平面

`C`参数用于训练阶段，指定在计算支持向量时考虑多少数据异常值。`C`的低值平滑决策表面，而高值允许 SVM 模型选择更多样本作为支持向量。

`gamma`参数定义单个训练示例的影响范围，低值表示“远”，高值表示“近”`gamma`参数可以解释为由模型选择作为支持向量的样本的影响半径的倒数。

选择合适的参数主要基于数据集属性。在这种情况下，对于高维数据集，rbf 是一个很好的选择。选择 C 和γ的值是一个棘手的问题。幸运的是，sklearn 提供了选择这些参数的迭代方法。

```
from sklearn.model_selection import GridSearchCV
grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=3)
grid.fit(X_train, y_train)
print('\n')
print('The best parameters are ', grid.best_params_)
grid_predictions = grid.predict(X_test)

```

`GridSearchCV`模块生成一个交叉验证的网格搜索对象。在这段代码中，对数据集执行了两项任务，即交叉验证和(超)参数调整。交叉验证是使用一组数据并使用另一组数据测试模型的过程。参数调整是选择模型参数值以最大限度提高模型准确性的过程。名为`grid`的对象现在包含了迭代网格搜索过程产生的`C`和`gamma`参数的最佳值。显示最佳参数值，并使用最佳参数进行一组新的预测。

```
from sklearn.metrics import classification_report
print(classification_report(y_test, grid_predictions))

```

使用从 sklearn 的`metrics`库中导入的`classification_report`模块来确认预测的准确性。回想一下，我以前在其他演示中使用过这个模块。

通过输入以下命令运行脚本:

```
python svmDemo2.py

```

图 [3-22](#Fig22) 显示了运行脚本的结果。

![../images/482214_1_En_3_Chapter/482214_1_En_3_Fig22_HTML.jpg](../images/482214_1_En_3_Chapter/482214_1_En_3_Fig22_HTML.jpg)

图 3-22

svmDemo2 结果

在这个图中，您可能注意到的第一件事是从顶部出现的中期结果滚动。这个卷轴只是计算最终优化参数的 75 个步骤中的一小部分。滚动中的最后一行显示最终值为

内核= rbf，伽玛= 0.0001，C = 1000。

显然，内核规范在迭代过程中没有改变，但另一方面的确如此。我确实检查了这个卷轴，并确定 gamma 值似乎对最终精度的影响最大。它是一个很小的值，这意味着由支持向量模型选择的样本的影响半径是相当大的，也就是说，最大数据点被包括在支持向量的确定中。

结果最后一行显示的加权平均准确度为 0.95 或 95%。这是一个很好的结果，与演示的第 1 部分中糟糕的 38%的结果相比是一个巨大的进步。这个结果正好证明了只使用“适合”原始数据集的适当数据模型是极其重要的，并且任何调优参数都必须进行优化调整。

## 学习矢量量化

我将首先感谢 Jason Brownlee 博士在 2018 年 8 月发表的题为“如何使用 Python 从零开始实现学习矢量量化”的精彩博客，本节的大部分代码和关键概念都基于该博客。我在之前的讨论中使用过 Jason 的博客，我发现他的教程非常清晰和有启发性。我强烈推荐你去看看他的博客、文章和电子书。

学习矢量量化(LVQ)类似于 k-NN 算法，通过找到与现有数据模式最接近的匹配来进行预测。两者之间的显著区别是，k-NN 使用实际的训练模式，而 LVQ 从训练数据中创建模式库。

模式库称为矢量码本，库中的每个模式称为码本。码本向量被初始化为从训练数据集中随机选择的值。然后，经过若干时期或训练周期，它们被修改以通过使用学习算法最佳地总结训练数据。这种学习算法通过在码本向量中寻找最佳匹配来一次处理一个训练记录。修改训练记录，使得如果它们都来自相同的类，则它“更接近”码本向量，或者如果它们来自不同的类，则移动“更远”。我将很快解释距离的比喻，以帮助澄清这个概念，移动靠近或远离数据项。

预测仅在所有码本向量都被处理后开始。使用 k = 1 的 k-NN 算法进行预测。

### LVQ 基本概念

需要讨论的第一项是将在包括演示在内的所有后续部分中使用的数据集。该数据集是雷达对地球大气进行“探测”所得到的数字记录的集合。每条记录都描述了返回雷达信号的特性，其中可能包括电离层的重要测量值。数据模型的目的是预测特定记录是否包含任何重要的电离层测量值。

数据集中有 351 条记录，每条记录包含 34 个数值数据点。对于每个雷达回波信号，这些点被分组为 17 对，每个值的数值范围为 0 到 1。目标类的属性值为“g”表示好，为“b”表示坏。

该数据集被命名为 inosphere.csv，可以从

`https://archive.ics.uci.edu/ml/datasets/Ionosphere`

#### 欧几里得距离

要讨论的概念是欧几里德距离。我意识到我在以前的讨论中使用过这个术语，它有时根据上下文有不同的意思。在这种情况下，电离层数据集由数行数字组成。欧几里德距离被定义为两个向量之间的平方差的和的平方根，其中向量由行数据构成。距离测量的公式为

![$$ distance=\sqrt{\sum_i^N{\left({x}_{1,i}-{x}_{2,i}\right)}^2} $$](../images/482214_1_En_3_Chapter/482214_1_En_3_Chapter_TeX_Equd.png)

在哪里

*   *x*<sub>T3】1T5】=第一行数据</sub>

*   *x*<sub>T3】2T5】=第二行数据</sub>

*   *i* =列索引

*   *N* =列数(属性)

欧几里德距离越小，两个数据记录越相似。相反，距离越大，记录越不相似。如果距离为 0，则记录相同。

#### 最佳匹配单元

最佳匹配单元(BMU)是与新数据记录最相似的码本向量。为新记录定位 BMU 需要计算新记录和每个码本向量之间的欧几里德距离。这是使用前面讨论的距离测量来完成的。一旦完成，所有的距离被排序，并且与最小距离值相关联的码本向量与新记录最相似。

前面描述的过程与使用 LVQ 进行预测的方式相同。k = 1 的 KNN 算法用于定位与未知记录最相似的码本向量。返回“g”或“b”的相关类值。

#### 训练码本向量

训练码本向量的第一步是用从训练数据集中找到的随机特征构造的模式初始化所有向量。一旦初始化，向量必须被修改以最佳地概括训练数据集。这些修改以迭代的方式发生。在顶层，使用完整的训练集对固定数量的时期重复该过程。在每个时期内，每个训练模式仅被使用一次来更新食谱向量。为每个训练模式检测并更新 BMU。训练模式和 BMU 之间的任何差异都被计算并记录为误差。然后将 BMU 和训练模式的类值进行比较，如果找到匹配，将导致记录的误差被添加到 BMU，这使其“更接近”训练模式。相反，如果类值不匹配，则减去误差，这导致 BMU 被“推”离训练模式更远。

学习率(LR)参数控制 BMU 的调整量。此参数是一个加权系数，影响应用于所有 bmu 的变更量。例如，如果 LR 是 0.20 或 20%，这将意味着只有 20%的检测误差将应用于 BMU。此外，LR 本身被调整，使得它在第一个时期具有最大效果，而在随后的时期具有较小效果。这种递减效应被称为线性衰减学习速率表，也广泛用于人工神经网络。

### LVQ 示威

在开始我惯常的演示之前，我认为引入零规则算法是合适的。在实际尝试各种模型之前，通常不可能确定哪种数据模型最适合您的特定问题领域。因此，在开始解决问题时，创建一个性能基线是很重要的。基线性能提供了一个参考，可以用来与应用于该问题的任何数据模型进行比较。没有基线，就不可能意识到一个特定的模型取得了多大的成就。分类和回归的基线都是由零规则算法创建的，也称为 ZeroR 或 0-R。

分类值是在分类预测模型中预测的。零规则算法预测训练数据集中具有最多观察值的类值。我将使用机器学习软件的怀卡托知识分析环境( *Weka* )套件演示如何将零规则算法应用于电离层数据集。主用户界面被称为*浏览器*。Weka 是一个基于 Java 的应用程序，可以作为 jar 文件在 RasPi 上运行。Weka 可从以下网址下载

`https://sourceforge.net/projects/weka/`

为了使用电离层数据集，它必须是 arff 格式。标题为 ionosphere.arff 的数据集可从本页下载:

`https://github.com/renatopp/arff-datasets/find/master`

在运行应用程序之前，请确保 ionosphere.arff 与 Weka jar 文件位于同一个目录中。然后，通过输入以下命令启动应用程序。请注意，Weka 也可以通过 Windows 的 exe 扩展名下载，因此您可以使用安装程序来安装 Weka。

```
java -jar weka.jar

```

要获得基线结果，应遵循以下七个步骤:

1.  启动 Weka GUI 选择器。

2.  单击“资源管理器”按钮打开 Weka 资源管理器界面。

3.  加载电离层数据集*电离层. arff* 文件。

4.  单击“分类”选项卡打开“分类”选项卡。

5.  选择 ZeroR 算法(它应该是默认选择的)。

6.  选择“交叉验证”测试选项(默认情况下应选中)。

7.  单击“开始”按钮评估数据集上的算法。

Weka 浏览器的结果如图 [3-23](#Fig23) 所示。

![../images/482214_1_En_3_Chapter/482214_1_En_3_Fig23_HTML.jpg](../images/482214_1_En_3_Chapter/482214_1_En_3_Fig23_HTML.jpg)

图 3-23

Weka 浏览器结果

ZeroR 算法预测所有实例的“*g”*值，因为它是多数类，并且实现了 64.1%的准确度。任何机器学习算法要证明它在这个问题上有更好的性能，它必须达到比这个值更好的精度。

以下脚本实现了基本概念一节中介绍的所有概念。它被命名为 lvqDemo.py，可以从该书的配套网站上获得。在清单之后，我还提供了额外的解释性注释。记住，为了与代码兼容，要使数据集在 csv 扩展中可用。

```
# LVQ for the ionosphere dataset
from random import seed
from random import randrange
from csv import reader
from math import sqrt

# Load a CSV file
def load_csv(filename):
      dataset = list()
      with open(filename, 'r') as file:
            csv_reader = reader(file)
            for row in csv_reader:
                   if not row:
                         continue
                   dataset.append(row)
      return dataset

# Convert string column to float
def str_column_to_float(dataset, column):
      for row in dataset:
            row[column] = float(row[column].strip())

# Convert string column to integer
def str_column_to_int(dataset, column):
      class_values = [row[column] for row in dataset]
      unique = set(class_values)
      lookup = dict()
      for i, value in enumerate(unique):
            lookup[value] = i
      for row in dataset:
            row[column] = lookup[row[column]]
      return lookup

# Split a dataset into k folds
def cross_validation_split(dataset, n_folds):
      dataset_split = list()
      dataset_copy = list(dataset)
      fold_size = int(len(dataset) / n_folds)
      for i in range(n_folds):
            fold = list()
            while len(fold) < fold_size:
                   index = randrange(len(dataset_copy))
                   fold.append(dataset_copy.pop(index))
            dataset_split.append(fold)
      return dataset_split

# Calculate accuracy percentage
def accuracy_metric(actual, predicted):
      correct = 0
      for i in range(len(actual)):
            if actual[i] == predicted[i]:
                   correct += 1
      return correct / float(len(actual)) * 100.0

# Evaluate an algorithm using a cross validation split
def evaluate_algorithm(dataset, algorithm, n_folds, *args):
      folds = cross_validation_split(dataset, n_folds)
      scores = list()
      for fold in folds:
            train_set = list(folds)
            train_set.remove(fold)
            train_set = sum(train_set, [])
            test_set = list()
            for row in fold:
                   row_copy = list(row)
                   test_set.append(row_copy)
                   row_copy[-1] = None
            predicted = algorithm(train_set, test_set, *args)
            actual = [row[-1] for row in fold]
            accuracy = accuracy_metric(actual, predicted)
            scores.append(accuracy)
      return scores

# calculate the Euclidean distance between two vectors
def euclidean_distance(row1, row2):
      distance = 0.0
      for i in range(len(row1)-1):
            distance += (row1[i] - row2[i])**2
      return sqrt(distance)

# Locate the best matching unit
def get_best_matching_unit(codebooks, test_row):
      distances = list()
      for codebook in codebooks:
            dist = euclidean_distance(codebook, test_row)
            distances.append((codebook, dist))
      distances.sort(key=lambda tup: tup[1])
      return distances[0][0]

# Make a prediction with codebook vectors
def predict(codebooks, test_row):
      bmu = get_best_matching_unit(codebooks, test_row)
      return bmu[-1]

# Create a random codebook vector
def random_codebook(train):
      n_records = len(train)
      n_features = len(train[0])
      codebook = [train[randrange(n_records)][i] for i in range(n_features)]
      return codebook

# Train a set of codebook vectors
def train_codebooks(train, n_codebooks, lrate, epochs):
      codebooks = [random_codebook(train) for i in range(n_codebooks)]
      for epoch in range(epochs):
            rate = lrate * (1.0-(epoch/float(epochs)))
            for row in train:
                   bmu = get_best_matching_unit(codebooks, row)
                   for i in range(len(row)-1):
                         error = row[i] - bmu[i]
                         if bmu[-1] == row[-1]:
                               bmu[i] += rate * error

                         else:
                               bmu[i] -= rate * error
      return codebooks

# LVQ Algorithm
def learning_vector_quantization(train, test, n_codebooks, lrate, epochs):
      codebooks = train_codebooks(train, n_codebooks, lrate, epochs)
      predictions = list()
      for row in test:
            output = predict(codebooks, row)
            predictions.append(output)
      return(predictions)

# Test LVQ on ionosphere dataset
seed(1)
# load and prepare data
filename = 'ionosphere.csv'
dataset = load_csv(filename)
for i in range(len(dataset[0])-1):
      str_column_to_float(dataset, i)
# convert class column to integers
str_column_to_int(dataset, len(dataset[0])-1)
# evaluate algorithm

n_folds = 5
learn_rate = 0.3
n_epochs = 50
n_codebooks = 20
scores = evaluate_algorithm(dataset, learning_vector_quantization, n_folds, n_codebooks, learn_rate, n_epochs)
print('Scores: %s' % scores)
print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))

```

以下是对上述代码中不易理解的部分的附加注释。此外，在讨论代码部分发生了什么之前，我将只展示三行或更少的代码(除了主要部分)。

```
# Split a dataset into k folds
def cross_validation_split(dataset, n_folds):
.
.
      return dataset_split

```

这个方法实现了一个 n 重交叉验证过程，我已经在第 [1](1.html) 章讨论过了。请参考那一章来重新了解这一过程。

```
# Evaluate an algorithm using a cross validation split
def evaluate_algorithm(dataset, algorithm, n_folds, *args):
.
.
    return scores

```

将 LVQ 算法应用于 n 重交叉验证数据集。如果需要，该方法被设计成使用其他算法。

```
# Locate the best matching unit
def get_best_matching_unit(codebooks, test_row):
.
.
      return distances[0][0]

```

为`test_row`参数寻找 BMU。这个方法实现了 BMU 部分描述的过程。

```
# Train a set of codebook vectors
def train_codebooks(train, n_codebooks, lrate, epochs):
.
.
      return codebooks

```

训练码本向量。这种方法实现了在训练码本矢量一节中描述的过程。

```
# LVQ Algorithm
def learning_vector_quantization(train, test, n_codebooks, lrate, epochs):
.
.
      return(predictions)

```

这是实际的 LVQ 算法。从某种意义上说，它并不仅仅调用实现基本 LVQ 概念的其他方法。在调用该方法之前，需要对数据集进行预处理，码本向量也是如此。

```
# Test LVQ on ionosphere dataset
seed(1)
# load and prepare data
filename = 'ionosphere.csv'
dataset = load_csv(filename)
.
.
print('Scores: %s' % scores)
print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))

```

这是执行整个 LVQ 数据模型所需的所有步骤的主要代码部分。这一部分之前的所有代码都是实现 LVQ 过程中各个步骤的函数定义。代码主体按照完全处理 LVQ 算法和显示最终结果所需的顺序调用这些方法。

通过输入以下命令运行脚本:

```
python lvqDemo.py

```

图 [3-24](#Fig24) 显示了运行该脚本的结果。

![../images/482214_1_En_3_Chapter/482214_1_En_3_Fig24_HTML.jpg](../images/482214_1_En_3_Chapter/482214_1_En_3_Fig24_HTML.jpg)

图 3-24

lvqDemo 结果

该图显示，该 LVQ 数据模型的平均准确度为 87.1%，比零规则估计值 64.1%有了显著提高。这一结果证实，LVQ 模型是一个很好的电离层数据集使用模型，可以做出相当准确的预测。

## 装袋和随机森林

我将通过再次赞扬杰森·布朗利博士关于套袋和随机森林的一系列伟大的博客来开始这次讨论。这些博客分别是 2016 年 4 月《机器学习的 Bagging 和随机森林集成算法》，2016 年 11 月《如何用 Python 从零开始实现 Bagging》，2016 年 11 月《如何用 Python 从零开始实现随机森林》。本节中的许多代码和关键概念都基于前面提到的博客；然而，我确实在那些需要的地方添加了我自己的评论和详细的解释，我相信这对没有经验的读者会有帮助。

### 装袋和随机森林简介

随机森林是一种流行的算法，是一种集成 ML 算法，简称为 bootstrap aggregation 或 bagging。我将首先讨论自举这个词的含义。这是一个统计过程，旨在从数据集中估计一些度量或指标。一个简单的例子应该有助于澄清这个概念。

如果数据集对于某个变量 *x* 有 100 个样本值，那么平均值很容易计算为

![$$ mean(x)=\frac{\sum x}{100} $$](../images/482214_1_En_3_Chapter/482214_1_En_3_Chapter_TeX_Eque.png)

然而，在这种计算中可能存在一些估计误差，这可以使用如下所列的自举过程来改善:

1.  创建许多(例如 1000 个)带有替换的数据集随机子样本(意味着相同的值可以多次使用)。

2.  计算每个新的子样本的平均值。

3.  计算所有新平均值的平均值，并将其用作数据集的新估计平均值。

这个过程也可以扩展到估计其他度量，如标准偏差。

#### 引导聚合(bagging)

Bagging 是一个集合过程，它将从多个 ML 算法中收集的预测组合成一个比任何单个 ML 预测都更准确的预测。这基本上是一种协同预测方法，其中一组算法比该组中的任何单个成员都更强大。使用 bagging 减少了那些受分类和回归树(CART)影响的算法的方差。例如，决策树对用于创建树的选定数据很敏感。如果在不同于原始数据子集的另一个数据子集上训练，在一个数据子集上训练的特定树可以容易地提供不同的预测结果。以下通用装袋过程可用于提高 CART 预测的准确性:

1.  使用替换创建数据集的许多(例如，100 个)随机子样本。

2.  针对每个新样本训练一个购物车模型。

3.  给定一个新数据集，计算每个模型的平均预测值。

用于装袋过程的决策树必须是深度的，这意味着在每个叶节点上只附加少量的训练样本。这样的树将具有高方差，但也具有低偏差。请参考我之前在第 [2](2.html) 章中关于决策树的讨论来更新你对这些术语的理解。需要注意的关键点是，装袋只涉及样品的数量，在这种情况下，只涉及树的数量。这个过程也非常容忍过拟合，并且可以运行大量的模型而不会引入太多的误差，如果有的话。唯一的问题是准备模型和进行计算的时间。

#### 随机森林

随机森林是为了提高决策树装袋的性能而开发的。CART 生成的决策树的一个大问题是，它们很贪婪，因为它们使用贪婪算法选择要分割的变量，试图将误差最小化。这对于 CART 算法完全有意义，但是对于装袋过程是一个问题。决策树可能经常包含相似的数据结构，这可能导致后续预测中的高度相关性。如果根据相对不相关的子集(子树)进行预测，Bagging 的性能会更好。随机森林改变了学习子集的方式，以努力提高预测精度。为了实现这一目标，必须降低所有子集的相关性。

CART 算法的随机森林修改相当简单。在未修改的 CART 算法中，学习部分被允许测试所有变量(特征),以便选择最佳分裂点。随机森林改变了这一程序，使得学习部分现在被限制于要测试的变量的随机样本。可以在每个分割点测试的变量的数量也被设置为学习算法的参数 *m* 。对于随机森林分类问题，建议将 *m* 设为 *p* 的平方根，其中 *p* 为数据集中特征的数量。

#### 绩效评估和可变重要性

当产生自举样本时，将有数据样本被排除在子集之外。这些样本被称为袋外(OOB)样本。如果 OOB 样本是平均的，则可以对袋装模型进行精度估计。这种估计的性能通常被称为 OOB 性能估计。这种性能测量是可靠的测试误差估计，并且与交叉验证估计很好地相关。

当构建袋装决策树时，可以计算每个额外变量在每个分裂点的误差函数下降了多少。在回归问题中，这可能是误差平方和的下降，对于分类问题，这可能是基尼系数。

这些误差下降可以在所有决策树上平均，并输出以提供每个输入变量的重要性的估计。选择变量时误差下降越大，重要性越大。这些输出有助于识别与问题最相关的输入变量子集，以及可能从数据集中移除(最不相关)的候选变量。

### 引导重采样演示

本演示将展示引导过程的工作原理。首先创建一个伪随机数数据集，从中导出各种大小的子集。然后计算每个子集的平均值，然后将子集平均值与原始数据集总平均值进行比较。

这个测试的完整脚本名为 bootstrapDemo.py，可以从本书的配套网站上获得。脚本代码非常简单，除了已经包含的内容之外，不需要任何额外的注释。

```
# Import required libraries
from random import seed
from random import random
from random import randrange

# Create a random sub-set from the dataset with replacement.
def subsample(dataset, ratio=1.0):
      sample = list()
      n_sample = round(len(dataset) * ratio)
      while len(sample) < n_sample:
            index = randrange(len(dataset))
            sample.append(dataset[index])
      return sample

 # Calculate the mean of a list of numbers.
def mean(numbers):
      return sum(numbers) / float(len(numbers))

seed(1)
# Calculate the true mean.
# The original dataset has 20 rows with a single random
# number 0 to 9 in each row.
dataset = [[randrange(10)] for i in range(20)]
print('True Mean: %.3f' % mean([row[0] for row in dataset]))

# Calculate and display the estimated means from the different
# sized sub-sets.
ratio = 0.10
for size in [1, 10, 100]:
      sample_means = list()
      for i in range(size):
            sample = subsample(dataset, ratio)
            sample_mean = mean([row[0] for row in sample])
            sample_means.append(sample_mean)
      print('Samples=%d, Estimated Mean: %.3f' % (size, mean(sample_means)))

```

通过输入以下命令运行该脚本:

```
python bootstrapDemo.py

```

图 [3-25](#Fig25) 显示了运行该脚本的结果。

![../images/482214_1_En_3_Chapter/482214_1_En_3_Fig25_HTML.jpg](../images/482214_1_En_3_Chapter/482214_1_En_3_Fig25_HTML.jpg)

图 3-25

bootstrapDemo 结果

您应该能够看到，随着每个子集中样本数量的增加，估计平均值开始向真实平均值收敛。

### 装袋演示

本演示在脚本中使用了决策树数据模型。Bootstrap 数据聚合或 bagging 正在应用于模型，以提高整体预测准确性。

正在使用的数据集名为 sonar-data.csv，是从海洋环境中经过处理的声纳“探测”得到的数字记录的集合。每条记录都描述了声纳系统啁啾信号的回波特性。有 60 个输入变量或特征，它们是在不同发射角度的返回信号强度的测量值。这是一个二元分类问题，因为该模型旨在区分岩石(R)和矿石(M)。该数据集中有 208 条记录。所有变量都是连续的，标称范围为 0 到 1。输出变量(类)是代表矿山的“M”或代表岩石的“R”。脚本将这些变量分别转换为整数 1 或 0。

数据集命名为 sonar.all-data.csv，可以从`https://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+(Sonar,+Mines+vs.+Rocks)`下载。确保将下载文件的扩展名更改为 csv。

我将这个脚本命名为 baggingDemo.py，它可以从本书的配套网站上获得。此外，为了改变进度，我选择不包含任何进一步的解释性注释，因为该脚本已经超过 200 行，并且您应该已经从本章之前的讨论以及第 [2](2.html) 章关于决策树的广泛讨论中熟悉了许多代码段。

```
# Bagging Algorithm on the Sonar dataset
# Import required libraries
from random import seed
from random import randrange
from csv import reader

# Load a CSV file
def load_csv(filename):
      dataset = list()
      with open(filename, 'r') as file:
            csv_reader = reader(file)
            for row in csv_reader:
                   if not row:
                         continue
                   dataset.append(row)
      return dataset

# Convert string column to float
def str_column_to_float(dataset, column):
      for row in dataset:
            row[column] = float(row[column].strip())

# Convert string column to integer
def str_column_to_int(dataset, column):
      class_values = [row[column] for row in dataset]
      unique = set(class_values)
      lookup = dict()
      for i, value in enumerate(unique):
            lookup[value] = i
      for row in dataset:
            row[column] = lookup[row[column]]
      return lookup

# Split a dataset into k folds

def cross_validation_split(dataset, n_folds):
      dataset_split = list()
      dataset_copy = list(dataset)
      fold_size = int(len(dataset) / n_folds)
      for i in range(n_folds):
            fold = list()
            while len(fold) < fold_size:
                   index = randrange(len(dataset_copy))
                   fold.append(dataset_copy.pop(index))
            dataset_split.append(fold)
      return dataset_split

# Calculate accuracy percentage
def accuracy_metric(actual, predicted):
      correct = 0
      for i in range(len(actual)):
            if actual[i] == predicted[i]:
                   correct += 1
      return correct / float(len(actual)) * 100.0

# Evaluate an algorithm using a cross validation split

def evaluate_algorithm(dataset, algorithm, n_folds, *args):
      folds = cross_validation_split(dataset, n_folds)
      scores = list()
      for fold in folds:
            train_set = list(folds)
            train_set.remove(fold)
            train_set = sum(train_set, [])
            test_set = list()
            for row in fold:
                   row_copy = list(row)
                   test_set.append(row_copy)
                   row_copy[-1] = None
            predicted = algorithm(train_set, test_set, *args)
            actual = [row[-1] for row in fold]
            accuracy = accuracy_metric(actual, predicted)
            scores.append(accuracy)
      return scores

# Split a dataset based on an attribute and an attribute value
def test_split(index, value, dataset):
      left, right = list(), list()
      for row in dataset:
            if row[index] < value:
                   left.append(row)
            else:
                   right.append(row)
      return left, right

# Calculate the Gini index for a split dataset
def gini_index(groups, classes):
      # count all samples at split point
      n_instances = float(sum([len(group) for group in groups]))
      # sum weighted Gini index for each group
      gini = 0.0
      for group in groups:
            size = float(len(group))
            # avoid divide by zero
            if size == 0:
                   continue
            score = 0.0
            # score the group based on the score for each class
            for class_val in classes:
                   p = [row[-1] for row in group].count(class_val) / size
                   score += p * p
            # weight the group score by its relative size
            gini += (1.0 - score) * (size / n_instances)
      return gini

# Select the best split point for a dataset
def get_split(dataset):
      class_values = list(set(row[-1] for row in dataset))
      b_index, b_value, b_score, b_groups = 999, 999, 999, None
      for index in range(len(dataset[0])-1):
            for row in dataset:
            # for i in range(len(dataset)):
            # row = dataset[randrange(len(dataset))]
                   groups = test_split(index, row[index], dataset)
                   gini = gini_index(groups, class_values)
                   if gini < b_score:
                         b_index, b_value, b_score, b_groups = index, row[index], gini, groups
      return {'index':b_index, 'value':b_value, 'groups':b_groups}

# Create a terminal node value

def to_terminal(group):
      outcomes = [row[-1] for row in group]
      return max(set(outcomes), key=outcomes.count)

# Create child splits for a node or make terminal
def split(node, max_depth, min_size, depth):
      left, right = node['groups']
      del(node['groups'])
      # check for a no split
      if not left or not right:
            node['left'] = node['right'] = to_terminal(left + right)
            return
      # check for max depth
      if depth >= max_depth:
            node['left'], node['right'] = to_terminal(left), to_terminal(right)
            return
      # process left child
      if len(left) <= min_size:
            node['left'] = to_terminal(left)
      else:
            node['left'] = get_split(left)
            split(node['left'], max_depth, min_size, depth+1)
      # process right child
      if len(right) <= min_size:
            node['right'] = to_terminal(right)
      else:
            node['right'] = get_split(right)
            split(node['right'], max_depth, min_size, depth+1)

# Build a decision tree
def build_tree(train, max_depth, min_size):
      root = get_split(train)
      split(root, max_depth, min_size, 1)
      return root

# Make a prediction with a decision tree

def predict(node, row):
      if row[node['index']] < node['value']:
            if isinstance(node['left'], dict):
                   return predict(node['left'], row)
            else:
                   return node['left']
      else:
            if isinstance(node['right'], dict):
                   return predict(node['right'], row)
            else:
                   return node['right']

# Create a random subsample from the dataset with replacement
def subsample(dataset, ratio):
      sample = list()
      n_sample = round(len(dataset) * ratio)
      while len(sample) < n_sample:
            index = randrange(len(dataset))
            sample.append(dataset[index])
      return sample

# Make a prediction with a list of bagged trees
def bagging_predict(trees, row):
      predictions = [predict(tree, row) for tree in trees]
      return max(set(predictions), key=predictions.count)

# Bootstrap Aggregation Algorithm
def bagging(train, test, max_depth, min_size, sample_size, n_trees):
      trees = list()
      for i in range(n_trees):
            sample = subsample(train, sample_size)
            tree = build_tree(sample, max_depth, min_size)
            trees.append(tree)
      predictions = [bagging_predict(trees, row) for row in test]
      return(predictions)

# Test bagging on the sonar dataset
seed(1)
# load and prepare data
filename = 'sonar.all-data.csv'

dataset = load_csv(filename)
# convert string attributes to integers
for i in range(len(dataset[0])-1):
      str_column_to_float(dataset, i)
# convert class column to integers
str_column_to_int(dataset, len(dataset[0])-1)
# evaluate algorithm
n_folds = 5
max_depth = 6
min_size = 2
sample_size = 0.50
for n_trees in [1, 5, 10, 50]:
      scores = evaluate_algorithm(dataset, bagging, n_folds, max_depth, min_size, sample_size, n_trees)
      print('Trees: %d' % n_trees)
      print('Scores: %s' % scores)
      print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))

```

通过输入以下命令运行该脚本:

```
python baggingDemo.py

```

图 [3-26](#Fig26) 显示了运行该脚本的结果。

![../images/482214_1_En_3_Chapter/482214_1_En_3_Fig26_HTML.jpg](../images/482214_1_En_3_Chapter/482214_1_En_3_Fig26_HTML.jpg)

图 3-26

打包演示结果

五重数据集的临时精度分数将与总体总精度值一起显示。您可以看到，整体准确率值从 1 棵树的 71.7%慢慢增加到 50 棵树的 75.6%。这不是一个出色的性能，但尽管如此，使用装袋方法实现了轻微的整体改善。

使用装袋方法的困难之一是，即使建造了深树，装袋的树也是相似的。因此，使用这些树做出的任何预测也将是相似的。基于对不同样本的训练在树中寻找的任何高方差也被消除。这都是因为我之前讨论的决策树分裂算法中使用的贪婪算法。这个脚本试图通过限制训练过程中使用的样本大小来增加方差，但这种方法取得的成功有限。增加子集中方差的真正答案是使用随机森林算法，这是下一次演示的主题。

### 随机森林演示

决策树通常具有很高的方差，这使得任何预测结果都非常依赖于训练数据。在称为 bagging 的技术中，从训练数据的样本构建多个模型可以帮助减少这种差异，但树仍然保持高度相关。

随机森林是一个 bagging 扩展，除了基于训练数据的多个样本构建树之外，它还约束可用于构建树的要素，从而迫使树与众不同。在构建决策树的过程中，这种修改通常会带来性能上的好处。

本次演示使用的数据集与之前的装袋演示中使用的数据集相同。事实上，除了决策分割的计算方式之外，该脚本与前面的脚本几乎相同。随机森林修改导致搜索输入属性的样本，而不是搜索最小化总成本函数的属性。该属性样本可以随机选择，无需替换，这意味着在搜索最小化成本的分割点时，每个输入属性只需考虑一次。

基尼指数用于评估潜在分裂的成本。我参考了决策树部分的基尼指数讨论，以使自己对这个函数有所了解。

我将这个脚本命名为 randonForestDemo.py，它可以从本书的配套网站上获得。与前面的脚本一样，我选择不包含任何进一步的解释性注释，因为这个脚本已经超过 200 行，并且许多代码段与 baggingDemo 脚本相同。

```
# Random Forest Algorithm on Sonar Dataset
# Import required libraries
from random import seed
from random import randrange
from csv import reader
from math import sqrt

# Load a CSV file
def load_csv(filename):
      dataset = list()
      with open(filename, 'r') as file:
            csv_reader = reader(file)
            for row in csv_reader:
                   if not row:
                         continue
                   dataset.append(row)
      return dataset

# Convert string column to float
def str_column_to_float(dataset, column):
      for row in dataset:
            row[column] = float(row[column].strip())

# Convert string column to integer
def str_column_to_int(dataset, column):
      class_values = [row[column] for row in dataset]
      unique = set(class_values)
      lookup = dict()
      for i, value in enumerate(unique):
            lookup[value] = i
      for row in dataset:
            row[column] = lookup[row[column]]
      return lookup

# Split a dataset into k folds
def cross_validation_split(dataset, n_folds):
      dataset_split = list()
      dataset_copy = list(dataset)
      fold_size = int(len(dataset) / n_folds)
      for i in range(n_folds):
            fold = list()
            while len(fold) < fold_size:
                   index = randrange(len(dataset_copy))
                   fold.append(dataset_copy.pop(index))
            dataset_split.append(fold)
      return dataset_split

# Calculate accuracy percentage
def accuracy_metric(actual, predicted):
      correct = 0
      for i in range(len(actual)):
            if actual[i] == predicted[i]:
                   correct += 1
      return correct / float(len(actual)) * 100.0

# Evaluate an algorithm using a cross validation split

def evaluate_algorithm(dataset, algorithm, n_folds, *args):
      folds = cross_validation_split(dataset, n_folds)
      scores = list()
      for fold in folds:
            train_set = list(folds)
            train_set.remove(fold)
            train_set = sum(train_set, [])
            test_set = list()
            for row in fold:
                   row_copy = list(row)
                   test_set.append(row_copy)
                   row_copy[-1] = None
            predicted = algorithm(train_set, test_set, *args)
            actual = [row[-1] for row in fold]
            accuracy = accuracy_metric(actual, predicted)
            scores.append(accuracy)
      return scores

# Split a dataset based on an attribute and an attribute value
def test_split(index, value, dataset):
      left, right = list(), list()
      for row in dataset:
            if row[index] < value:
                   left.append(row)
            else:
                   right.append(row)
      return left, right

# Calculate the Gini index for a split dataset
def gini_index(groups, classes):
      # count all samples at split point
      n_instances = float(sum([len(group) for group in groups]))
      # sum weighted Gini index for each group
      gini = 0.0
      for group in groups:
            size = float(len(group))
            # avoid divide by zero
            if size == 0:
                   continue
            score = 0.0
            # score the group based on the score for each class
            for class_val in classes:
                   p = [row[-1] for row in group].count(class_val) / size
                   score += p * p
            # weight the group score by its relative size
            gini += (1.0 - score) * (size / n_instances)
      return gini

# Select the best split point for a dataset
def get_split(dataset, n_features):
      class_values = list(set(row[-1] for row in dataset))
      b_index, b_value, b_score, b_groups = 999, 999, 999, None
      features = list()
      while len(features) < n_features:
            index = randrange(len(dataset[0])-1)
            if index not in features:
                   features.append(index)
      for index in features:
            for row in dataset:
                   groups = test_split(index, row[index], dataset)
                   gini = gini_index(groups, class_values)
                   if gini < b_score:
                         b_index, b_value, b_score, b_groups = index, row[index], gini, groups
      return {'index':b_index, 'value':b_value, 'groups':b_groups}

# Create a terminal node value
def to_terminal(group):
      outcomes = [row[-1] for row in group]
      return max(set(outcomes), key=outcomes.count)

# Create child splits

for a node or make terminal
def split(node, max_depth, min_size, n_features, depth):
      left, right = node['groups']
      del(node['groups'])
      # check for a no split
      if not left or not right:
            node['left'] = node['right'] = to_terminal(left + right)
            return
      # check for max depth
      if depth >= max_depth:
            node['left'], node['right'] = to_terminal(left), to_terminal(right)
            return
      # process left child
      if len(left) <= min_size:
            node['left'] = to_terminal(left)
      else:
            node['left'] = get_split(left, n_features)
            split(node['left'], max_depth, min_size, n_features, depth+1)
      # process right child
      if len(right) <= min_size:
            node['right'] = to_terminal(right)
      else:
            node['right'] = get_split(right, n_features)
            split(node['right'], max_depth, min_size, n_features, depth+1)

# Build a decision tree
def build_tree(train, max_depth, min_size, n_features):
      root = get_split(train, n_features)
      split(root, max_depth, min_size, n_features, 1)
      return root

# Make a prediction

with a decision tree
def predict(node, row):
      if row[node['index']] < node['value']:
            if isinstance(node['left'], dict):
                   return predict(node['left'], row)
            else:
                   return node['left']
      else:
            if isinstance(node['right'], dict):
                   return predict(node['right'], row)
            else:
                   return node['right']

# Create a random subsample

from the dataset with replacement
def subsample(dataset, ratio):
      sample = list()
      n_sample = round(len(dataset) * ratio)
      while len(sample) < n_sample:
            index = randrange(len(dataset))
            sample.append(dataset[index])
      return sample

# Make a prediction with a list of bagged trees
def bagging_predict(trees, row):
      predictions = [predict(tree, row) for tree in trees]
      return max(set(predictions), key=predictions.count)

# Random Forest Algorithm
def random_forest(train, test, max_depth, min_size, sample_size, n_trees, n_features):
      trees = list()
      for i in range(n_trees):
            sample = subsample(train, sample_size)
            tree = build_tree(sample, max_depth, min_size, n_features)
            trees.append(tree)
      predictions = [bagging_predict(trees, row) for row in test]
      return(predictions)

# Test the random forest algorithm
seed(2)
# load and prepare data
filename = 'sonar.all-data.csv'
dataset = load_csv(filename)
# convert string attributes to integers
for i in range(0, len(dataset[0])-1):
      str_column_to_float(dataset, i)
# convert class column to integers
str_column_to_int(dataset, len(dataset[0])-1)
# evaluate algorithm
n_folds = 5
max_depth = 10
min_size = 1
sample_size = 1.0
n_features = int(sqrt(len(dataset[0])-1))
for n_trees in [1, 5, 10]:
      scores = evaluate_algorithm(dataset, random_forest, n_folds, max_depth, min_size, sample_size, n_trees, n_features)
      print('Trees: %d' % n_trees)
      print('Scores: %s' % scores)
      print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))

```

通过输入以下命令运行该脚本:

```
python randomForestDemo.py

```

图 [3-27](#Fig27) 显示了运行该脚本的结果。

![../images/482214_1_En_3_Chapter/482214_1_En_3_Fig27_HTML.jpg](../images/482214_1_En_3_Chapter/482214_1_En_3_Fig27_HTML.jpg)

图 3-27

randomForestDemo 结果

k 值为 5 用于交叉验证，给出每个折叠 208/5 = 41.6，或每次迭代评估刚好超过 40 个记录。深度树的最大深度为 10，每个节点的最小训练行数为 1。训练数据集的样本是以与原始数据集相同的大小创建的，这是随机森林算法的默认预期。在每个分割点考虑的特征数量被设置为 sqrt(num_features)或 sqrt(60)=7.74，四舍五入为 7 个特征。

对尺寸为 1、5 和 10 的采油树套件进行了评估比较，结果显示，随着采油树数量的增加，精确度也在增加。随着树套件的增加，平均准确度分数从 62.4%增加到 81.0%。最终得分比装袋演示提高了 5%以上，这表明随机森林改造已如预期那样发挥作用。