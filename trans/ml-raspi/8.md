# 8.使用 CNN 和 MLPs 进行医学研究的预测

在前一章，我向你介绍了人工神经网络和 CNN 是如何被用来做预测的。讨论的预测与数值数据集严格相关，不直接涉及任何输入图像。在这一章中，我将讨论如何使用带有 CNN 的图像进行医学诊断预测。目前，这个研究领域非常重要，许多人工智能研究人员正在寻求可行的研究路线来推进这一主题。事实上，我在本章末尾增加了一个面向数据的 MLP 演示，希望向您展示纯数据项目在这个领域仍然是相关的。

这一章的大部分内容都是从 Adrian rose Brock 2019 年 2 月题为“使用 Keras 和深度学习进行乳腺癌分类”的博客中获得的灵感。正如阿德里安在他的博客中指出的那样，他的大多数读者“都认识曾经患过癌症的人。”我确信这种说法对本书的大多数读者来说是真实的。希望这一章的内容将为潜在的癌症患者提供一些希望，即在使用 AI，ML 和 DL 对某些类型的癌症进行早期检测方面正在取得真正的进展。

## 零件目录表

本章演示需要一个标准的 RasPi 桌面配置。

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"></colgroup> 
| 

项目

 | 

模型

 | 

量

 | 

来源

 |
| --- | --- | --- | --- |
| 树莓 Pi 4 | 型号 B(配有 2gb 或 4 GB 内存的 RasPi 4) | one | mcmelectronics.comadafruit.comdigikey.commouser.comfarnell.com |
| 微型 SD 卡 | 32 GB，10 级或更大 | one | amazon.com |
| USB 键盘 | 亚马逊基础版 | one | amazon.com |
| USB 鼠标 | 亚马逊基础版 | one | amazon.com |
| HDMI 监视器 | 商品 | one | amazon.com |

### 注意

要使 RasPi 4 能够编译和训练章节演示中使用的 CNN 模型，至少需要 2 GB 的 RAM。只有 1 GB 内存的 RasPis 在演示中不会成功。

需要使用 32 GB 的 micro SD 卡，因为 OpenCV、Keras、TensorFlow、演示中使用的数据集以及虚拟 Python 环境中最新的 Raspbian 操作系统的总内存要求超过 16 GB。

## 下载乳腺癌组织学图像数据集

组织学，又称显微解剖学或显微解剖学，是[生物学](https://en.wikipedia.org/wiki/Biology)的分支，研究生物[组织](https://en.wikipedia.org/wiki/Tissue_%2528biology%2529)的显微[解剖学](https://en.wikipedia.org/wiki/Anatomy)。具体来说，在这个问题领域中引用的组织学是取自具有和不具有恶性乳腺癌细胞的患者的显微图像。

本演示中使用的数据集用于浸润性导管癌(IDC)。该数据集可从以下网址下载

*   `www.kaggle.com/paultimothymooney/breast-histopathology-images`

这是一个非常大的下载文件(1.6 GB)，需要解压缩两次才能访问原始图像。最终提取的数据集大小超过 2.4 GB。

以下是数据集下载网站的上下文和内容描述:

`Context:`

浸润性导管癌(IDC)是所有乳腺癌中最常见的亚型。为了给整个样本分配一个侵略性等级，病理学家通常关注包含 IDC 的区域。因此，自动侵袭性分级的常见预处理步骤之一是在整个载片内描绘 IDC 的准确区域。

`Content:`

原始数据集由 162 个乳腺癌(BCa)标本的整片载玻片图像组成，以 40 倍扫描。从中提取了 277，524 个大小为 50 x 50 的碎片(198，738 个 IDC 阴性和 78，786 个 IDC 阳性)。每个补片的文件名格式为 u_xX_yY_classC.png。例如，10253 _ idx 5 _ X 1351 _ Y 1101 _ class 0 . png，其中 u 是患者 ID (10253_idx5)，X 是该补片裁剪位置的 X 坐标，Y 是该补片裁剪位置的 Y 坐标，C 表示类别，其中 0 表示非 IDC，1 表示 IDC。

总之，根据前面的描述，有

*   277，524 个 50×50 像素的图像块

*   78，786 个阳性样本(即，表明在贴片中检测到乳腺癌)

*   198，738 例阴性(即未检测到乳腺癌)

根据我对补丁坐标样本的检查，我已经推断出原始的整个安装幻灯片图像的像素大小必须是 1600 x 1600。这意味着，如果没有重叠的补丁，从任何给定的幻灯片中最多可以提取 1024 个补丁。这意味着整个数据集具有最大患者时间数 1024 的潜力，假设每个患者具有癌症和无癌症斑块。我将很快向您展示这项研究中有 837 名患者，这意味着可能最多有 857，088 个补丁图像。实际上，数据集中有 277，524 幅图像，这意味着只有 32%的潜在碎片被采样。虽然这个统计数据对于统计学家来说对于任何预测的整体“质量”可能是有意义的，但是出于演示的目的，我将选择忽略它。

然而，数据集中的图像类型明显不平衡。负面类形象是正面类形象的两倍。这是将在数据预处理时处理的事情。

图 [8-1](#Fig1) 显示了数据集中正负图像的一小部分。

![../images/482214_1_En_8_Chapter/482214_1_En_8_Fig1_HTML.jpg](../images/482214_1_En_8_Chapter/482214_1_En_8_Fig1_HTML.jpg)

图 8-1

数据集图像的代表性样本

在名为 IDC_regular_ps50_idc5 的主目录下有 837 个子目录。接下来，您需要将该目录重命名为 dataset，以使其与我稍后将讨论的配置脚本兼容。您可以使用 cp 命令或使用文件管理器工具来进行更改。我几乎总是使用文件管理器，因为它很方便。

图 [8-2](#Fig2) 是运行`tree`命令的结果，在这里你可以看到 837 个子目录的一小部分。

![../images/482214_1_En_8_Chapter/482214_1_En_8_Fig2_HTML.jpg](../images/482214_1_En_8_Chapter/482214_1_En_8_Fig2_HTML.jpg)

图 8-2

`tree`命令用于数据集主目录

每个子目录包含给定患者的正面和负面图像，其数字 id 是子目录的名称。在每个子目录中，还有两个名为 0 和 1 的子目录。0 目录包含图像，其中没有检测到任何癌细胞。1 目录具有包含检测到的癌细胞的图像。

本演示的最终目标是训练一个 CNN 模型来区分阳性和阴性图像类别，从而预测给定患者是否患有 IDC。

### 准备项目环境

在尝试任何项目脚本之前，第一步是设置一个 Python 虚拟环境。我在以前的演示中使用过这种环境类型，并将在本章的演示中继续使用。如果需要复习，请参考第 [1](1.html) 章，了解如何创建虚拟环境。

为了支持本章中使用的脚本，必须安装五个依赖项。如果您一直在重复前一章的演示，那么您可能已经安装了大部分(如果不是全部的话)。在任何情况下，您需要做的就是输入以下命令，以确保安装了所需的依赖项:

```
pip install numpy opencv-contrib-python
pip install pillow
pip install tensorflow keras
pip install imutils
pip install scikit-learn matplotlib

```

如果没有安装 OpenCV，使用`imutils`包会有问题。虽然 OpenCV 函数没有被任何章节脚本直接调用，但是`imutils`确实与这个包有一些内嵌的依赖关系。如果你需要安装 OpenCV 的指导，请回头参考第 [2](2.html) 章。

一旦建立了虚拟环境，您就可以开始处理第一个脚本了。

#### 配置脚本

以下脚本设置了适当的目录路径，并定义了用于训练和验证的数据量。该脚本名为 config_IDC.py，可从本书的配套网站获得:

```
# Import the required library
import os

# Initialize the path to the input image directory.
ORIG_INPUT_DATASET = "dataset"

# Initialize the base path to the directory that contain the
# images remaining after the training and testing splits.
BASE_PATH = "datasets/idc"

# Define the training, validation, and testing directory paths.
TRAIN_PATH = os.path.sep.join([BASE_PATH, "training"])
VAL_PATH = os.path.sep.join([BASE_PATH, "validation"])
TEST_PATH = os.path.sep.join([BASE_PATH, "testing"])

# Define the data split

that will be used for training.
TRAIN_SPLIT = 0.8

# Define the data split that will be used for validation.
VAL_SPLIT = 0.1

# Display to user that configuration is complete.
print('[INFO]: Configuration complete')

```

这个配置脚本将在下一个将要讨论的脚本运行时运行。

演示的下一步是构建数据集。

#### 构建数据集

构建数据集部分包括将原始数据集分成三个更小的数据集，如图 [8-3](#Fig3) 所示。

![../images/482214_1_En_8_Chapter/482214_1_En_8_Fig3_HTML.jpg](../images/482214_1_En_8_Chapter/482214_1_En_8_Fig3_HTML.jpg)

图 8-3

数据集拆分

您首先应该意识到的一点是，原始数据集的大小略大于 5.8 GB。这对于一个 4 GB 的 RasPi 4 来说显然太大了，我用它来运行这个演示。为了避免这个问题，将使用 Keras ImageDataGenerator 类从拆分的数据集创建较小的批处理，这将消除在 RAM 中加载整个原始数据集的需求。但是，必须首先拆分和重组原始数据集。

该脚本名为 build_IDC_dataset.py，将用于组织原始数据集。该脚本使用配置常量，这些常量是在 config_IDC 脚本开始运行时设置的。该脚本可从该书的配套网站上获得。清单后面有一些解释性注释。

```
# Import the required libraries
from config_IDC import config_IDC
from imutils import paths
import random
import shutil
import os

# Grab the paths to all input images in the original input
# directory and shuffle them.
imagePaths = list(paths.list_images(config_IDC.ORIG_INPUT_DATASET))
random.seed(42)
random.shuffle(imagePaths)

# Compute the training and testing split.
i = int(len(imagePaths) * config_IDC.TRAIN_SPLIT)
trainPaths = imagePaths[:i]
testPaths = imagePaths[i:]

# Use part of the training data for validation.
i = int(len(trainPaths) * config.VAL_SPLIT)
valPaths = trainPaths[:i]
trainPaths = trainPaths[i:]

# Define the datasets that are built.
datasets = [
    ("training", trainPaths, config.TRAIN_PATH),
    ("validation", valPaths, config.VAL_PATH),
    ("testing", testPaths, config.TEST_PATH)
]

# Loop over the datasets.
for (dType, imagePaths, baseOutput) in datasets:
    # Show which data split created
    print("[INFO] building '{}' split".format(dType))

    # If the base output directory does not exist,
    # create it.
    if not os.path.exists(baseOutput):
        print("[INFO] 'creating {}' directory".format(baseOutput))
        os.makedirs(baseOutput)

    # Loop over the input image paths.
    for inputPath in imagePaths:
        # Extract the filename of the input image and extract
        # the class label ("0" for "negative" and "1" for
        # "positive").
        filename = inputPath.split(os.path.sep)[-1]
        label = filename[-5:-4]

        # Build the path to the label directory.
        labelPath = os.path.sep.join([baseOutput, label])

        # If the label output directory does not exist, create
        # it.
        if not os.path.exists(labelPath):
            print("[INFO] 'creating {}' directory".format(labelPath))
            os.makedirs(labelPath)

        # Construct the path to the destination image and then
        # copy the image itself.
        p = os.path.sep.join([labelPath, filename])
        shutil.copy2(inputPath, p)

```

解释性注释:

在 config_IDC 脚本开始运行后，将收集配置设置和路径。Python 随机库用于随机打乱路径。shutil 库用于复制图像，os 库用于连接路径和创建目录。

接下来，所有数据集图像路径被打乱以提高随机性，从而获得更好的最终结果。然后计算训练/测试分割的索引，并通过对图像路径进行切片来构建训练路径和测试路径。列车路径被进一步分割以保留一部分用于验证。

然后定义一个名为数据集的列表。这个列表中有三个元组，每个元组都包含将所有图像路径组织成训练、验证和测试数据所需的信息。

然后开始对所有数据集进行迭代。循环中会出现以下步骤:

*   创建基本输出目录(仅一次)。

*   在当前分割中的所有输入图像上发生嵌套循环，其中
    *   从输入路径中提取文件名，从文件名中提取类标签。

    *   构造 labelPath 并创建标签输出目录(仅一次)。

    *   每个文件都被复制到其目标目录中。

#### 运行构建数据集脚本

通过输入以下命令运行 build_IDC_datascript:

```
python build_IDC_dataset.py

```

图 [8-4](#Fig4) 显示了运行脚本的结果。

![../images/482214_1_En_8_Chapter/482214_1_En_8_Fig4_HTML.jpg](../images/482214_1_En_8_Chapter/482214_1_En_8_Fig4_HTML.jpg)

图 8-4

运行 build_IDC_dataset 脚本后的结果

接下来，我在新构建的数据集目录上运行 tree 命令，以确认所需的数据集是按照预期构建的。图 [8-5](#Fig5) 显示了运行树命令的结果。

![../images/482214_1_En_8_Chapter/482214_1_En_8_Fig5_HTML.jpg](../images/482214_1_En_8_Chapter/482214_1_En_8_Fig5_HTML.jpg)

图 8-5

应用于数据集目录的树命令

一旦数据集被设置好，现在是时候讨论 CNN 模型了。

#### CNN 模型

本演示中使用的模型主要基于 VGGNet 风格的模型，我在前一章中讨论过。有多个堆叠卷积层，使用 3 x 3 滤波器，典型的 VGG 模型。然而，这个 VGG 模型使用深度方向可分离的卷积层，而不是标准的卷积层。在不涉及任何细节的情况下，我将简单地说，与常规卷积相比，深度方向可分离卷积是一种计算效率更高的过程。

这种 CNN 模型被命名为 CancerNet，鉴于它在根据患者的组织学研究预测患者是否患有该疾病方面的作用，这似乎是合适的。图 [8-6](#Fig6) 显示了 CancerNet 的结构。

![../images/482214_1_En_8_Chapter/482214_1_En_8_Fig6_HTML.png](../images/482214_1_En_8_Chapter/482214_1_En_8_Fig6_HTML.png)

图 8-6

癌网结构

从这个图中可以明显看出，这个 CNN 网络是复杂的，有许多层。这个 CNN 确实是一个深层网络的典型代表。图中显示了 31 层，您可以通过计算在下面的类定义中添加到模型的层数来确认。

下面的类定义文件命名为 cancernet.py，可从本书的配套网站获得:

```
# Import the required libraries
from keras.models import Sequential
from keras.layers.normalization import BatchNormalization
from keras.layers.convolutional import SeparableConv2D
from keras.layers.convolutional import MaxPooling2D
from keras.layers.core import Activation
from keras.layers.core import Flatten
from keras.layers.core import Dropout
from keras.layers.core import Dense
from keras import backend as K

class CancerNet:
    @staticmethod
    def build(width, height, depth, classes):
        # Initialize the model along with the input shape to
        # be "channels last" and the channels dimension itself
        model = Sequential()
        inputShape = (height, width, depth)
        chanDim = -1

        # If using "channels first", update the input shape
        # and channels dimension.
        if K.image_data_format() == "channels_first":
            inputShape = (depth, height, width)
            chanDim = 1

        # CONV => RELU => POOL
        model.add(SeparableConv2D(32, (3, 3), padding="same",
            input_shape=inputShape))
        model.add(Activation("relu"))
        model.add(BatchNormalization(axis=chanDim))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        model.add(Dropout(0.25))

        # (CONV => RELU => POOL) * 2
        model.add(SeparableConv2D(64, (3, 3), padding="same"))
        model.add(Activation("relu"))
        model.add(BatchNormalization(axis=chanDim))
        model.add(SeparableConv2D(64, (3, 3), padding="same"))
        model.add(Activation("relu"))
        model.add(BatchNormalization(axis=chanDim))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        model.add(Dropout(0.25))

        # (CONV => RELU => POOL) * 3
        model.add(SeparableConv2D(128, (3, 3), padding="same"))
        model.add(Activation("relu"))
        model.add(BatchNormalization(axis=chanDim))
        model.add(SeparableConv2D(128, (3, 3), padding="same"))
        model.add(Activation("relu"))
        model.add(BatchNormalization(axis=chanDim))
        model.add(SeparableConv2D(128, (3, 3), padding="same"))
        model.add(Activation("relu"))
        model.add(BatchNormalization(axis=chanDim))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        model.add(Dropout(0.25))

        # First (and only) set of FC => RELU layers
        model.add(Flatten())
        model.add(Dense(256))
        model.add(Activation("relu"))
        model.add(BatchNormalization())
        model.add(Dropout(0.5))

        # Softmax classifier
        model.add(Dense(classes))
        model.add(Activation("softmax"))

        # Return the constructed network architecture
        return model

```

该模型的结构是连续的，这意味着层是以连续的方式添加的。该模型中使用的大多数层类型都在第 [7 章](7.html) CNN 模型中使用，除了 SeparableConv2D 层，它实现了前面提到的深度方向可分离卷积。

在模型中定义了三个深度方向 _CONV => RELU = >池块，增加了堆叠并应用了过滤器。还添加了 BatchNormalization 和 Dropout 层。

FC => RELU 层和 softmax 分类器完成网络。softmax 分类器的输出将为每个预测类创建预测百分比。

该模型的结构是一个可调用的方法，这意味着实例化的模型将返回到训练脚本。

#### 培训和测试脚本

培训脚本是关键部分，它最终将整个项目联系在一起。这个脚本被命名为 train_IDC_model.py，它不仅训练模型，还测试模型的预测准确性。该脚本可从该书的配套网站上获得。清单后面有解释性注释。

```
# Set the matplotlib backend so figures can be saved in the
# background
import matplotlib
matplotlib.use("Agg")

# Import the required libraries
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import LearningRateScheduler
from keras.optimizers import Adagrad
from keras.utils import np_utils
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from cancernet import CancerNet
import config_IDC as config
from imutils import paths
import matplotlib.pyplot as plt
import numpy as np
import argparse
import os

# Construct the argument parser and parse the arguments.
ap = argparse.ArgumentParser()
ap.add_argument("-p", "--plot", type=str, default="plot.png",
    help="path to output loss/accuracy plot")
args = vars(ap.parse_args())

# Initialize the number of epochs, initial learning rate, and
# batch size.
NUM_EPOCHS = 40
INIT_LR = 1e-2
BS = 32

# Determine the total number of image paths in training,
# validation, and testing directories.
trainPaths = list(paths.list_images(config.TRAIN_PATH))
totalTrain = len(trainPaths)
totalVal = len(list(paths.list_images(config.VAL_PATH)))
totalTest = len(list(paths.list_images(config.TEST_PATH)))

# Account for skew in the labeled data
trainLabels = [int(p.split(os.path.sep)[-2]) for p in trainPaths]
trainLabels = np_utils.to_categorical(trainLabels)
classTotals = trainLabels.sum(axis=0)
classWeight = classTotals.max() / classTotals

# Initialize the training data augmentation object
trainAug = ImageDataGenerator(
    rescale=1 / 255.0,
    rotation_range=20,
    zoom_range=0.05,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.05,
    horizontal_flip=True,
    vertical_flip=True,
    fill_mode="nearest")

# Initialize the validation (and testing) data augmentation
# object.
valAug = ImageDataGenerator(rescale=1 / 255.0)

# Initialize the training generator.
trainGen = trainAug.flow_from_directory(
    config.TRAIN_PATH,
    class_mode="categorical",
    target_size=(48, 48),
    color_mode="rgb",
    shuffle=True,
    batch_size=BS)

# Initialize the validation generator.
valGen = valAug.flow_from_directory(
    config.VAL_PATH,
    class_mode="categorical",
    target_size=(48, 48),
    color_mode="rgb",
    shuffle=False,
    batch_size=BS)

# Initialize the testing generator.
testGen = valAug.flow_from_directory(
    config.TEST_PATH,
    class_mode="categorical",
    target_size=(48, 48),
    color_mode="rgb",
    shuffle=False,
    batch_size=BS)

# Initialize the CancerNet model and compile it.
model = CancerNet.build(width=48, height=48, depth=3,
    classes=2)
opt = Adagrad(lr=INIT_LR, decay=INIT_LR / NUM_EPOCHS)
model.compile(loss="binary_crossentropy", optimizer=opt,
    metrics=["accuracy"])

# Fit the model.
H = model.fit_generator(
    trainGen,
    steps_per_epoch=totalTrain // BS,
    validation_data=valGen,
    validation_steps=totalVal // BS,
    class_weight=classWeight,
    epochs=NUM_EPOCHS)

# Reset the testing generator and then use the trained model to
# make predictions on the data.
print("[INFO] evaluating network...")
testGen.reset()
predIdxs = model.predict_generator(testGen,
    steps=(totalTest // BS) + 1)

# For each image in the testing set find the index of the
# label with corresponding largest predicted probability.
predIdxs = np.argmax(predIdxs, axis=1)

# Show a nicely formatted classification report.
print(classification_report(testGen.classes, predIdxs,
    target_names=testGen.class_indices.keys()))

# Compute the confusion matrix and use it to derive the raw
# accuracy, sensitivity, and specificity.
cm = confusion_matrix(testGen.classes, predIdxs)
total = sum(sum(cm))
acc = (cm[0, 0] + cm[1, 1]) / total
sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])
specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])

# Show the confusion matrix, accuracy, sensitivity, and
# specificity.
print(cm)
print("acc: {:.4f}".format(acc))
print("sensitivity: {:.4f}".format(sensitivity))
print("specificity: {:.4f}".format(specificity))

# Plot the training loss and accuracy.
N = NUM_EPOCHS
plt.style.use("ggplot")
plt.figure()
plt.plot(np.arange(0, N), H.history["loss"], label="train_loss")
plt.plot(np.arange(0, N), H.history["val_loss"], label="val_loss")
plt.plot(np.arange(0, N), H.history["acc"], label="train_acc")
plt.plot(np.arange(0, N), H.history["val_acc"], label="val_acc")
plt.title("Training Loss and Accuracy on Dataset")
plt.xlabel("Epoch #")
plt.ylabel("Loss/Accuracy")
plt.legend(loc="lower left")
plt.savefig(args["plot"])

```

解释性评论如下:

此脚本使用了以下库，并对每个库进行了简要说明:

1.  matplotlib——这是科学绘图包，是 Python 事实上的标准。该库设置为使用“Agg”后端将训练图保存到磁盘。

2.  Keras–使用 Keras ImageDataGenerator、LearningRateScheduler、Adagrad optimizer 和 np_utils。

3.  sk learn–使用分类报告和混淆矩阵的 scikit-learn 实现。

4.  config _ IDC–使用这个脚本配置来获取三个数据分割的路径。

5.  cancernet–培训和评估所需的 cancer net 的类别定义。

6.  imutils–使用路径模块获取每个图像的路径。

7.  numpy–使用 Python 进行数值处理时需要。

8.  arg parse–用于解析命令行参数。

9.  操作系统–用于访问操作系统级命令。

这个脚本可以使用一个可选的命令行参数，那就是- plot。当运行时在终端中提供该参数时，脚本将使用该名称将绘图保存到磁盘。如果您没有用绘图文件名指定命令行参数，将使用默认名称 plot.png。

训练时期的数量、初始学习率和批量大小在解析器代码之后定义。

在这些定义之后，确定了训练、验证和测试目录中的映像路径的总数。

然后为训练数据计算一个`classWeight`参数，以说明类别不平衡/偏斜。当训练数据集中的数据元素份额不成比例时，就会出现类别不平衡。正如我在本章开始时提到的，这个项目就是这种情况。良性样本图像是恶性样本图像的两倍多。类别不平衡会导致模型出现两个问题:

*   永远不要为不平衡的类获得优化的结果，因为模型从未得到充分的训练。

*   验证变得困难，因为在一个或多个类被严重低估的情况下，跨类的错误陈述。

Keras fit 函数使用`classWeight`参数来帮助校正数据集的不平衡。我不确定这是如何在函数中实现的。

接下来的代码部分处理数据扩充，这是一种正则化形式。正则化对于几乎所有的 DL 实验都很重要，有助于模型的泛化。在将训练数据集传递到网络进行训练之前，此函数会干扰训练数据集，稍微修改其内容。这种方法部分减少了收集额外训练数据的需要。

数据扩充对象`trainAug`首先被初始化。随机旋转、移位、剪切和翻转随后在应用时被应用到训练数据集。图像像素强度也被`trainAug`对象重新调整到范围 0 到 1。

接下来，初始化训练、验证和测试生成器。每个发生器根据需要提供一批图像，由`batch_size`参数指定。

然后用 Adagrad 优化器对模型进行初始化。回想一下，我在前一章中提到了 Keras 提供的各种优化器。Adagrad 优化器是用于基于梯度的优化的算法，其使学习率(lr)适应参数，对与频繁出现的特征相关联的参数执行较小的更新(即，低 lr ),对与不频繁出现的特征相关联的参数执行较大的更新(即，高 lr)。因此，它非常适合处理稀疏数据，至少对于一个类来说，这就是训练数据集的情况。Adagrad 优化器在其操作中使用初始 lr 和衰减 lr。

然后使用`binary_crossentropy`损失函数编译模型，因为只有两个数据类。

Keras fit_generator 方法启动训练过程。通过使用这种方法，训练图像数据可以驻留在磁盘上并批量应用，而不是在整个训练过程中将整个数据集放在 RAM 中。这种方法是 RasPi 系统可能处理如此大的训练数据集的唯一方式。

一旦训练完成，就对所有测试数据进行预测。在预测过程中再次使用生成器对象。

收集每个样本的最高预测指数，然后显示分类报告。

然后生成混淆矩阵。该矩阵显示了模型的准确性、敏感性和特异性。

最后，生成由训练/验证损失和训练/验证准确度组成的训练历史图。这些是时间图，允许检测过拟合/欠拟合。

#### 运行培训和测试脚本

### 注意

这个脚本的计算量非常大。我确定使用 RasPi 4 系统只需要 2.7 小时就可以完成 1 个纪元。如果你选择做 40 个纪元，就像最初的博客一样，那么等待大约 108 个小时直到它完成。那就是 4.5 天！另一种方法是将历元的数量减少到更容易管理的数量，比如 8，这仍然意味着您需要等待大约 21 个小时才能完成。据我估计，精确度的损失最多只有 0.5%到 1.0%，我认为这是一个可以接受的折衷方案，可以节省将近 4 天的等待时间。运行这个演示让我相信了支持 GPU 的处理的有用性。

我在 RasPi 4 系统(4 GB)上运行了 train_IDC_model 脚本，使用了默认的配置值，只是将时期数设置为 8。我不确定这个带有训练集的脚本是否能在标准的 RasPi 3 系统上运行。

通过输入以下命令运行该脚本:

```
python train_IDC_model.py

```

图 [8-7](#Fig7) 显示了脚本开始运行时的结果。

![../images/482214_1_En_8_Chapter/482214_1_En_8_Fig7_HTML.jpg](../images/482214_1_En_8_Chapter/482214_1_En_8_Fig7_HTML.jpg)

图 8-7

开始运行脚本

21.5 小时后，脚本完成，最终结果如图 [8-8](#Fig8) 所示。

![../images/482214_1_En_8_Chapter/482214_1_En_8_Fig8_HTML.jpg](../images/482214_1_En_8_Chapter/482214_1_En_8_Fig8_HTML.jpg)

图 8-8

运行培训 IDC 模型脚本后的结果

图中显示的混淆矩阵(误差矩阵)复制在表 [8-1](#Tab1) 中。如果需要复习，请参考第 [1](1.html) 章关于混淆矩阵的讨论。

表 8-1

CNN 混淆矩阵

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
|   | 

预测

 |
| --- | --- |
| **实际** | Zero | one |
| Zero | 35055(总氮) | 4788 (FP) |
| one | 3455(新生力量) | 12207 (TP) |

在哪里

0 =未检测到癌细胞(阴性)

1 =检测到癌细胞(阳性)

有关 TN、FN、TP 和 FP 的定义，请参见以下数据。

图 [8-9](#Fig9) 包含训练损失和精确度的时间图。这些图只是每个时期完成后的临时结果。

![../images/482214_1_En_8_Chapter/482214_1_En_8_Fig9_HTML.jpg](../images/482214_1_En_8_Chapter/482214_1_En_8_Fig9_HTML.jpg)

图 8-9

训练损失和准确度的时间图

在这些情节中有几个事项需要注意。首先，在第一个时期完成后，训练和验证的精度图收敛，并在所有剩余时期保持在一起。这表明 CNN 模型几乎没有过度/不足之处。该模型似乎非常适合这个数据集。下一个要注意的事项是，第二个历元完成后，精度图显示为水平，这证实了我的假设，即 8 个历元足以产生可靠的结果。此外，查看损失图显示，它们已经稳定在随着更多时期仅略有变化的值附近，这证实了最终结果的稳定性。

#### 通过讨论灵敏度、特异性和 AUROC 曲线来评估结果

看图，可以看到模型达到了 85.15%的准确率；然而，该准确度值受到“无癌症”分类正确识别率为 91%这一事实的严重影响。

计算结果的敏感性和特异性也有助于更好地理解模型的性能。在开始度量讨论之前，我需要定义一些术语，并提供一些等式作为背景。为了下一次讨论的目的，假设所提到的模型用于预测患者是否患有疾病。阳性结果意味着疾病存在，阴性结果意味着没有疾病。

真阳性(TP)-真阳性是模型正确预测阳性类别的结果。

真阴性(TN)-真阴性是模型正确预测阴性类别的结果。

假阳性(FP)-假阳性是模型错误预测阳性类别的结果。

假阴性(FN))–假阴性是模型错误预测阴性类别的结果。

真阳性率(TPR)/灵敏度/回忆方程式:

![$$ TPR=\frac{TP}{TP+ FN} $$](../images/482214_1_En_8_Chapter/482214_1_En_8_Chapter_TeX_Equa.png)

特异性方程:

![$$ Specificity=\frac{TN}{TN+ FP} $$](../images/482214_1_En_8_Chapter/482214_1_En_8_Chapter_TeX_Equb.png)

假阳性率(FPR)方程:

![$$ FPR=1- Specificity $$](../images/482214_1_En_8_Chapter/482214_1_En_8_Chapter_TeX_Equc.png)

![$$ =\frac{FP}{TN+ FP} $$](../images/482214_1_En_8_Chapter/482214_1_En_8_Chapter_TeX_Equd.png)

假阴性率(FNR)方程:

![$$ FNR=\frac{FN}{TP+ FN} $$](../images/482214_1_En_8_Chapter/482214_1_En_8_Chapter_TeX_Eque.png)

在演示模型中，灵敏度测量了 TP 的比例，该比例也以 87.98%的比率被预测为阳性。相反，特异性测量的 TN 率为 77.94%。重要的是要小心假阴性。当一个人实际上是“癌症阳性”时，你绝对不想把他归类为“无癌症”

FPR 也很重要，因为你不想错误地将患者归类为“癌症阳性”，然后在他们并不真正需要的时候让他们接受广泛而可能痛苦的治疗。

任何人工智能从业者都必须注意灵敏度和特异性之间的平衡，尤其是在涉及到 DL 和医疗保健/健康治疗时。

##### 什么是敏感？

敏感度是预测为阳性(TP)的实际阳性病例的比例的度量。敏感性的另一个名称是回忆，这意味着将有另一部分实际阳性病例，其将被错误地预测为阴性，并可被称为 FN。这也以 FNR 的形式表示。灵敏度和假阴性率(FNR)之和将始终为 1。当一个模型被用来预测一个人是否患有疾病时，这个概念可能更容易理解。敏感性是对被正确预测为患有疾病的人患有疾病的比例的度量。换句话说，不健康的人实际上被预测为不健康。

理想情况下，该模型应寻求低 FNs，因为它可能会危及生命。

较高的灵敏度值意味着较高的 TPs 值和较低的 FNs 值。较低的敏感度值意味着较低的 TPs 值和较高的 FNs 值。出于医疗保健和金融方面的原因，需要具有高灵敏度的模型。

##### 什么是特异性？

特异性被定义为预测为阴性(TN)的实际阴性的比例。这意味着将会有另一部分的实际负值被预测为正值，可以称为 FP。这个比例也被称为 FPR。特异性和 FPR 的总和总是 1。当一个模型被用来预测一个人是否患有疾病时，这个概念可能更容易理解。特异性是对未患病人群中被正确预测为未患病人群的比例的度量。换句话说，特异性是当一个健康的人实际上被预测为健康时。

更高的特异性值意味着更高的 TN 值和更低的 FPR。特异性的较低值意味着 TN 的较低值和 FP 的较高值。

##### 敏感性和特异性有什么区别，如何使用？

敏感性测量用于确定被正确预测的实际阳性病例的比例。特异性测量用于确定被正确预测的实际阴性病例的比例。

灵敏度和特异性测量可用于绘制曲线下面积-受试者操作特征(AUC-ROC)曲线。AUC-ROC(也称为 AUROC)曲线是说明二元分类器系统在其辨别阈值变化时的诊断能力的图表。ROC 是概率曲线，AUC 表示类别可分性的程度或度量。它告诉我们模型在多大程度上能够区分不同的类。AUC 值越高，模型预测 0 为 0、1 为 1 的能力越强。以此类推，AUC 值越高，该模型在区分患病患者和未患病患者方面就越好。

在不同的阈值设置下，通过将 y 轴上的真阳性率(TPR)相对于 x 轴上的假阳性率(FPR)作图来创建 AUROC 曲线。FPR 也称为下降或虚警概率，可以计算为 1 TPR。因此，AUROC 曲线是灵敏度与沉降的函数关系。图 [8-10](#Fig10) 显示了通用 AUROC 曲线。

![../images/482214_1_En_8_Chapter/482214_1_En_8_Fig10_HTML.jpg](../images/482214_1_En_8_Chapter/482214_1_En_8_Fig10_HTML.jpg)

图 8-10

通用 AUROC 曲线

一个优秀的模型具有接近 1.0 的 AUC，这意味着它具有分离类别预测的良好度量。差模型的 AUC 接近于 0，这意味着它具有最差的可分性度量。其实就是在预测 0 当 1，1 当 0。这种情况称为类的往复。当 AUC 为 0.5 时，意味着模型根本不区分类别。

接下来的一系列数字将有助于阐明 AUROC 曲线如何有助于解释模型的性能。

如前所述，ROC 是一条概率曲线，因此我将使用概率分布图进行讨论。假设图中右边的曲线代表阳性类别或患有疾病的患者。相应的，左边的曲线是健康患者的。图 [8-11](#Fig11) 显示了两类完全分离且 AUC 为 1.0 的情况。该模型能够完全区分正类样本和负类样本。

![../images/482214_1_En_8_Chapter/482214_1_En_8_Fig11_HTML.jpg](../images/482214_1_En_8_Chapter/482214_1_En_8_Fig11_HTML.jpg)

图 8-11

完美的阶级分离

这种情况下的 AUROC 曲线如图 [8-12](#Fig12) 所示。

![../images/482214_1_En_8_Chapter/482214_1_En_8_Fig12_HTML.jpg](../images/482214_1_En_8_Chapter/482214_1_En_8_Fig12_HTML.jpg)

图 8-12

AUC = 1.0 时的 AUROC 曲线

现在，让情况稍微改变一下，假设概率分布有一点重叠。这带来了统计学家所说的第一类和第二类错误发生的机会。第一类错误是 FP，或者在这种情况下，预测患者患有不存在的疾病。类似地，2 型错误是 FN，或者当它存在时预测患者没有疾病。图 [8-13](#Fig13) 显示了 AUC 等于 0.7 的分布。

![../images/482214_1_En_8_Chapter/482214_1_En_8_Fig13_HTML.jpg](../images/482214_1_En_8_Chapter/482214_1_En_8_Fig13_HTML.jpg)

图 8-13

70%的阶级分离

AUC 为 0.7 意味着模型有 70%的机会能够成功区分阳性和阴性类别。

这种情况下的 AUROC 曲线如图 [8-14](#Fig14) 所示。

![../images/482214_1_En_8_Chapter/482214_1_En_8_Fig14_HTML.jpg](../images/482214_1_En_8_Chapter/482214_1_En_8_Fig14_HTML.jpg)

图 8-14

AUC = 0.7 的 AUROC 曲线

现在，让 AUC 等于 0.5，让情况变得更糟。有了这个 AUC，模型就不能区分类别。图 [8-15](#Fig15) 显示了重叠的概率分布曲线，证明了模型失效的原因。

![../images/482214_1_En_8_Chapter/482214_1_En_8_Fig15_HTML.jpg](../images/482214_1_En_8_Chapter/482214_1_En_8_Fig15_HTML.jpg)

图 8-15

50%的阶级分离

这种情况下的 AUROC 曲线如图 [8-16](#Fig16) 所示。

![../images/482214_1_En_8_Chapter/482214_1_En_8_Fig16_HTML.jpg](../images/482214_1_En_8_Chapter/482214_1_En_8_Fig16_HTML.jpg)

图 8-16

AUC = 0.5 的 AUROC 曲线

当分布如图 [8-11](#Fig11) 所示翻转时，会发生最后一种情况，只是正类现在在左手边，负类在右手边。这就是我之前提到的反演情况，这种情况下的 AUROC 曲线如图 [8-17](#Fig17) 所示。

![../images/482214_1_En_8_Chapter/482214_1_En_8_Fig17_HTML.jpg](../images/482214_1_En_8_Chapter/482214_1_En_8_Fig17_HTML.jpg)

图 8-17

AUC = 0.0 时的 AUROC 曲线

反演是一种极端情况，在任何实际模型中都不应该发生。展示它只是为了完成背景讨论。

在下一次演示中，我将展示一条真实的 AUROC 曲线。

### 使用 MLP 模型进行乳腺癌预测

本演示使用对 699 名患者的乳腺癌样本进行的组织学研究的结果，根据记录的特征预测癌症的存在或不存在。这个演示与本章中使用 CNN 模型的第一个演示有很大不同。在这种情况下，使用病理学家活检检查的结果，而不是像第一次演示那样直接处理原始图像。这个模型是 MLP 的应用程序，而不是 CNN 的应用程序。

该数据集是乳腺癌威斯康辛州(诊断)数据集特征，它是根据乳腺肿块细针抽吸(FNA)的数字化图像计算的。这些数据描述了图像中出现的细胞核的特征。K. P. Bennett 和 O. L. Mangasarian 详细描述了该数据集:“两个线性不可分集合的鲁棒线性规划判别”，Optimization Methods and Software 1，1992。

您可以从 UCI 机器学习资源库下载输入数据集。

`https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29`

将下载的文件重命名为 data.csv，并放在名为 input 的新子目录中。

你现在需要替换 16 号吗？第七列中的条目用 1 表示。我知道这可能会使数据集有所偏差，但是如果字符不被替换为数字，脚本就无法运行。我选择的数字是该列中最常见的一个。我使用 MS Excel 程序进行修改，但是您可以使用已经安装在 RasPi 系统上的 LibreOffice Calc 应用程序。

以下脚本名为 bcMLP.py，可从本书的配套网站获得。不需要更多的解释性注释，因为我已经在之前的脚本中向您展示了相同或几乎相同的代码。

```
# Import required libraries libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_curve, auc
from sklearn.ensemble import RandomForestClassifier
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout

# Load data
data = pd.read_csv('input/data.csv')
#del data['Unnamed: 32']
X = data.iloc[:, 1:9].values
y = data.iloc[:, 10].values

# Encoding categorical data
labelencoder_X_1 = LabelEncoder()
y = labelencoder_X_1.fit_transform(y)

# Split the dataset into Training and Test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)

#Feature Scaling
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

# Initialise the ANN
classifier = Sequential()

# Add the input layer and the first hidden layer
classifier.add(Dense(output_dim=16, init="uniform", activation="relu", input_dim=8))

# Add dropout to prevent overfitting
classifier.add(Dropout(p=0.1))

# Add the second hidden layer
classifier.add(Dense(output_dim=16, init="uniform", activation="relu"))

# Add dropout to prevent overfitting
classifier.add(Dropout(p=0.1))

# Add the output layer
classifier.add(Dense(output_dim=1, init="uniform", activation="sigmoid"))

# Compile the ANN
classifier.compile(optimizer='adam', loss="binary_crossentropy", metrics=['accuracy'])

# Fit the ANN to the Training set
# The batch size and number of epochs have been set using trial
# and error.
classifier.fit(X_train, y_train, batch_size=100, nb_epoch=150)

# Predict the Test set results
y_pred = classifier.predict(X_test)
y_pred = (y_pred > 0.5) # Converts continuous to binary

#  Create confusion matrix object
cm = confusion_matrix(y_test, y_pred)

# Display accuracy
print('Accuracy is {}%'.format(((cm[0][0] + cm[1][1])/70)*100))

# Display the confusion matrix
print('\nConfusion Matrix\n',cm)

# Generate and display a Seaborn heatmap
sns.heatmap(cm, annot=True)
plt.savefig('bcHeatmap.png')
plt.show()

# Instantiate a random forest classifier
rf_clf = RandomForestClassifier(n_estimators=100)
rf_clf.fit(X_train, y_train)

# Compute the probability distributions
probas = rf_clf.predict_proba(X_test)# plot
plt.figure(dpi=150)
plt.hist(probas, bins=20)
plt.title('Classification Probabilities')
plt.xlabel('Probability')
plt.ylabel('# of Instances')
plt.xlim([0.5, 1.0])
plt.legend('01')
plt.show()

# Compute the false and true positive rates
fpr, tpr, thresholds = roc_curve(y_test, probas[:,0], pos_label=0)

# Compute the area under the curve
roc_auc = auc(fpr, tpr)

# Plot the AUROC curve
plt.figure(dpi=150)
plt.plot(fpr, tpr, lw=1, color="green", label=f'AUC = {roc_auc:.3f}')
plt.title('ROC Curve for RF classifier')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate (Recall)')
plt.xlim([-0.05, 1.05])
plt.ylim([-0.05, 1.05])
plt.legend()
plt.show()

```

#### 运行 MLP 脚本

通过输入以下命令运行该脚本:

```
python bcMLP.py

```

图 [8-18](#Fig18) 显示了运行脚本后的结果。

![../images/482214_1_En_8_Chapter/482214_1_En_8_Fig18_HTML.jpg](../images/482214_1_En_8_Chapter/482214_1_En_8_Fig18_HTML.jpg)

图 8-18

运行 bcMLP 脚本后的结果

图中显示的混淆矩阵复制在表 [8-2](#Tab2) 中。

表 8-2

MLP 混淆矩阵

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
|   | 

预测

 |
| --- | --- |
| **实际** | Zero | one |
| Zero | Forty | one |
| one | Zero | Twenty-nine |

在哪里

0 =未检测到癌症(阴性)

1 =检测到癌症(阳性)

从表中可以清楚地看到，该模型在预测癌症不存在时的准确率为 100%(0 个假阳性)，在预测癌症存在时的准确率为 98.57%(1 个假阴性)。最后一个指标与脚本运行后显示的精确度值完全相同。当然，在癌症仍然存在的情况下报告患者没有癌症的现实生活后果对患者来说可能是毁灭性的。因此，即使是 1.43%的错误率，虽然非常低，但也必须谨慎看待，因为这会给患者安全带来巨大的后果。

顺便说一句，虽然大多数读者已经明白了这一点，但我将明确指出混淆矩阵中显示的 70 的总和是由测试数据集大小的 10%分割产生的。由于原始数据集中有 699 名患者，测试数据集的大小被四舍五入为 70。

图 [8-19](#Fig19) 是一张热图，提供了另一种可视化混淆矩阵结果的方式。

![../images/482214_1_En_8_Chapter/482214_1_En_8_Fig19_HTML.jpg](../images/482214_1_En_8_Chapter/482214_1_En_8_Fig19_HTML.jpg)

图 8-19

Heatmap(热图)

对于印刷书籍的读者，我强烈建议看一下 PDF 中包含的彩色图像版本的图 [8-19](#Fig19) ，其中包含了该书的所有彩色图。

为了生成 AUROC 图，必须首先创建概率分布。因为概率分布不容易从 MLP 模型中获得，所以我实例化了一个名为`rf_clf`的随机森林分类器对象。尽管基础模型不同，但由于数据集的性质，最终的 AUROC 图应该几乎相同。图 8-20 是正(1)类和负(0)类概率分布的条形图。

![../images/482214_1_En_8_Chapter/482214_1_En_8_Fig20_HTML.jpg](../images/482214_1_En_8_Chapter/482214_1_En_8_Fig20_HTML.jpg)

图 8-20

数据集类别概率分布

你可以清楚地看到，两个类别的分布都高度向右倾斜，这将迫使 AUROC 图类似于图 [8-12](#Fig12) 。正如你在图 [8-21](#Fig21) 中所看到的，这正是剧情生成时所发生的事情。

![../images/482214_1_En_8_Chapter/482214_1_En_8_Fig21_HTML.jpg](../images/482214_1_En_8_Chapter/482214_1_En_8_Fig21_HTML.jpg)

图 8-21

随机森林模型乳腺癌数据集的 AUROC 图

当查看这样的图时，您的直接收获是分类器模型对于该特定数据集来说是一个优秀的执行者。这一结论得到了用于量化该模型的其他绩效指标的支持。