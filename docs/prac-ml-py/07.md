# 7.分析电影评论情感

在本章中，我们继续关注面向案例研究的章节，其中我们将关注特定的现实世界问题和场景，以及我们如何使用机器学习来解决它们。在本章中，我们将涉及自然语言处理(NLP)、文本分析和机器学习。眼前的问题是情感分析或观点挖掘，我们希望分析一些文本文档，并根据这些文档的内容预测他们的情感或观点。情感分析可能是自然语言处理和文本分析最受欢迎的应用之一，有大量关于这个主题的网站、书籍和教程。一般来说，情感分析似乎对主观文本最有效，人们在主观文本中表达观点、感受和情绪。从现实世界的行业角度来看，情感分析被广泛用于分析企业调查、反馈调查、社交媒体数据以及电影、场所、商品等的评论。这个想法是分析和理解人们对特定实体的反应，并根据他们的情绪采取有见地的行动。

文本语料库由多个文本文档组成，每个文档可以是简单的单个句子，也可以是包含多个段落的完整文档。尽管文本数据是非结构化的，但它可以分为两种主要的文档类型。事实文档，通常描述某种形式的陈述或事实，不附带任何特定的感觉或情感。这些也被称为客观文件。另一方面，主观文档包含表达感觉、情绪、情感和观点的文本。

情感分析通常也被称为意见分析或意见挖掘。关键思想是使用来自文本分析、NLP、机器学习和语言学的技术从非结构化文本中提取重要信息或数据点。这反过来可以帮助我们获得定性输出，如正面、中性或负面的总体情绪，以及定量输出，如情绪极性、主观性和客观性比例。情感极性通常是一个数字分数，它基于主观参数(如表达感受和情绪的特定单词和短语)分配给文本文档的积极和消极方面。中性情绪通常具有`0`极性，因为它不表达特定情绪，积极情绪将具有极性`> 0`，而消极情绪将具有极性`< 0`。当然，您总是可以根据您正在处理的文本类型来更改这些阈值；对此没有硬性约束。

在这一章中，我们致力于分析大量的电影评论，并从中获取情感。我们涵盖了各种各样的分析情感的技术，包括以下内容。

*   无监督的基于词典的模型
*   传统的监督机器学习模型
*   更新的监督深度学习模型
*   高级监督深度学习模型

除了查看各种方法和模型，我们还关注机器学习管道中的重要方面，包括文本预处理、规范化和模型的深入分析，包括模型解释和主题模型。这里的关键思想是理解我们如何处理像对非结构化文本进行情感分析这样的问题，学习各种技术和模型，并理解如何解释结果。这将使您能够在将来对自己的数据集使用这些方法。我们开始吧！

## 问题陈述

本章的主要目的是预测从互联网电影数据库(IMDb)获得的大量电影评论的情绪。该数据集包含 50，000 条电影评论，这些评论已经基于评论内容预先标记了“正面”和“负面”情感类别标签。除此之外，还有其他未标记的电影评论。数据集可以从 [`http://ai.stanford.edu/~amaas/data/sentiment/`](http://ai.stanford.edu/%7Eamaas/data/sentiment/) 获得，由斯坦福大学和 Andrew L. Maas、Raymond E. Daly、Peter T. Pham、黄丹、Andrew Y. Ng 和 Christopher Potts 提供。这个数据集也用于他们的著名论文，[学习用于情感分析的词向量](http://ai.stanford.edu/%7Eamaas/papers/wvSent_acl2011.pdf)计算语言学协会第 49 届年会会议录(ACL 2011)。他们有原始文本形式的数据集以及已经处理过的单词包格式。我们在本章的分析中将只使用原始的带标签的电影评论。因此，我们的任务将是预测 15，000 条带标签的电影评论的情感，并使用剩余的 35，000 条评论来训练我们的监督模型。在无监督模型的情况下，我们仍将仅对 15，000 条评论预测情感，以保持一致性并便于比较。

## 设置相关性

我们将使用几个专门针对文本分析、NLP 和机器学习的 Python 库和框架。虽然每个部分都会提到它们中的大多数，但您需要确保安装了`pandas`、`numpy`、`scipy`和`scikit-learn`，它们将用于数据处理和机器学习。本章使用的深度学习框架包括带有`tensorflow`后端的 keras，但如果你选择这样做，你也可以使用`theano`作为后端。将要使用的 NLP 库包括`spacy`、`nltk`和`gensim`。一定要记得检查你安装的`nltk`版本至少是`>= 3.2.4`，否则`ToktokTokenizer`类可能不存在。如果你出于某种原因想要使用一个更低的`nltk`版本，你可以使用任何其他的记号赋予器，比如基于`TreebankWordTokenizer`的默认`word_tokenize()`。`gensim`的版本至少应为`2.3.0`，而`spacy`使用的版本为`1.9.0`。我们建议使用最近发布的最新版本的 spacy(2 . x 版),因为它修复了几个错误并增加了几项改进。如果您是第一次安装`spacy`和`nltk`的话，您还需要下载必要的依赖项和语料库。下面的代码片段应该可以做到这一点。对于`nltk`,在使用`pip`或`conda`安装`nltk`之后，您需要从 Python 或 ipython shell 中键入以下代码。

```py
import nltk
nltk.download('all', halt_on_error=False)

```

对于`spacy`，您需要在 Unix shell\windows 命令提示符下键入以下代码，以安装库(如果您不想使用`conda`，请使用`pip install spacy`)并获得英语模型依赖项。

```py
$ conda config --add channels conda-forge

$ conda install spacy

$ python -m spacy download en

```

我们还使用我们定制开发的文本预处理和规范化模块，您可以在名为`contractions.py`和`text_normalizer.py`的文件中找到该模块。与监督模型拟合、预测和评估相关的实用程序出现在`model_evaluation_utils.py`中，所以请确保您将这些模块放在同一个目录中，并将其他 Python 文件和 jupyter 笔记本放在本章中。

## 获取数据

该数据集将与本章的代码文件一起在 GitHub 知识库中以文件名`movie_reviews.csv`在 [`https://github.com/dipanjanS/practical-machine-learning-with-python`](https://github.com/dipanjanS/practical-machine-learning-with-python) 提供，其中包含 50，000 条带标签的 IMDb 电影评论。如果需要，您也可以从 [`http://ai.stanford.edu/~amaas/data/sentiment/`](http://ai.stanford.edu/%7Eamaas/data/sentiment/) 下载相同的数据。一旦你有了 CSV 文件，你可以使用`pandas`的`read_csv(...)`实用函数轻松地用 Python 加载它。

## 文本预处理和规范化

在进入特征工程和建模过程之前的一个关键步骤包括清理、预处理和规范化文本，以将短语和单词等文本组件转换为某种标准格式。这实现了跨文档语料库的标准化，这有助于构建有意义的特征，并有助于减少由于许多因素(如不相关的符号、特殊字符、XML 和 HTML 标签等)而引入的噪声。名为`text_normalizer.py`的文件包含了我们文本标准化所需的所有必要工具。也可以参考名为`Text Normalization Demo.ipynb`的 jupyter 笔记本，获得更具互动性的体验。本节将描述我们的文本规范化管道中的主要组件。

*   清理文本:我们的文本往往包含像 HTML 标签这样不必要的内容，在分析情感时并没有增加多少价值。因此，我们需要确保在提取特征之前移除它们。库在为此提供必要的函数方面做得非常好。我们的`strip_html_tags(...)`函数支持清理和剥离 HTML 代码。
*   删除重音字符:在我们的数据集中，我们处理的是英语评论，所以我们需要确保任何其他格式的字符，尤其是重音字符都被转换并标准化为 ASCII 字符。一个简单的例子是将é转换成 e。我们的`remove_accented_chars(...)`函数在这方面帮助了我们。
*   扩展缩写:在英语中，缩写基本上是单词或音节的缩短版本。这些现有单词或短语的缩短版本是通过删除特定的字母和声音创建的。单词中的元音常常被去掉。例如，do not to don't 和 I would to I'd。缩写在文本规范化中造成了一个问题，因为我们必须处理像撇号这样的特殊字符，并且我们还必须将每个缩写转换为其扩展的原始形式。我们的`expand_contractions(...)`函数使用正则表达式和映射在我们的`contractions.py`模块中的各种缩写来扩展我们的文本语料库中的所有缩写。
*   删除特殊字符:文本清理和规范化的另一个重要任务是删除特殊字符和符号，这些字符和符号通常会增加非结构化文本中的额外噪声。简单的正则表达式可以用来实现这一点。我们的函数`remove_special_characters(...)`帮助我们删除特殊字符。在我们的代码中，我们保留了数字，但是如果您不希望它们出现在您的规范化语料库中，您也可以删除它们。
*   词干和词汇化:词干通常是可能单词的基本形式，可以通过在词干上附加前缀和后缀等词缀来创建新单词。这就是所谓的变调。获取单词基本形式的相反过程称为词干提取。一个简单的例子是手表、手表和手表。他们有词根词干表作为基本形式。`nltk`包提供了各种各样的词干分析器，如`PorterStemmer`和`LancasterStemmer`。词汇化与词干化非常相似，我们去掉词缀来获得单词的基本形式。然而，在这种情况下，基本形式被称为词根，而不是词干。区别在于词根总是字典上正确的单词(存在于字典中),但是词干可能不是这样。我们将只在规范化管道中使用词汇化来保留词典正确的单词。功能`lemmatize_text(...)`在这方面帮助了我们。
*   去除停用词:意义不大或没有意义的词，尤其是当从文本中构造有意义的特征时，也称为停用词或停用词。如果您在文档语料库中使用简单的术语或词频，这些词通常是出现频率最高的词。像 a、an、the 等词被认为是停用词。没有通用的停用词表，但是我们使用来自`nltk`的标准英语停用词表。如果需要，您还可以添加自己的特定于域的停用词。函数`remove_stopwords(...)`帮助我们删除停用词，保留语料库中最有意义和上下文的词。

我们使用所有这些组件，并在下面这个名为`normalize_corpus(...)`的函数中将它们联系在一起，这个函数可以用来将一个文档语料库作为输入，并返回相同的语料库以及经过清理和规范化的文本文档。

```py
def normalize_corpus(corpus, html_stripping=True, contraction_expansion=True,
                     accented_char_removal=True, text_lower_case=True,
                     text_lemmatization=True, special_char_removal=True,
                     stopword_removal=True):
    normalized_corpus = []
    # normalize each document in the corpus
    for doc in corpus:
        # strip HTML
        if html_stripping:
            doc = strip_html_tags(doc)
        # remove accented characters
        if accented_char_removal:
            doc = remove_accented_chars(doc)
        # expand contractions    
        if contraction_expansion:
            doc = expand_contractions(doc)
        # lowercase the text    
        if text_lower_case:
            doc = doc.lower()
        # remove extra newlines
        doc = re.sub(r'[\r|\n|\r\n]+', ' ',doc)
        # insert spaces between special characters to isolate them    
        special_char_pattern = re.compile(r'([{.(-)!}])')
        doc = special_char_pattern.sub(" \\1 ", doc)
        # lemmatize text
        if text_lemmatization:
            doc = lemmatize_text(doc)
        # remove special characters    
        if special_char_removal:
            doc = remove_special_characters(doc)  
        # remove extra whitespace
        doc = re.sub(' +', ' ', doc)
        # remove stopwords
        if stopword_removal:
            doc = remove_stopwords(doc, is_lower_case=text_lower_case)
        normalized_corpus.append(doc)
    return normalized_corpus

```

下面的代码片段描述了一个使用我们的规范化模块对样本文档进行文本规范化的小演示。

```py
In [1]: from text_normalizer import normalize_corpus

In [2]: document = """<p>Héllo! Héllo! can you hear me! I just heard about <b>Python</b>!<br/>\r\n
   ...: It's an amazing language which can be used for Scripting, Web development,\r\n\r\n
   ...: Information Retrieval, Natural Language Processing, Machine Learning & Artificial Intelligence!\n
   ...: What are you waiting for? Go and get started.<br/> He's learning, she's learning, they've already\n\n
   ...: got a headstart!</p>
   ...:            """

In [3]: document
Out[3]: "<p>Héllo! Héllo! can you hear me! I just heard about <b>Python</b>!<br/>\r\n \n              It's an amazing language which can be used for Scripting, Web development,\r\n\r\n\n              Information Retrieval, Natural Language Processing, Machine Learning & Artificial Intelligence!\n\n              What are you waiting for? Go and get started.<br/> He's learning, she's learning, they've already\n\n\n              got a headstart!</p>\n           "

In [4]: normalize_corpus([document], text_lemmatization=False, stopword_removal=False,
                         text_lower_case=False)
Out[4]: ['Hello Hello can you hear me I just heard about Python It is an amazing language which can be used for Scripting Web development Information Retrieval Natural Language Processing Machine Learning Artificial Intelligence What are you waiting for Go and get started He is learning she is learning they have already got a headstart ']

In [5]: normalize_corpus([document])
Out[5]: ['hello hello hear hear python amazing language use scripting web development information retrieval natural language processing machine learning artificial intelligence wait go get start learn learn already get headstart']

```

既然我们已经准备好了我们的标准化模块，我们可以开始建模和分析我们的语料库。NLP 和文本分析爱好者可能对文本规范化的更深入的细节感兴趣，可以参考“使用 Python 进行文本分析”的第 115 页第 [3](03.html) 章“文本规范化”一节(ApressDipanjan Sarkar，2016)。

## 无监督的基于词典的模型

我们过去讨论过无监督学习方法，它指的是在没有标记数据的情况下，可以直接应用于数据特征的特定建模方法。任何组织面临的主要挑战之一是获取标记数据集，因为缺少时间和资源来完成这项乏味的任务。无监督的方法在这种情况下非常有用，我们将在这一节中讨论其中的一些方法。尽管我们已经标记了数据，但这一部分应该让您很好地了解基于词典的模型是如何工作的，并且当您没有标记的数据时，您可以在自己的数据集中应用同样的方法。

无监督的情感分析模型使用精心策划的知识库、本体、词典和数据库，这些数据库具有关于主观单词、短语的详细信息，包括情感、情绪、极性、客观性、主观性等等。词典模型通常使用词典，也称为词典或专门用于情感分析的词汇。通常这些词典包含与正面和负面情绪、极性(负面或正面分数的大小)、词性(POS)标签、主观性分类器(强、弱、中性)、语气、情态等相关联的单词列表。您可以使用这些词典，并通过匹配词典中特定单词的存在来计算文本文档的情感，查看其他附加因素，如否定参数、周围单词、整体上下文和短语的存在，并合计整体情感极性分数来决定最终的情感分数。有几种流行的词汇模型用于情感分析。其中一些提到如下。

*   刘冰的词汇
*   MPQA 主观性词汇
*   模式词典
*   阿芬·莱克西
*   SentiWordNet 词典
*   VADER 词典

这不是一个详尽的词典模型列表，但肯定是当今最流行的。我们将使用我们的电影评论数据集，通过实际操作代码和示例更详细地介绍最后三个词典模型。我们将使用最近的 15，000 条评论，预测他们的情绪，并根据准确性、精确度、召回率和 F1 分数等模型评估指标来看看我们的模型表现如何，我们在第 [5](05.html) 章中对此进行了详细介绍。因为我们已经标记了数据，所以我们很容易看到这些电影评论的实际情感值与我们基于词典模型的预测情感值的匹配程度。您可以参考标题为`unsupervised_sentiment_analysis.py`的 Python 文件来获得本节中使用的所有代码，或者使用标题为`Sentiment Analysis - Unsupervised Lexical.ipynb`的 jupyter 笔记本来获得更具交互性的体验。在我们开始分析之前，让我们使用下面的代码片段加载必要的依赖项和配置设置。

```py
In [1]: import pandas as pd
   ...: import numpy as np
   ...: import text_normalizer as tn
   ...: import model_evaluation_utils as meu
   ...:
   ...: np.set_printoptions(precision=2, linewidth=80)

```

现在，我们可以加载我们的 IMDb 评论数据集，筛选出将用于我们分析的最后 15，000 条评论，并使用以下代码片段对它们进行规范化。

```py
In [2]: dataset = pd.read_csv(r'movie_reviews.csv')
   ...:
   ...: reviews = np.array(dataset['review'])
   ...: sentiments = np.array(dataset['sentiment'])
   ...:
   ...: # extract data for model evaluation
   ...: test_reviews = reviews[35000:]
   ...: test_sentiments = sentiments[35000:]
   ...: sample_review_ids = [7626, 3533, 13010]
   ...:
   ...: # normalize dataset
   ...: norm_test_reviews = tn.normalize_corpus(test_reviews)

```

我们还提取了一些样本评论，以便我们可以对它们运行我们的模型，并详细解释它们的结果。

### 刘冰的词汇

该词典包含超过 6800 个单词，分为两个文件，名为`positive-words.txt`，包含约 2000+单词/短语，以及`negative-words.txt`，包含 4800+单词/短语。该词典是由刘冰多年来开发和策划的，Nitin Jindal 和刘冰在他的原始论文“识别文本文档中的比较句”中对其进行了详细解释，该论文发表在 2006 年西雅图 SIGIR 第 29 届国际 ACM 年会上。如果你想使用这个词典，你可以从`https://` [`www.cs.uic.edu/~liub/FBS/sentiment-analysis.html#lexicon`](http://www.cs.uic.edu/%7Eliub/FBS/sentiment-analysis.html%23lexicon) 获得，其中还包括下载它作为存档(RAR 格式)的链接。

### MPQA 主观性词汇

术语 MPQA 代表多视角问题回答，并且它包含关于意见语料库、主观性词典、主观性意义注释、论点词典、辩论语料库、意见查找器等等的多种资源。这是由匹兹堡大学开发和维护的，他们的官方网站 [`http://mpqa.cs.pitt.edu/`](http://mpqa.cs.pitt.edu/) 包含了所有必要的信息。主观性词汇是他们意见发现框架的一部分，包含主观性线索和语境极性。关于这一点的细节可以在由 Theresa Wilson、Janyce Wiebe 和 Paul Hoffmann 撰写的论文中找到，“在短语级情感分析中识别上下文极性”。

你可以从他们的官方网站 [`http://mpqa.cs.pitt.edu/lexicons/subj_lexicon/`](http://mpqa.cs.pitt.edu/lexicons/subj_lexicon/) 下载主观性词典，包含存在于名为`subjclueslen1-HLTEMNLP05.tff`的数据集中的主观性线索。下面的代码片段显示了词典中的一些示例行。

```py
type=weaksubj len=1 word1=abandonment pos1=noun stemmed1=n priorpolarity=negative
type=weaksubj len=1 word1=abandon pos1=verb stemmed1=y priorpolarity=negative
...
...
type=strongsubj len=1 word1=zenith pos1=noun stemmed1=n priorpolarity=positive
type=strongsubj len=1 word1=zest pos1=noun stemmed1=n priorpolarity=positive

```

每行包含一个特定的单词及其相关的极性、位置标签信息、长度(现在只显示长度为 1 的单词)、主观上下文和词干信息。

### 模式词典

pattern package 是 Python 中一个完整的自然语言处理框架，可用于文本处理、情感分析等。这是由 CLiPS(计算语言学和心理语言学)开发的，CLiPS 是安特卫普大学文学院语言学系的一个研究中心。Pattern 使用自己的情感模块，该模块内部使用一个词典，您可以从位于 [`https://github.com/clips/pattern/blob/master/pattern/text/en/en-sentiment.xml`](https://github.com/clips/pattern/blob/master/pattern/text/en/en-sentiment.xml) 的官方 GitHub 知识库中访问该词典，该词典包含完整的基于主观性的词典数据库。词典中的每一行通常如下例所示。

```py
<word form="absurd" wordnet_id="a-02570643" pos="JJ" sense="incongruous" polarity="-0.5" subjectivity="1.0" intensity="1.0" confidence="0.9" />

```

因此，您可以获得重要的元数据信息，如 WordNet 语料库标识符、极性得分、词义、词性标签、强度、主观性得分等等。这些又可以用于基于极性和主观性得分来计算对文本文档的情感。不幸的是，pattern 还没有正式移植到 Python `3.x`上，它可以在 Python `2.7.x`上工作。但是，您仍然可以加载这个词典，并根据需要进行自己的建模。

### 阿芬·莱克西

AFINN 词典可能是最简单和最流行的词典之一，可以广泛用于情感分析。由芬恩·RUP Nielsen 开发和策划，你可以在芬恩·RUP Nielsen 的论文“一个新的新:评估用于微博情感分析的单词列表”，ESWC2011 研讨会的会议录中找到关于这个词汇的更多细节。该词典的当前版本是`AFINN-en-165.txt`，它包含超过 3300 个单词，每个单词都有一个极性分数。你可以在作者的官方 GitHub 库中找到这本词典，以及这本词典的以前版本，包括在 [`https://github.com/fnielsen/afinn/blob/master/afinn/data/`](https://github.com/fnielsen/afinn/blob/master/afinn/data/) 的`AFINN-111`。作者还在此基础上用 Python 创建了一个名为`afinn`的包装器库，我们将使用它来满足我们的分析需求。您可以导入该库，并使用以下代码实例化一个对象。

```py
In [3]: from afinn import Afinn
   ...:
   ...: afn = Afinn(emoticons=True)

```

我们现在可以使用这个对象，并使用下面的代码片段计算我们选择的四个样本评论的极性。

```py
In [4]: for review, sentiment in zip(test_reviews[sample_review_ids], test_sentiments[sample_review_ids]):
   ...:     print('REVIEW:', review)
   ...:     print('Actual Sentiment:', sentiment)
   ...:     print('Predicted Sentiment polarity:', afn.score(review))
   ...:     print('-'*60)
REVIEW: no comment - stupid movie, acting average or worse... screenplay - no sense at all... SKIP IT!
Actual Sentiment: negative
Predicted Sentiment polarity: -7.0
------------------------------------------------------------
REVIEW: I don't care if some people voted this movie to be bad. If you want the Truth this is a Very Good Movie! It has every thing a movie should have. You really should Get this one.
Actual Sentiment: positive
Predicted Sentiment polarity: 3.0
------------------------------------------------------------
REVIEW: Worst horror film ever but funniest film ever rolled in one you have got to see this film it is so cheap it is unbelievable but you have to see it really!!!! P.S. Watch the carrot
Actual Sentiment: positive
Predicted Sentiment polarity: -3.0
------------------------------------------------------------

```

我们可以比较每个评论的实际情感标签，也可以检查预测的情感极性得分。负极性通常表示消极情绪。为了预测 15，000 条评论的完整测试数据集上的情感(我使用原始文本文档，因为 AFINN 考虑了其他方面，如表情符号和感叹词)，我们现在可以使用下面的代码片段。我使用了一个阈值`>= 1.0`来确定整体情绪是积极还是消极。你可以在未来分析你自己的语料库的基础上选择你自己的阈值。

```py
In [5]: sentiment_polarity = [afn.score(review) for review in test_reviews]
   ...: predicted_sentiments = ['positive' if score >= 1.0 else 'negative' for score in
                                                                        sentiment_polarity]

```

现在我们已经有了预测的情感标签，我们可以使用我们的效用函数基于标准的性能度量来评估我们的模型性能。见图 [7-1](#Fig1) 。

![A448827_1_En_7_Fig1_HTML.jpg](A448827_1_En_7_Fig1_HTML.jpg)

图 7-1。

Model performance metrics for AFINN lexicon based model

```py
In [6]: meu.display_model_performance_metrics(true_labels=test_sentiments,
                                             predicted_labels=predicted_sentiments,
                                             classes=['positive', 'negative'])

```

我们得到了 71%的总体 F1 分数，考虑到这是一个无监督的模型，这已经相当不错了。查看混淆矩阵，我们可以清楚地看到，相当多的基于负面情绪的评论被错误地分类为正面(3，189)，这导致负面情绪类别的召回率较低，为 57%。在召回率或命中率方面，正面类的性能更好，其中我们正确预测了 7，510 个正面评论中的 6，376 个，但是精确度是 67%，因为在负面情绪评论的情况下做出了许多错误的正面预测。

### SentiWordNet 词典

WordNet 语料库无疑是在自然语言处理和语义分析中广泛使用的最流行的英语语料库之一。WordNet 给了我们同义词集的概念。SentiWordNet 词典基于 WordNet 同义词集，可用于情感分析和观点挖掘。SentiWordNet 词典通常为每个 WordNet 同义词集分配三个情感得分。这些包括正极性得分、负极性得分和客观性得分。更多细节可在官方网站 [`http://sentiwordnet.isti.cnr.it`](http://sentiwordnet.isti.cnr.it) 获得，包括研究论文和词典的下载链接。我们将使用 nltk 库，它提供了一个到 SentiWordNet 的 Pythonic 接口。想想我们有形容词“棒极了”。使用下面的代码片段，我们可以获得与这个单词的 synset 相关的情感得分。

```py
In [8]: from nltk.corpus import sentiwordnet as swn
   ...:
   ...: awesome = list(swn.senti_synsets('awesome', 'a'))[0]
   ...: print('Positive Polarity Score:', awesome.pos_score())
   ...: print('Negative Polarity Score:', awesome.neg_score())
   ...: print('Objective Score:', awesome.obj_score())
Positive Polarity Score: 0.875
Negative Polarity Score: 0.125
Objective Score: 0.0

```

现在，让我们构建一个通用函数，根据文档中匹配的同义词集来提取和聚合整个文本文档的情感得分。

```py
def analyze_sentiment_sentiwordnet_lexicon(review,
                                           verbose=False):

    # tokenize and POS tag text tokens
    tagged_text = [(token.text, token.tag_) for token in tn.nlp(review)]
    pos_score = neg_score = token_count = obj_score = 0
    # get wordnet synsets based on POS tags
    # get sentiment scores if synsets are found
    for word, tag in tagged_text:
        ss_set = None
        if 'NN' in tag and list(swn.senti_synsets(word, 'n')):
            ss_set = list(swn.senti_synsets(word, 'n'))[0]
        elif 'VB' in tag and list(swn.senti_synsets(word, 'v')):
            ss_set = list(swn.senti_synsets(word, 'v'))[0]
        elif 'JJ' in tag and list(swn.senti_synsets(word, 'a')):
            ss_set = list(swn.senti_synsets(word, 'a'))[0]
        elif 'RB' in tag and list(swn.senti_synsets(word, 'r')):
            ss_set = list(swn.senti_synsets(word, 'r'))[0]
        # if senti-synset is found        
        if ss_set:
            # add scores for all found synsets
            pos_score += ss_set.pos_score()
            neg_score += ss_set.neg_score()
            obj_score += ss_set.obj_score()
            token_count += 1
    # aggregate final scores
    final_score = pos_score - neg_score
    norm_final_score = round(float(final_score) / token_count, 2)
    final_sentiment = 'positive' if norm_final_score >= 0 else 'negative'
    if verbose:
        norm_obj_score = round(float(obj_score) / token_count, 2)
        norm_pos_score = round(float(pos_score) / token_count, 2)
        norm_neg_score = round(float(neg_score) / token_count, 2)
        # to display results in a nice table
        sentiment_frame = pd.DataFrame([[final_sentiment, norm_obj_score, norm_pos_score,
                                         norm_neg_score, norm_final_score]],
                                       columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'],
                                                        ['Predicted Sentiment', 'Objectivity',
                                                         'Positive', 'Negative', 'Overall']],
                                                        labels=[[0,0,0,0,0],[0,1,2,3,4]]))
        print(sentiment_frame)
    return final_sentiment

```

我们的函数基本上接受一个电影评论，用相应的 POS 标签标记每个单词，根据其 POS 标签提取任何匹配的 synset 标记的情感分数，最后汇总分数。当我们在样本文档中运行它时，这一点会更清楚。

```py
In [10]: for review, sentiment in zip(test_reviews[sample_review_ids], test_sentiments[sample_review_ids]):
    ...:     print('REVIEW:', review)
    ...:     print('Actual Sentiment:', sentiment)
    ...:     pred = analyze_sentiment_sentiwordnet_lexicon(review, verbose=True)    
    ...:     print('-'*60)
REVIEW: no comment - stupid movie, acting average or worse... screenplay - no sense at all... SKIP IT!
Actual Sentiment: negative
     SENTIMENT STATS:                                      
  Predicted Sentiment Objectivity Positive Negative Overall
0            negative        0.76     0.09     0.15   -0.06
------------------------------------------------------------
REVIEW: I don't care if some people voted this movie to be bad. If you want the Truth this is a Very Good Movie! It has every thing a movie should have. You really should Get this one.
Actual Sentiment: positive
     SENTIMENT STATS:                                      
  Predicted Sentiment Objectivity Positive Negative Overall
0            positive        0.74      0.2     0.06    0.14
------------------------------------------------------------
REVIEW: Worst horror film ever but funniest film ever rolled in one you have got to see this film it is so cheap it is unbelievable but you have to see it really!!!! P.S. watch the carrot
Actual Sentiment: positive
     SENTIMENT STATS:                                      
  Predicted Sentiment Objectivity Positive Negative Overall
0            positive         0.8     0.14     0.07    0.07
------------------------------------------------------------

```

我们可以清楚地看到在格式化的数据帧中描绘的每个样本电影评论的预测情感以及情感极性得分和客观性得分。现在让我们使用这个模型来预测我们所有测试评论的情绪，并评估它的性能。阈值`>=0`用于将总体情绪极性分类为积极情绪，阈值`< 0`用于分类为消极情绪。见图 [7-2](#Fig2) 。

![A448827_1_En_7_Fig2_HTML.jpg](A448827_1_En_7_Fig2_HTML.jpg)

图 7-2。

Model performance metrics for SentiWordNet lexicon based model

```py
In [11]: predicted_sentiments = [analyze_sentiment_sentiwordnet_lexicon(review, verbose=False)
                                                            for review in norm_test_reviews]
    ...: meu.display_model_performance_metrics(true_labels=test_sentiments,
                                              predicted_labels=predicted_sentiments,
    ...:                                      classes=['positive', 'negative'])

```

我们得到了 68%的 F1 总分，这无疑比我们基于 AFINN 的模型低了一步。虽然基于负面情绪的评论被错误分类为正面评论的数量较少，但模型性能的其他方面已经受到影响。

### VADER 词典

由 C.J .休顿开发的 VADER 词典是一个基于基于规则的情感分析框架的词典，专门用于分析社交媒体中的情感。VADER 代表价觉词典和情感推理机。关于这一框架的细节可以在休顿，C.J .和吉尔伯特，E.E. (2014)的题为“VADER:一个基于简约规则的社交媒体文本情感分析模型”的原始论文中阅读，第八届网络日志和社交媒体国际会议(ICWSM-14)的会议录。您可以在`nltk.sentiment.vader`模块下使用基于`nltk's`接口的库。除此之外，你还可以从 [`https://github.com/cjhutto/vaderSentiment`](https://github.com/cjhutto/vaderSentiment) 下载实际的词典或者安装框架，其中也包含了关于 VADER 的详细信息。该词典存在于名为`vader_lexicon.txt`的文件中，包含与单词、表情符号和俚语(如 wtf、lol、nah 等)相关联的必要情感得分。总共有超过 9000 个词汇特征，其中超过 7500 个精选词汇特征最终被选入词库，并具有适当的有效价分数。每个功能都按照从`"[-4] Extremely Negative"`到`"[4] Extremely Positive"`的等级进行评分，并考虑到`"[0] Neutral (or Neither, N/A)"`。选择词汇特征的过程是通过保留所有具有非零平均评级并且其标准偏差小于`2.5`的特征来完成的，该标准偏差由十个独立评级者的总和来确定。我们描述了来自`VADER`词典的一个样本如下。

```py
:(     -1.9     1.13578 [-2, -3, -2, 0, -1, -1, -2, -3, -1, -4]
:)      2.0     1.18322 [2, 2, 1, 1, 1, 1, 4, 3, 4, 1]
...
terrorizing     -3.0    1.0     [-3, -1, -4, -4, -4, -3, -2, -3, -2, -4]
thankful         2.7    0.78102 [4, 2, 2, 3, 2, 4, 3, 3, 2, 2]

```

前面的词典示例中的每一行都描述了一个独特的术语，它可以是一个表情符号，也可以是一个单词。第一个标记表示单词/表情符号，第二个标记表示平均情感极性分数，第三个标记表示标准偏差，最后一个标记表示由十个独立评分者给出的分数列表。现在就用`VADER`来分析一下我们的影评吧！我们构建自己的建模函数如下。

```py
from nltk.sentiment.vader import SentimentIntensityAnalyzer

def analyze_sentiment_vader_lexicon(review,
                                    threshold=0.1,
                                    verbose=False):
    # pre-process text
    review = tn.strip_html_tags(review)
    review = tn.remove_accented_chars(review)
    review = tn.expand_contractions(review)

    # analyze the sentiment for review
    analyzer = SentimentIntensityAnalyzer()
    scores = analyzer.polarity_scores(review)
    # get aggregate scores and final sentiment
    agg_score = scores['compound']
    final_sentiment = 'positive' if agg_score >= threshold\
                                   else 'negative'
    if verbose:
        # display detailed sentiment statistics
        positive = str(round(scores['pos'], 2)*100)+'%'
        final = round(agg_score, 2)
        negative = str(round(scores['neg'], 2)*100)+'%'
        neutral = str(round(scores['neu'], 2)*100)+'%'
        sentiment_frame = pd.DataFrame([[final_sentiment, final, positive,
                                        negative, neutral]],
                                        columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'],
                                                    ['Predicted Sentiment', 'Polarity Score',
                                                     'Positive', 'Negative', 'Neutral']],
                                                    labels=[[0,0,0,0,0],[0,1,2,3,4]]))
        print(sentiment_frame)

    return final_sentiment

```

在我们的建模功能中，我们做了一些基本的预处理，但保持标点符号和表情完整。除此之外，我们使用`VADER`来获得评论文本的情感极性以及正面、中性和负面情感的比例。我们还基于用户输入的聚合情感极性阈值来预测最终情感。通常情况下，`VADER`建议对聚合极性使用正情绪`>= 0.5,`中性`[-0.5, 0.5]`，对极性使用负情绪`< -0.5`。在我们的语料库中，我们使用阈值`>= 0.4`表示正面，使用阈值`<` `0.4`表示负面。以下是我们对样本评论的分析。

```py
In [13]: for review, sentiment in zip(test_reviews[sample_review_ids], test_sentiments[sample_review_ids]):
    ...:     print('REVIEW:', review)
    ...:     print('Actual Sentiment:', sentiment)
    ...:     pred = analyze_sentiment_vader_lexicon(review, threshold=0.4, verbose=True)    
    ...:     print('-'*60)
REVIEW: no comment - stupid movie, acting average or worse... screenplay - no sense at all... SKIP IT!
Actual Sentiment: negative
     SENTIMENT STATS:                                         
  Predicted Sentiment Polarity Score Positive Negative Neutral
0            negative           -0.8     0.0%    40.0%   60.0%
------------------------------------------------------------
REVIEW: I don't care if some people voted this movie to be bad. If you want the Truth this is a Very Good Movie! It has every thing a movie should have. You really should Get this one.
Actual Sentiment: positive
     SENTIMENT STATS:                                                     
  Predicted Sentiment Polarity Score Positive  Negative Neutral
0            negative          -0.16    16.0%  14.0%    69.0%
------------------------------------------------------------
REVIEW: Worst horror film ever but funniest film ever rolled in one you have got to see this film it is so cheap it is unbelievable but you have to see it really!!!! P.S. Watch the carrot
Actual Sentiment: positive
     SENTIMENT STATS:                                         
  Predicted Sentiment Polarity Score Positive Negative Neutral
0            positive           0.49    11.0%    11.0%   77.0%
------------------------------------------------------------

```

我们可以看到关于每个样本电影评论的情感和极性的详细统计数据。现在让我们在完整的测试电影评论语料库上测试我们的模型，并评估模型性能。见图 [7-3](#Fig3) 。

![A448827_1_En_7_Fig3_HTML.jpg](A448827_1_En_7_Fig3_HTML.jpg)

图 7-3。

Model performance metrics for VADER lexicon based model

```py
In [14]: predicted_sentiments = [analyze_sentiment_vader_lexicon(review, threshold=0.4,
                                                    verbose=False) for review in test_reviews]
    ...: meu.display_model_performance_metrics(true_labels=test_sentiments,
                                              predicted_labels=predicted_sentiments,
    ...:                                      classes=['positive', 'negative'])

```

我们得到了总体 F1 分数和 71%的模型准确度，这与基于 AFINN 的模型非常相似。基于 AFINN 的模型仅在平均精度上胜出 1%；除此之外，两种型号的性能都差不多。

## 使用监督学习对情感进行分类

另一种建立模型以理解文本内容并预测基于文本的评论的情感的方法是使用监督机器学习。更具体地说，我们将使用分类模型来解决这个问题。我们已经在第 [1](01.html) 章“监督学习”一节中介绍了与监督学习和分类相关的概念。关于建立和评估分类模型的细节，如果需要的话，你可以翻到第 [5](05.html) 章并刷新你的记忆。我们将在后续章节中构建一个自动情感文本分类系统。实现这一目标的主要步骤如下。

1.  准备训练和测试数据集(可选的验证数据集)
2.  预处理和规范化文本文档
3.  特征工程
4.  模特培训
5.  模型预测和评估

这些是建立我们系统的主要步骤。可选地，最后一步是在您的服务器或云上部署模型。图 [7-4](#Fig4) 显示了使用监督学习(分类)模型构建标准文本分类系统的详细工作流程。

![A448827_1_En_7_Fig4_HTML.jpg](A448827_1_En_7_Fig4_HTML.jpg)

图 7-4。

Blueprint for building an automated text classification system (Source: Text Analytics with Python, Apress 2016)

在我们的场景中，文档指示电影评论，类指示评论情绪，可以是正面的，也可以是负面的，这使得它成为一个二元分类问题。我们将在后续章节中使用传统的机器学习方法和更新的深度学习来建立模型。您可以参考标题为`supervised_sentiment_analysis.py`的 Python 文件来获得本节中使用的所有代码，或者使用标题为`Sentiment Analysis - Supervised.ipynb`的 jupyter 笔记本来获得更具交互性的体验。在开始之前，让我们加载必要的依赖项和设置。

```py
In [1]: import pandas as pd
   ...: import numpy as np
   ...: import text_normalizer as tn
   ...: import model_evaluation_utils as meu
   ...:
   ...: np.set_printoptions(precision=2, linewidth=80)

```

我们现在可以加载我们的 IMDb 电影评论数据集，使用前 35，000 条评论作为训练模型，剩余的 15，000 条评论作为测试数据集来评估模型性能。除此之外，我们还将使用我们的标准化模块来标准化我们的审查数据集(我们工作流中的步骤 1 和 2)。

```py
In [2]: dataset = pd.read_csv(r'movie_reviews.csv')
   ...:
   ...: # take a peek at the data
   ...: print(dataset.head())
   ...: reviews = np.array(dataset['review'])
   ...: sentiments = np.array(dataset['sentiment'])
   ...:
   ...: # build train and test datasets
   ...: train_reviews = reviews[:35000]
   ...: train_sentiments = sentiments[:35000]
   ...: test_reviews = reviews[35000:]
   ...: test_sentiments = sentiments[35000:]
   ...:
   ...: # normalize datasets
   ...: norm_train_reviews = tn.normalize_corpus(train_reviews)
   ...: norm_test_reviews = tn.normalize_corpus(test_reviews)
                                              review sentiment
0  One of the other reviewers has mentioned that ...  positive
1  A wonderful little production. <br /><br />The...  positive
2  I thought this was a wonderful way to spend ti...  positive
3  Basically there's a family where a little boy ...  negative
4  Petter Mattei's "Love in the Time of Money" is...  positive

```

我们的数据集现在已经准备好并标准化了，因此我们可以从前面描述的文本分类工作流中的步骤 3 开始构建我们的分类系统。

## 传统的监督机器学习模型

在这一部分，我们将使用传统的分类模型对电影评论的情感进行分类。我们的特征工程技术(步骤 3)将基于单词袋模型和 TF-IDF 模型，我们在第 4 章[的“文本数据的特征工程”一节中对此进行了广泛的讨论。下面的代码片段帮助我们在`train`和`test`数据集上使用这些模型来设计特征。](04.html)

```py
In [3]: from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
   ...:
   ...: # build BOW features on train reviews
   ...: cv = CountVectorizer(binary=False, min_df=0.0, max_df=1.0, ngram_range=(1,2))
   ...: cv_train_features = cv.fit_transform(norm_train_reviews)
   ...: # build TFIDF features on train reviews
   ...: tv = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0, ngram_range=(1,2),
   ...:                      sublinear_tf=True)
   ...: tv_train_features = tv.fit_transform(norm_train_reviews)
   ...:
   ...: # transform test reviews into features
   ...: cv_test_features = cv.transform(norm_test_reviews)
   ...: tv_test_features = tv.transform(norm_test_reviews)
   ...:
   ...: print('BOW model:> Train features shape:', cv_train_features.shape,
              ' Test features shape:', cv_test_features.shape)
   ...: print('TFIDF model:> Train features shape:', tv_train_features.shape,
              ' Test features shape:', tv_test_features.shape)

BOW model:> Train features shape: (35000, 2114021)  Test features shape: (15000, 2114021)
TFIDF model:> Train features shape: (35000, 2114021)  Test features shape: (15000, 2114021)

```

对于我们的特征集，我们考虑单词以及二元模型。我们现在可以使用一些传统的监督机器学习算法，这些算法在文本分类方面非常有效。当您将来处理自己的数据集时，我们建议使用逻辑回归、支持向量机和多项式朴素贝叶斯模型。在这一章中，我们使用逻辑回归和 SVM 建立模型。下面的代码片段有助于初始化这些分类模型估计器。

```py
In [4]: from sklearn.linear_model import SGDClassifier, LogisticRegression
   ...:
   ...: lr = LogisticRegression(penalty='l2', max_iter=100, C=1)
   ...: svm = SGDClassifier(loss='hinge', n_iter=100)

```

在不涉及太多理论复杂性的情况下，逻辑回归模型是一种用于分类的监督线性机器学习模型，无论其名称如何。在这个模型中，我们试图预测一个给定的电影评论属于一个离散类(在我们的场景中是二进制类)的概率。这里展示了模型用于学习的函数。

![$$ P\left(y= positive\;\left|X\right.\right)=\upsigma\;\left({\theta}^T\;X\right) $$](A448827_1_En_7_Chapter_Equa.gif)

![$$ P\left(y= negative\;\left|X\right.\right)=1-\upsigma\;\left({\theta}^T\;X\right) $$](A448827_1_En_7_Chapter_Equb.gif)

其中模型试图使用特征向量![$$ X $$](A448827_1_En_7_Chapter_IEq1.gif)和![$$ \sigma (z)=\frac{1}{1+{e}^{-z}} $$](A448827_1_En_7_Chapter_IEq2.gif)来预测情感类别，这通常被称为 sigmoid 函数或 logistic 函数或 logit 函数。该模型的主要目的是搜索![$$ \theta $$](A448827_1_En_7_Chapter_IEq3.gif)的最优值，使得当特征向量![$$ X $$](A448827_1_En_7_Chapter_IEq4.gif)针对正面电影评论时正面情感类别的概率最大，而当其针对负面电影评论时正面情感类别的概率最小。逻辑函数有助于对描述最终预测类的概率进行建模。![$$ \theta $$](A448827_1_En_7_Chapter_IEq5.gif)的最佳值可以通过使用标准方法(如梯度下降)最小化适当的成本\损失函数来获得(如果您对更多细节感兴趣，请参考第 [5](05.html) 章中的“逻辑回归的三个阶段”一节)。逻辑回归通常也被称为 logit 回归或`MaxEnt`(最大熵)分类器。

现在，我们将使用`model_evaluation_utils`模块中的效用函数`train_predict_model(...)`来构建训练特征的逻辑回归模型，并评估测试特征的模型性能(步骤 4 和 5)。见图 [7-5](#Fig5) 。

![A448827_1_En_7_Fig5_HTML.jpg](A448827_1_En_7_Fig5_HTML.jpg)

图 7-5。

Model performance metrics for logistic regression on Bag of Words features

```py
In [5]: # Logistic Regression model on BOW features
   ...: lr_bow_predictions = meu.train_predict_model(classifier=lr,
   ...:                        train_features=cv_train_features, train_labels=train_sentiments,
   ...:                        test_features=cv_test_features, test_labels=test_sentiments)
   ...: meu.display_model_performance_metrics(true_labels=test_sentiments,
   ...:                                      predicted_labels=lr_bow_predictions,
   ...:                                      classes=['positive', 'negative'])

```

如图 [7-5](#Fig5) 所示，我们得到了总体 F1 分数和 91%的模型准确度，这真是太棒了！我们现在可以使用下面的代码片段在 TF-IDF 特性上构建一个类似的逻辑回归模型。见图 [7-6](#Fig6) 。

![A448827_1_En_7_Fig6_HTML.jpg](A448827_1_En_7_Fig6_HTML.jpg)

图 7-6。

Model performance metrics for logistic regression on TF-IDF features

```py
In [6]: # Logistic Regression model on TF-IDF features
   ...: lr_tfidf_predictions = meu.train_predict_model(classifier=lr,
   ...:                         train_features=tv_train_features, train_labels=train_sentiments,
   ...:                         test_features=tv_test_features, test_labels=test_sentiments)
   ...: meu.display_model_performance_metrics(true_labels=test_sentiments,  
   ...:                                      predicted_labels=lr_tfidf_predictions,
   ...:                                      classes=['positive', 'negative'])

```

如图 [7-6](#Fig6) 所示，我们得到了总体 F1 分数和 90%的模型准确性，这很好，但我们之前的模型仍然略好。您可以类似地使用我们之前创建的支持向量机模型估计器对象`svm`，并使用相同的代码片段通过 SVM 模型进行训练和预测。我们用 SVM 模型获得了最大的准确性和 90%的 F1 分数(参考 jupyter 笔记本的分步代码片段)。因此，您可以看到这些监督机器学习分类算法在构建文本情感分类器方面是多么有效和准确。

## 更新的监督深度学习模型

在之前的章节中，我们已经多次提到深度学习如何在过去十年中彻底改变了机器学习的格局。在这一节中，我们将构建一些深度神经网络，并在一些基于单词嵌入的高级文本特征上训练它们，以构建一个类似于我们在上一节中所做的文本情感分类系统。在开始分析之前，让我们加载以下必要的依赖项。

```py
In [7]: import gensim
   ...: import keras
   ...: from keras.models import Sequential
   ...: from keras.layers import Dropout, Activation, Dense
   ...: from sklearn.preprocessing import LabelEncoder
Using TensorFlow backend.

```

如果你还记得在第 4 章[的](04.html)中，我们谈到了分类标签的编码和一次性编码方案。到目前为止，我们在`scikit-learn`中的模型直接接受情感类标签为`positive`和`negative`，并在内部执行这些操作。然而，对于我们的深度学习模型，我们需要明确地这样做。下面的代码片段帮助我们标记我们的电影评论，并将基于文本的情感类别标签转换为独热编码向量(构成步骤 2 的一部分)。

```py
In [8]: le = LabelEncoder()
   ...: num_classes=2
   ...: # tokenize train reviews & encode train labels
   ...: tokenized_train = [tn.tokenizer.tokenize(text)
   ...:                    for text in norm_train_reviews]
   ...: y_tr = le.fit_transform(train_sentiments)
   ...: y_train = keras.utils.to_categorical(y_tr, num_classes)
   ...: # tokenize test reviews & encode test labels
   ...: tokenized_test = [tn.tokenizer.tokenize(text)
   ...:                    for text in norm_test_reviews]
   ...: y_ts = le.fit_transform(test_sentiments)
   ...: y_test = keras.utils.to_categorical(y_ts, num_classes)
   ...:
   ...: # print class label encoding map and encoded labels
   ...: print('Sentiment class label map:', dict(zip(le.classes_, le.transform(le.classes_))))
   ...: print('Sample test label transformation:\n'+'-'*35,
   ...:       '\nActual Labels:', test_sentiments[:3], '\nEncoded Labels:', y_ts[:3],
   ...:       '\nOne hot encoded Labels:\n', y_test[:3])
Sentiment class label map: {'positive': 1, 'negative': 0}
Sample test label transformation:
-----------------------------------
Actual Labels: ['negative' 'positive' 'negative']
Encoded Labels: [0 1 0]
One hot encoded Labels:
 [[ 1\.  0.]
  [ 0\.  1.]
  [ 1\.  0.]]

```

因此，我们可以从前面的样本输出中看到，我们的情感类别标签是如何被编码成数字表示的，这些数字表示又被转换成独热编码向量。我们将在本节(步骤 3)中使用的特征工程技术是基于单词嵌入概念的稍微高级一些的单词向量化技术。我们将使用`word2vec`和手套模型来生成嵌入。这个`word2vec`模型是由 Google 建立的，我们已经在第 [4](04.html) 章的“单词嵌入”一节中详细介绍过了。在这个场景中，我们将选择 size 参数为 500，表示每个单词的特征向量大小为 500。

```py
In [9]: # build word2vec model
   ...: w2v_num_features = 500
   ...: w2v_model = gensim.models.Word2Vec(tokenized_train, size=w2v_num_features, window=150,
   ...:                                    min_count=10, sample=1e-3)

```

我们将在此模型上使用第 [4](04.html) 章中的文档词向量平均方案，将每个电影评论表示为评论中不同词的所有词向量表示的平均向量。下面的函数帮助我们计算任何文本文档语料库的平均单词向量表示。

```py
def averaged_word2vec_vectorizer(corpus, model, num_features):
    vocabulary = set(model.wv.index2word)
    def average_word_vectors(words, model, vocabulary, num_features):
        feature_vector = np.zeros((num_features,), dtype="float64")
        nwords = 0\.        
        for word in words:
            if word in vocabulary:
                nwords = nwords + 1.
                feature_vector = np.add(feature_vector, model[word])
        if nwords:
            feature_vector = np.divide(feature_vector, nwords)
        return feature_vector

    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)
                    for tokenized_sentence in corpus]
    return np.array(features)

```

现在，我们可以使用前面的函数在两个电影评论数据集上生成平均单词向量表示。

```py
In [10]: # generate averaged word vector features from word2vec model
    ...: avg_wv_train_features = averaged_word2vec_vectorizer(corpus=tokenized_train,
    ...:                                                 model=w2v_model, num_features=500)
    ...: avg_wv_test_features = averaged_word2vec_vectorizer(corpus=tokenized_test,
    ...:                                                 model=w2v_model, num_features=500)

```

代表全局向量的手套模型是用于获得单词向量表示的无监督模型。该模型由斯坦福大学创建，在维基百科、公共爬虫和 Twitter 等各种语料库上进行训练，并且相应的预训练词向量可用于我们的分析需求。你可以参考 Jeffrey Pennington、Richard Socher 和 Christopher D. Manning 的原始论文。2014 年，称为[手套:单词表示的全球矢量](https://nlp.stanford.edu/pubs/glove.pdf#_blank)，了解更多细节。`spacy`库提供了使用 GloVe 模型在通用爬行语料库上训练的 300 维单词向量。它们提供了一个简单的标准接口来获取每个单词的大小为 300 的特征向量以及整个文本文档的平均特征向量。下面的代码片段利用`spacy`为我们的两个数据集获取手套嵌入。请注意，您也可以通过利用其他预训练的模型来构建自己的手套模型，或者通过使用 [`https://nlp.stanford.edu/projects/glove`](https://nlp.stanford.edu/projects/glove) 提供的资源在您自己的语料库上构建模型，其中包含预训练的单词嵌入、代码和示例。

```py
In [11]: # feature engineering with GloVe model
    ...: train_nlp = [tn.nlp(item) for item in norm_train_reviews]
    ...: train_glove_features = np.array([item.vector for item in train_nlp])
    ...:
    ...: test_nlp = [tn.nlp(item) for item in norm_test_reviews]
    ...: test_glove_features = np.array([item.vector for item in test_nlp])

```

您可以使用下面的代码，基于前面的每个模型来检查我们的数据集的特征向量维度。

```py
In [12]: print('Word2Vec model:> Train features shape:', avg_wv_train_features.shape,
               ' Test features shape:', avg_wv_test_features.shape)
    ...: print('GloVe model:> Train features shape:', train_glove_features.shape,
               ' Test features shape:', test_glove_features.shape)
Word2Vec model:> Train features shape: (35000, 500)  Test features shape: (15000, 500)
GloVe model:> Train features shape: (35000, 300)  Test features shape: (15000, 300)

```

我们可以从前面的输出中看到，正如预期的那样,`word2vec`模型特征的尺寸是 500，手套特征的尺寸是 300。现在，我们可以进入分类系统工作流程的第 4 步，我们将根据这些特征构建并训练一个深度神经网络。我们已经在第 [1](01.html) 章“深度学习”一节中简要介绍了深度神经网络的各个方面和架构。我们将为我们的模型使用一个全连接的四层深度神经网络(多层感知器或深度 ANN)。在任何深层架构中，我们通常不计算输入层，因此我们的模型将由三个 512 个神经元或单元的隐藏层和一个具有两个单元的输出层组成，这两个单元将用于基于输入层特征预测积极或消极情绪。图 [7-7](#Fig7) 描绘了我们用于情感分类的深度神经网络模型。

![A448827_1_En_7_Fig7_HTML.jpg](A448827_1_En_7_Fig7_HTML.jpg)

图 7-7。

Fully connected deep neural network model for sentiment classification

我们称之为全连接深度神经网络(DNN ),因为每对相邻层中的神经元或单元是完全成对连接的。这些网络也被称为深度人工神经网络(ann)或多层感知器(MLPs)，因为它们有一个以上的隐藏层。下面的函数在`tensorflow`之上利用 keras 来构建期望的 DNN 模型。

```py
def construct_deepnn_architecture(num_input_features):
    dnn_model = Sequential()
    dnn_model.add(Dense(512, activation='relu', input_shape=(num_input_features,)))
    dnn_model.add(Dropout(0.2))
    dnn_model.add(Dense(512, activation='relu'))
    dnn_model.add(Dropout(0.2))
    dnn_model.add(Dense(512, activation='relu'))
    dnn_model.add(Dropout(0.2))
    dnn_model.add(Dense(2))
    dnn_model.add(Activation('softmax'))

    dnn_model.compile(loss='categorical_crossentropy', optimizer='adam',                 
                      metrics=['accuracy'])
    return dnn_model

```

从前面的函数中，您可以看到我们接受了一个参数`num_input_features`，它决定了输入层中所需的单元数量(`500`用于`word2vec`，而`300`用于`glove`特征)。我们构建了一个`Sequential`模型，它帮助我们线性堆叠我们的隐藏层和输出层。

我们对所有隐藏层使用`512`单位，激活函数`relu`表示一个校正的线性单位。该函数通常定义为![$$ relu(x)=\max\;\left(0,x\right) $$](A448827_1_En_7_Chapter_IEq6.gif)，其中 x 通常是神经元的输入。在电子和电气工程中，这也就是通常所说的斜坡函数。与以前流行的 sigmoid 函数相比，这个函数现在是优选的，因为它试图解决消失梯度问题。这个问题发生在![$$ x>0 $$](A448827_1_En_7_Chapter_IEq7.gif)时，随着 x 的增加，sigmoids 的梯度变得非常小(几乎消失)，但 relu 防止这种情况发生。除此之外，它还有助于更快地收敛梯度下降。我们也在网络中以`Dropout`层的形式使用正则化。通过增加`0.2`的退出率，它在训练模型期间的每次更新时随机地将输入特征单元的`20%`设置为`0`。这种正则化形式有助于防止模型过度拟合。

最终输出层由两个具有`softmax`激活功能的单元组成。softmax 函数基本上是我们前面看到的逻辑函数的推广，可用于表示 n 个可能的类结果的概率分布。在我们的例子![$$ n=2 $$](A448827_1_En_7_Chapter_IEq8.gif)中，类可以是正的也可以是负的，softmax 概率将帮助我们确定相同的类。二元 softmax 分类器也可互换地称为二元逻辑回归函数。

`compile(...)`方法用于在我们实际训练它之前配置 DNN 模型的学习或训练过程。这包括在损失参数中提供成本或损失函数。这将是模型试图最小化的目标或目的。基于您想要解决的问题类型，有各种损失函数，例如回归的均方误差和分类的分类交叉熵。查看 [`https://keras.io/losses/`](https://keras.io/losses/) 中可能的损失函数列表。

我们将使用`categorical_crossentropy`，它有助于我们将 softmax 输出的误差或损失降至最低。我们需要一个优化器来帮助我们收敛我们的模型并最小化损失或误差函数。梯度下降或随机梯度下降是一种流行的优化器。我们将使用`adam`优化器，它只需要一阶梯度和很少的内存。Adam 还使用动量，其中基本上每次更新不仅基于当前点的梯度计算，还包括先前更新的一部分。这有助于加快收敛。你可以参考来自 [`https://arxiv.org/pdf/1412.6980v8.pdf`](https://arxiv.org/pdf/1412.6980v8.pdf) 的原文，了解关于 ADAM 优化器的更多细节。最后，`metrics`参数用于指定模型性能度量，这些度量用于在训练时评估模型(但不用于修改训练损失本身)。现在，让我们基于我们的`word2vec`输入特征表示为我们的培训评审构建一个 DNN 模型。

```py
In [13]: w2v_dnn = construct_deepnn_architecture(num_input_features=500)

```

你也可以在`keras`的帮助下可视化 DNN 模型架构，类似于我们在第 [4 章](04.html)中所做的，使用下面的代码。参见图 [7-8](#Fig8) 。

![A448827_1_En_7_Fig8_HTML.jpg](A448827_1_En_7_Fig8_HTML.jpg)

图 7-8。

Visualizing the DNN model architecture using `keras`

```py
In [14]: from IPython.display import SVG
    ...: from keras.utils.vis_utils import model_to_dot
    ...:
    ...: SVG(model_to_dot(w2v_dnn, show_shapes=True, show_layer_names=False,
    ...:                  rankdir='TB').create(prog='dot', format='svg'))

```

我们现在将在由`avg_wv_train_features`表示的`word2vec`特征的训练评论数据集上训练我们的模型(步骤 4)。我们将在训练过程中使用`keras`中的`fit(...)`功能，有些参数你应该知道。`epoch`参数表示所有训练样本通过网络的一次完整的向前和向后传递。`batch_size`参数指示在一次反向和正向传递中通过 DNN 模型传播的样本总数，用于训练模型和更新梯度。因此，如果您有 1，000 个观测值，并且您的批量大小为 100，则每个历元将由 10 次迭代组成，其中 100 个观测值将一次通过网络，并且隐藏层单元上的权重将被更新。我们还指定了一个`0.1`的`validation_split`来提取训练数据的`10%`，并将其用作验证数据集来评估每个时期的性能。在训练模型时，`shuffle`参数有助于打乱每个时期的样本。

```py
In [18]: batch_size = 100
    ...: w2v_dnn.fit(avg_wv_train_features, y_train, epochs=5, batch_size=batch_size,
    ...:             shuffle=True, validation_split=0.1, verbose=1)
Train on 31500 samples, validate on 3500 samples
Epoch 1/5 31500/31500 - 11s - loss: 0.3097 - acc: 0.8720 - val_loss: 0.3159 - val_acc: 0.8646
Epoch 2/5 31500/31500 - 11s - loss: 0.2869 - acc: 0.8819 - val_loss: 0.3024 - val_acc: 0.8743
Epoch 3/5 31500/31500 - 11s - loss: 0.2778 - acc: 0.8857 - val_loss: 0.3012 - val_acc: 0.8763
Epoch 4/5 31500/31500 - 11s - loss: 0.2708 - acc: 0.8901 - val_loss: 0.3041 - val_acc: 0.8734
Epoch 5/5 31500/31500 - 11s - loss: 0.2612 - acc: 0.8920 - val_loss: 0.3023 - val_acc: 0.8763

```

前面的代码片段告诉我们，我们已经在五个时期的训练数据上训练了我们的 DNN 模型，批次大小为 100。我们得到了接近 88%的验证准确率，这是非常好的。是时候对我们的模型进行真正的测试了！让我们在测试评审`word2vec`特性上评估我们的模型性能(步骤 5)。

![A448827_1_En_7_Fig9_HTML.jpg](A448827_1_En_7_Fig9_HTML.jpg)

图 7-9。

Model performance metrics for deep neural networks on word2vec features

```py
In [19]: y_pred = w2v_dnn.predict_classes(avg_wv_test_features)
    ...: predictions = le.inverse_transform(y_pred)
    ...: meu.display_model_performance_metrics(true_labels=test_sentiments,
    ...:               predicted_labels=predictions, classes=['positive', 'negative'])

```

图 [7-9](#Fig9) 中描绘的结果显示，我们已经获得了 88%的模型准确性和 F1 值，这太棒了！您可以使用类似的工作流程来为我们基于手套的功能构建和训练 DNN 模型，并评估模型性能。下面的代码片段描述了我们的文本分类系统蓝图的步骤 4 和 5 的工作流程。

```py
# build DNN model
glove_dnn = construct_deepnn_architecture(num_input_features=300)
# train DNN model on GloVe training features
batch_size = 100
glove_dnn.fit(train_glove_features, y_train, epochs=5, batch_size=batch_size,
              shuffle=True, validation_split=0.1, verbose=1)
# get predictions on test reviews
y_pred = glove_dnn.predict_classes(test_glove_features)
predictions = le.inverse_transform(y_pred)
# Evaluate model performance
meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=predictions,
                                      classes=['positive', 'negative'])

```

我们使用手套功能获得了 85%的整体模型准确性和 F1 分数，这仍然很好，但并不比我们使用`word2vec`功能获得的结果更好。您可以参考`Sentiment Analysis - Supervised.ipynb` jupyter 笔记本来查看前面代码的分步输出。这结束了我们关于利用更新的深度学习模型和方法来构建文本情感分类系统的讨论。继续学习高级深度学习模型！

## 高级监督深度学习模型

在前面的部分中，我们已经使用了完全连接的深度神经网络和单词嵌入。另一种新的有趣的监督深度学习方法是使用递归神经网络(RNNs)和长短期记忆网络(LSTMs)，它也考虑数据的序列(单词、事件等)。这些是比你的常规全连接深度网络更高级的模型，通常需要更多的时间来训练。我们将利用`tensorflow`之上的`keras`，并尝试在这里建立一个基于 LSTM 的分类模型，并使用单词嵌入作为我们的特征。你可以参考标题为`sentiment_analysis_adv_deep_learning.py`的 Python 文件来获得本节使用的所有代码，或者使用标题为`Sentiment Analysis - Advanced Deep Learning.ipynb`的 jupyter 笔记本来获得更多的交互体验。

我们将致力于标准化和预处理的训练和测试评审数据集`norm_train_reviews`和`norm_test_reviews`，它们是我们在之前的分析中创建的。假设您已经加载了它们，我们将首先标记化这些数据集，以便将每个文本评论分解为相应的标记(工作流步骤 2)。

```py
In [1]: tokenized_train = [tn.tokenizer.tokenize(text) for text in norm_train_reviews]
    ...: tokenized_test = [tn.tokenizer.tokenize(text) for text in norm_test_reviews]

```

对于特征工程(步骤 3)，我们将创建单词嵌入。然而，我们将使用`keras`自己创建它们，而不是使用像`word2vec`或 GloVe 这样的预构建的，我们之前使用过。单词嵌入倾向于将文本文档矢量化成固定大小的向量，使得这些向量试图捕捉上下文和语义信息。

为了生成嵌入，我们将使用 keras 的`Embedding`层，它要求将文档表示为标记化的数字向量。在我们的`tokenized_train`和`tokenized_text`变量中已经有了标记化的文本向量。然而，我们需要将它们转换成数字表示。除此之外，我们还需要向量具有统一的大小，即使标记化的文本评论由于每个评论中标记数量的不同而具有可变的长度。为此，一种策略可以是取最长评论的长度(具有最大数量的标记\单词)并将其设置为向量大小，我们称之为`max_len`。长度较短的评论可以在开始时添加一个`PAD`术语，以将其长度增加到`max_len`。

我们需要创建一个单词到索引词汇表的映射，以数字形式表示每个标记化的文本评论。请注意，您还需要为填充项创建一个数字映射，我们称之为`PAD_INDEX`，并为其分配数字索引`0`。对于未知的术语，如果它们在测试数据集或者更新的、以前没有见过的评论中出现，我们也需要把它分配到一些索引中。这是因为我们将对特征进行矢量化处理，并且仅在训练数据上构建模型。因此，如果将来出现某个新术语(这原本不是模型训练的一部分)，我们会将其视为一个词汇表之外的(OOV)术语，并将其分配给一个常量索引(我们将这个术语命名为`NOT_FOUND_INDEX`，并将其分配给索引`vocab_size+1`)。下面的片段帮助我们从我们的`tokenized_train`训练文本评论语料库中创建这个词汇表。

```py
In [2]: from collections import Counter
   ...:
   ...: # build word to index vocabulary
   ...: token_counter = Counter([token for review in tokenized_train for token in review])
   ...: vocab_map = {item[0]: index+1
                      for index, item in enumerate(dict(token_counter).items())}
   ...: max_index = np.max(list(vocab_map.values()))
   ...: vocab_map['PAD_INDEX'] = 0
   ...: vocab_map['NOT_FOUND_INDEX'] = max_index+1
   ...: vocab_size = len(vocab_map)
   ...: # view vocabulary size and part of the vocabulary map
   ...: print('Vocabulary Size:', vocab_size)
   ...: print('Sample slice of vocabulary map:', dict(list(vocab_map.items())[10:20]))
Vocabulary Size: 82358
Sample slice of vocabulary map: {'martyrdom': 6, 'palmira': 7, 'servility': 8, 'gardening': 9, 'melodramatically': 73505, 'renfro': 41282, 'carlin': 41283, 'overtly': 41284, 'rend': 47891, 'anticlimactic': 51}

```

在这种情况下，我们已经使用了我们词汇表中的所有术语，您可以通过使用来自`Counter`的`most_common(count)`函数，并从训练语料库中的唯一术语列表中选取第一个`count`术语，来轻松地过滤和使用更多相关术语(基于它们的频率)。我们现在将根据之前的`vocab_map`对标记化的文本评论进行编码。除此之外，我们还将把文本情感分类标签编码成数字表示。

```py
In [3]: from keras.preprocessing import sequence
   ...: from sklearn.preprocessing import LabelEncoder
   ...:
   ...: # get max length of train corpus and initialize label encoder
   ...: le = LabelEncoder()
   ...: num_classes=2 # positive -> 1, negative -> 0
   ...: max_len = np.max([len(review) for review in tokenized_train])
   ...:
   ...: ## Train reviews data corpus
   ...: # Convert tokenized text reviews to numeric vectors
   ...: train_X = [[vocab_map[token] for token in tokenized_review]
                       for tokenized_review in tokenized_train]
   ...: train_X = sequence.pad_sequences(train_X, maxlen=max_len) # pad
   ...: ## Train prediction class labels
   ...: # Convert text sentiment labels (negative\positive) to binary encodings (0/1)
   ...: train_y = le.fit_transform(train_sentiments)
   ...:
   ...: ## Test reviews data corpus
   ...: # Convert tokenized text reviews to numeric vectors
   ...: test_X = [[vocab_map[token] if vocab_map.get(token) else vocab_map['NOT_FOUND_INDEX']
   ...:            for token in tokenized_review]
   ...:               for tokenized_review in tokenized_test]
   ...: test_X = sequence.pad_sequences(test_X, maxlen=max_len)
   ...: ## Test prediction class labels
   ...: # Convert text sentiment labels (negative\positive) to binary encodings (0/1)
   ...: test_y = le.transform(test_sentiments)
   ...:
   ...: # view vector shapes
   ...: print('Max length of train review vectors:', max_len)
   ...: print('Train review vectors shape:', train_X.shape,
               ' Test review vectors shape:', test_X.shape)

Max length of train review vectors: 1442
Train review vectors shape: (35000, 1442)  Test review vectors shape: (15000, 1442)

```

从前面的代码片段和输出可以清楚地看到，我们将每个文本评论编码成一个数字序列向量，因此每个评论向量的大小为`1442,`，这基本上是来自训练数据集的评论的最大长度。我们填充较短的评论并从较长的评论中截取额外的标记，使得每个评论的形状如输出中所描绘的那样是恒定的。现在，我们可以通过引入`Embedding`层并将其与基于 LSTMs 的深度网络架构相结合，继续进行分类工作流的步骤 3 和步骤 4 的一部分。

```py
from keras.models import Sequential
from keras.layers import Dense, Embedding, Dropout, SpatialDropout1D
from keras.layers import LSTM

EMBEDDING_DIM = 128 # dimension for dense embeddings for each token
LSTM_DIM = 64 # total LSTM units

model = Sequential()
model.add(Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM, input_length=max_len))
model.add(SpatialDropout1D(0.2))
model.add(LSTM(LSTM_DIM, dropout=0.2, recurrent_dropout=0.2))
model.add(Dense(1, activation="sigmoid"))

model.compile(loss="binary_crossentropy", optimizer="adam",
              metrics=["accuracy"])

```

`Embedding`层帮助我们从头开始生成单词嵌入。该层最初也用一些权重初始化，并且当网络试图最小化每个时期中的损失时，这基于我们的优化器进行更新，类似于其它层中神经元单元的权重。因此，嵌入层试图优化其权重，使得我们获得最佳的单词嵌入，这将在模型中产生最小的误差，并且还捕获单词之间的语义相似性和关系。我们如何得到嵌入，让我们考虑我们有一个带有`3`个术语`['movie', 'was', 'good']`和一个由`82358`个词的词到索引映射组成的`vocab_map`的评论。单词嵌入的生成有点类似于图 [7-10](#Fig10) 。

![A448827_1_En_7_Fig10_HTML.jpg](A448827_1_En_7_Fig10_HTML.jpg)

图 7-10。

Understanding how word embeddings are generated

基于我们的模型架构，`Embedding`层接受三个参数——`input_dim`，它等于`82358`的词汇大小(`vocab_size`)、`output_dim`，它是`128`，代表密集嵌入的维度(在图 [7-10](#Fig10) 的`EMBEDDING LAYER`中用行表示)，以及`input_len`，它指定输入序列(电影评论序列向量)的长度，它是`1442`。在图 [7-10](#Fig10) 所示的示例中，由于我们有一个审核，因此维度为`(1, 3)`。该审核根据`VOCAB_MAP`转换成数字序列`[2, 57, 121]`。然后从`EMBEDDING LAYER`(分别在列索引`2`、`57`和`121`处的向量)中选择代表审查序列中索引的特定列，以生成最终的单词嵌入。当基于每个序列字嵌入向量来表示每行时，这给了我们一个维度为`(1, 128, 3)`的嵌入向量，也表示为`(1, 3, 128)`。像 keras 这样的许多深度学习框架将嵌入维度表示为(m，n)，其中 m 表示我们词汇表中的所有唯一术语(`82358`)，n 表示`output_dim`，在这种情况下是`128`。考虑图 [7-10](#Fig10) 中描述的图层的转置版本，你就可以开始了！

通常，如果你有一个用一个热编码格式表示的编码的评论术语序列向量`(3, 82358)`，并且用表示为`(82358, 128)`的`EMBEDDING LAYER`做矩阵乘法，其中每一行表示一个单词在词汇表中的嵌入，你将直接获得评论序列向量的单词嵌入为`(3, 128)`。当像我们前面提到的那样通过整个网络传播时，嵌入层中的权重在每个时期基于输入数据得到更新和优化，使得整体损失和误差最小化，以获得最大的模型性能。

这些密集的单词嵌入然后被传递到具有`64`单元的`LSTM`层。我们已经在第 [1](01.html) 章“深度学习”下“重要概念”一节中标题为“长期短期记忆网络”的小节中向您简要介绍了 LSTM 架构。LSTMs 基本上试图克服 RNN 模型的缺点，特别是关于处理长期依赖性和当与单元(神经元)相关的权重矩阵变得太小(导致消失梯度)或太大(导致爆炸梯度)时发生的问题。这些架构比常规的深度网络更复杂，深入研究详细的内部结构和数学概念超出了当前的范围，但是我们将尝试在不使数学变得沉重的情况下在这里涵盖本质。如果你对 LSTMs 的内部研究感兴趣，可以看看 Hochreiter，s .和 Schmidhuber，J. (1997)的原始论文。长短期记忆。神经计算。9(8), 1735-1780.在图 [7-11](#Fig11) 中，我们描述了 RNNs 的基本架构，并将其与 LSTMs 进行了比较。

![A448827_1_En_7_Fig11_HTML.jpg](A448827_1_En_7_Fig11_HTML.jpg)

图 7-11。

Basic structure of RNN and LSTM units (Source: Christopher Olah’s blog: colah.github.io)

RNN 单元通常有一串重复的模块(这发生在我们展开循环的时候；参见第 [1](01.html) 章中的图 [1-13](01.html#Fig13) ，在这里我们会谈到这一点)以使模块具有一个简单的结构，可能有一层`tanh`激活。LSTM 也是一种特殊类型的 RNN，具有相似的结构，但是 LSTM 单元具有四个神经网络层，而不是只有一个。LSTM 单元的详细结构如图 [7-12](#Fig12) 所示。

![A448827_1_En_7_Fig12_HTML.jpg](A448827_1_En_7_Fig12_HTML.jpg)

图 7-12。

Detailed architecture of an LSTM cell (Source: Christopher Olah’s blog: colah.github.io)

LSTM 单元的详细架构如图 [7-12](#Fig12) 所示。符号 t 表示一个时间步长，C 表示单元状态，h 表示隐藏状态。门![$$ i,f,o\&\overset{\smile }{\mathrm{C}} $$](A448827_1_En_7_Chapter_IEq9.gif)有助于删除或添加细胞状态的信息。门 I、f & o 分别表示输入、输出和遗忘门，并且它们中的每一个都由 s 形层调制，该 s 形层输出从 0 到 1 的数字，控制来自这些门的多少输出应该通过。因此，这有助于保护和控制细胞状态。图 [7-13](#Fig13) 分四步描述了信息如何流经 LSTM 单元的详细工作流程。

1.  第一步讲的是遗忘门层 f，它帮助我们决定应该从细胞状态中丢弃哪些信息。这是通过查看先前的隐藏状态![$$ {h}_{t-1} $$](A448827_1_En_7_Chapter_IEq10.gif)和当前输入 x <sub>t</sub> 来完成的，如等式所示。乙状结肠层有助于控制应该保留或忘记多少。
2.  第二步描述输入栅极层 t，它有助于决定在当前单元状态中存储什么信息。输入门的 sigmoid 层有助于决定再次根据![$$ {h}_{t-1}\&{x}_t $$](A448827_1_En_7_Chapter_IEq11.gif)更新哪些值。tanh 层帮助创建基于![$$ {h}_{t-1}\&{x}_t $$](A448827_1_En_7_Chapter_IEq13.gif)的新候选值![$$ {\overset{\smile }{\mathrm{C}}}_t $$](A448827_1_En_7_Chapter_IEq12.gif)的向量，该向量可以添加到当前单元格状态。因此，tanh 层创建值，而具有 sigmoid 层的输入门帮助选择应该更新哪些值。
3.  第三步涉及利用我们在前两步中获得的信息，将旧的单元状态 C <sub>t ‐ 1</sub> 更新为新的单元状态 C <sub>t</sub> 。我们将旧的单元状态乘以遗忘门![$$ \left({f}_t\times {C}_{t\hbox{-} 1}\right) $$](A448827_1_En_7_Chapter_IEq14.gif)，然后添加由具有 s 形层的输入门![$$ \left({i}_t\times {\overset{\smile }{\mathrm{C}}}_t\right) $$](A448827_1_En_7_Chapter_IEq15.gif)缩放的新的候选值。
4.  第四步，也是最后一步，帮助我们决定什么应该是最终的输出，它基本上是我们细胞状态的过滤版本。具有 sigmoid 层 o 的输出门帮助我们选择单元状态的哪些部分将传递到最终输出。当通过 tanh 层时，它与单元状态值相乘，得到最终的隐藏状态值![$$ {h}_t={o}_t\times \tanh\;\left({\overset{\smile }{\mathrm{C}}}_t\right) $$](A448827_1_En_7_Chapter_IEq16.gif)。

图 [7-13](#Fig13) 描述了详细工作流程中的所有步骤，并附有必要的注释和等式。我们要感谢我们的好朋友 Christopher Olah 为我们提供了详细的信息以及描绘 LSTM 网络内部运作的图像。我们建议在 [`http://colah.github.io/posts/2015-08-Understanding-LSTMs`](http://colah.github.io/posts/2015-08-Understanding-LSTMs) 查看 Christopher 的博客了解更多详情。另外，埃德温·陈(Edwin Chen)用简单易懂的方式解释了 RNNs 和 LSTMs。我们建议参考 Edwin 在 [`http://blog.echen.me/2017/05/30/exploring-lstms`](http://blog.echen.me/2017/05/30/exploring-lstms) 的博客，了解 rnn 和 LSTMs 的工作方式。

![A448827_1_En_7_Fig13_HTML.jpg](A448827_1_En_7_Fig13_HTML.jpg)

图 7-13。

Walkthrough of data flow in an LSTM cell (Source: Christopher Olah’s blog: colah.github.io)

我们深度网络中的最后一层是具有`1`单元和 sigmoid 激活函数的`Dense`层。我们基本上使用`binary_crossentropy`函数和`adam`优化器，因为这是一个二元分类问题，模型将最终预测`0`或`1`，我们可以用我们的标签编码器将其解码为负面或正面的情绪预测。你也可以在这里使用`categorical_crossentropy`损失函数，但是你需要使用一个带有`2`单元的`Dense`层来代替一个`softmax`函数。现在我们的模型已经编译好了，我们可以进入分类工作流程的第 4 步，实际训练模型。我们使用与我们之前的深度网络模型类似的策略，其中我们使用五个时期的训练数据训练我们的模型，100 个评论的批量大小，以及训练数据的 10%验证分割来测量验证准确性。

```py
In [4]: batch_size = 100
   ...: model.fit(train_X, train_y, epochs=5, batch_size=batch_size,
   ...:           shuffle=True, validation_split=0.1, verbose=1)
Train on 31500 samples, validate on 3500 samples
Epoch 1/5 31500/31500 - 2491s - loss: 0.4081 - acc: 0.8184 - val_loss: 0.3006 - val_acc: 0.8751
Epoch 2/5 31500/31500 - 2489s - loss: 0.2253 - acc: 0.9158 - val_loss: 0.3209 - val_acc: 0.8780
Epoch 3/5 31500/31500 - 2656s - loss: 0.1431 - acc: 0.9493 - val_loss: 0.3483 - val_acc: 0.8671
Epoch 4/5 31500/31500 - 2604s - loss: 0.1023 - acc: 0.9658 - val_loss: 0.3803 - val_acc: 0.8729
Epoch 5/5 31500/31500 - 2701s - loss: 0.0694 - acc: 0.9761 - val_loss: 0.4430 - val_acc: 0.8706

```

众所周知，在 CPU 上训练 LSTMs 是非常慢的，正如你所看到的，我的模型在具有 8 GB 内存的 i5 第三代英特尔 CPU 上仅训练五个时期就花费了大约 3.6 小时。当然，像 Google Cloud Platform 或 AWS on GPU 这样的基于云的环境花了我大约不到一个小时来训练相同的模型。所以我建议你选择一个基于 GPU 的深度学习环境，尤其是在使用基于 RNNs 或 LSTM 的网络架构时。基于前面的输出，我们可以看到，仅用五个时期，我们就有相当好的验证准确性，但是训练准确性开始上升，表明可能发生了一些过度拟合。克服这一点的方法包括添加更多的数据或提高丢弃率。一定要试一试，看看它是否有效！是时候测试我们的模型了！让我们看看它对我们的测试评论的情绪的预测有多好，并使用我们对以前的模型使用的相同的模型评估框架(步骤 5)。

![A448827_1_En_7_Fig14_HTML.jpg](A448827_1_En_7_Fig14_HTML.jpg)

图 7-14。

Model performance metrics for LSTM based Deep Learning model on word embeddings

```py
In [5]: # predict sentiments on test data
   ...: pred_test = model.predict_classes(test_X)
   ...: predictions = le.inverse_transform(pred_test.flatten())
   ...: # evaluate model performance
   ...: meu.display_model_performance_metrics(true_labels=test_sentiments,
   ...:                    predicted_labels=predictions, classes=['positive', 'negative'])

```

图 [7-14](#Fig14) 中描绘的结果显示，我们已经获得了 88%的模型准确性和 F1-得分，这相当不错！有了更多高质量的数据，您可以期望获得更好的结果。尝试不同的架构，看看是否会得到更好的结果！

## 分析情感原因

我们建立了监督和非监督模型，根据评论文本内容预测电影评论的情感。虽然特性工程和建模绝对是当前的需要，但是您还需要知道如何分析和解释模型预测工作背后的根本原因。在这一部分，我们分析情感因果关系。这个想法是为了确定导致积极或消极情绪的根本原因或关键因素。第一个重点领域是模型解释，我们将试图理解、解释和说明我们的分类模型所做预测背后的机制。第二个重点领域是应用主题建模，并从正面和负面的情感评论中提取关键主题。

### 解释预测模型

机器学习模型的挑战之一是从试点或概念验证阶段过渡到生产阶段。商业和关键利益相关者经常将机器学习模型视为复杂的黑盒，并提出这样的问题，我为什么要相信你的模型？向他们解释复杂的数学或理论概念没有用。有什么方法可以让我们以一种容易理解的方式解释这些模型吗？事实上，这个话题在 2016 年最近获得了广泛关注。参考 M.T. Ribeiro、S. Singh 和 C. Guestrin 的原始研究论文，题为“我为什么应该相信你？:解释任何分类器的预测”从 [`https://arxiv.org/pdf/1602.04938.pdf`](https://arxiv.org/pdf/1602.04938.pdf) 了解有关模型解释和 LIME 框架的更多信息。查看第 [5](05.html) 章中关于模型解释的更多内容，我们将详细介绍对各种模型进行出色解释的溜冰者框架。

有各种方式来解释我们的预测性情感分类模型所做出的预测。我们想更多地了解为什么一个积极的评论被正确地预测为有积极的情绪，或者一个消极的评论有消极的情绪。除此之外，没有一个模型总是 100%准确的，所以我们也想了解错误分类或错误预测的原因。本节中使用的代码可以在名为`sentiment_causal_model_interpretation.py`的文件中找到，或者您也可以参考名为`Sentiment Causal Analysis - Model Interpretation.ipynb`的 jupyter 笔记本来获得交互体验。

让我们首先为目前为止最适合我们的模型构建一个基本的文本分类管道。这是基于词袋特征模型的逻辑回归模型。我们将利用来自`scikit-learn`的管道模块，使用以下代码来构建这个机器学习管道。

```py
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline

# build BOW features on train reviews
cv = CountVectorizer(binary=False, min_df=0.0, max_df=1.0, ngram_range=(1,2))
cv_train_features = cv.fit_transform(norm_train_reviews)
# build Logistic Regression model
lr = LogisticRegression()
lr.fit(cv_train_features, train_sentiments)

# Build Text Classification Pipeline
lr_pipeline = make_pipeline(cv, lr)

# save the list of prediction classes (positive, negative)
classes = list(lr_pipeline.classes_)

```

我们基于`norm_train_reviews`构建我们的模型，它包含我们在所有早期分析中使用的标准化培训回顾。现在我们已经准备好了我们的分类管道，你可以通过使用 pickle 或 joblib 来保存分类器和特征对象来实际部署模型，类似于我们在第 [5 章](05.html)的“模型部署”一节中所讨论的。假设我们的管道在生产中，我们如何使用它来进行新的电影评论？让我们尝试预测两个新的样本评论的情绪(在训练模型时没有使用)。

```py
In [3]: lr_pipeline.predict(['the lord of the rings is an excellent movie',
   ...:                      'i hated the recent movie on tv, it was so bad'])
Out[3]: array(['positive', 'negative'], dtype=object)

```

我们的分类管道正确地预测了两个评论的情绪！这是一个好的开始，但是我们如何解释模型预测呢？一种方法是通常使用模型预测类概率作为置信度的度量。您可以使用下面的代码来获得我们的示例评论的预测概率。

```py
In [4]: pd.DataFrame(lr_pipeline.predict_proba(['the lord of the rings is an excellent movie',
   ...:                      'i hated the recent movie on tv, it was so bad']), columns=classes)
Out[4]:
   negative  positive
0  0.169653  0.830347
1  0.730814  0.269186

```

因此，我们可以说，与具有 73%的概率具有负面情绪的第二电影评论相比，第一电影评论具有 83%的预测置信度或概率具有正面情绪。现在让我们更进一步，而不是玩玩具例子，我们现在将对来自`test_reviews`数据集的实际评论运行相同的分析(我们将使用`norm_test_reviews`，它有规范化的文本评论)。除了预测概率，我们还将使用`skater`框架来轻松解释模型决策，类似于我们在第 [5](05.html) 章“模型解释”一节中所做的。您需要首先从`skater`包中加载以下依赖项。我们还定义了一个助手函数，它接收文档索引、语料库、响应预测和解释器对象，并帮助我们进行模型解释分析。

```py
from skater.core.local_interpretation.lime.lime_text import LimeTextExplainer

explainer = LimeTextExplainer(class_names=classes)
# helper function for model interpretation
def interpret_classification_model_prediction(doc_index, norm_corpus, corpus,
                                              prediction_labels, explainer_obj):
    # display model prediction and actual sentiments
    print("Test document index: {index}\nActual sentiment: {actual}
                                       \nPredicted sentiment: {predicted}"
      .format(index=doc_index, actual=prediction_labels[doc_index],
              predicted=lr_pipeline.predict([norm_corpus[doc_index]])))
    # display actual review content
    print("\nReview:", corpus[doc_index])
    # display prediction probabilities
    print("\nModel Prediction Probabilities:")
    for probs in zip(classes, lr_pipeline.predict_proba([norm_corpus[doc_index]])[0]):
        print(probs)
    # display model prediction interpretation
    exp = explainer.explain_instance(norm_corpus[doc_index],
                                     lr_pipeline.predict_proba, num_features=10,
                                     labels=[1])
    exp.show_in_notebook()

```

前面的代码片段利用`skater`来解释我们的文本分类器，以一种易于解释的形式来分析它的决策过程。即使从全局的角度来看，模型可能是一个复杂的模型，但是在本地实例上解释和近似模型行为还是比较容易的。这是通过学习感兴趣的数据点 X 附近的模型来完成的，通过对 X 周围的实例进行采样，并基于它们的接近度 toX 分配权重。因此，这些局部学习的线性模型有助于以更容易解释的方式解释复杂的模型，其中类概率、顶级特征对类概率的贡献有助于决策过程。让我们从测试数据集中选取一个电影评论，其中实际和预测的情绪都是负面的，并使用我们在前面的代码片段中创建的 helper 函数对其进行分析。

![A448827_1_En_7_Fig15_HTML.jpg](A448827_1_En_7_Fig15_HTML.jpg)

图 7-15。

Model interpretation for our classification model’s correct prediction for a negative review

```py
In [6]: doc_index = 100
   ...: interpret_classification_model_prediction(doc_index=doc_index, corpus=norm_test_reviews,
                                         corpus=test_reviews, prediction_labels=test_sentiments,
                                         explainer_obj=explainer)

Test document index: 100
Actual sentiment: negative
Predicted sentiment: ['negative']

Review: Worst movie, (with the best reviews given it) I've ever seen. Over the top dialog, acting, and direction. more slasher flick than thriller. With all the great reviews this movie got I'm appalled that it turned out so silly. shame on you Martin Scorsese

Model Prediction Probabilities:
('negative', 0.8099323456145181)
('positive', 0.19006765438548187)

```

图 [7-15](#Fig15) 中描绘的结果向我们展示了类别预测概率以及对预测决策过程贡献最大的前 10 个特征。这些关键特征也在标准化的电影评论文本中突出显示。我们的模型在这种情况下表现很好，我们可以看到导致该评论负面情绪的关键特征，包括`bad, silly, dialog`和`shame`，这很有意义。除此之外，单词`great`对 0.19 的阳性概率贡献最大，事实上，如果我们从我们的评论文本中删除这个单词，阳性概率会显著下降。

下面的代码对实际和预测情绪都为正值的测试电影评论进行了类似的分析。

![A448827_1_En_7_Fig16_HTML.jpg](A448827_1_En_7_Fig16_HTML.jpg)

图 7-16。

Model interpretation for our classification model’s correct prediction for a positive review

```py
In [7]: doc_index = 2000
   ...: interpret_classification_model_prediction(doc_index=doc_index, corpus=norm_test_reviews,
                                         corpus=test_reviews, prediction_labels=test_sentiments,
                                         explainer_obj=explainer)

Test document index: 2000
Actual sentiment: positive
Predicted sentiment: ['positive']

Review: I really liked the Movie "JOE." It has really become a cult classic among certain age groups.<br /><br />The Producer of this movie is a personal friend of mine. He is my Stepsons Father-In-Law. He lives in Manhattan's West side, and has a Bungalow. in Southampton, Long Island. His son-in-law live next door to his Bungalow.<br /><br />Presently, he does not do any Producing, But dabbles in a business with HBO movies.<br /><br />As a person, Mr. Gil is a real gentleman and I wish he would have continued in the production business of move making.

Model Prediction Probabilities:
('negative', 0.020629181561415355)
('positive', 0.97937081843858464)

```

图 [7-16](#Fig16) 中描述的结果显示了模型做出正面评估决定的主要特征。根据内容，评论者真的很喜欢这个模型，而且它在某些年龄组中是一个真正的邪教经典。在我们的最终分析中，我们将查看模型对一个示例的解释，在该示例中，模型做出了错误的预测。

![A448827_1_En_7_Fig17_HTML.jpg](A448827_1_En_7_Fig17_HTML.jpg)

图 7-17。

Model interpretation for our classification model’s incorrect prediction

```py
In [8]: doc_index = 347
   ...: interpret_classification_model_prediction(doc_index=doc_index, corpus=norm_test_reviews,
                                         corpus=test_reviews, prediction_labels=test_sentiments,
                                         explainer_obj=explainer)

Test document index: 347
Actual sentiment: negative
Predicted sentiment: ['positive']

Review: When I first saw this film in cinema 11 years ago, I loved it. I still think the directing and cinematography are excellent, as is the music. But it's really the script that has over the time started to bother me more and more. I find Emma Thompson's writing self-absorbed and unfaithful to the original book; she has reduced Marianne to a side-character, a second fiddle to her much too old, much too severe Elinor - she in the movie is given many sort of 'focus moments', and often they appear to be there just to show off Thompson herself.<br /><br />I do understand her cutting off several characters from the book, but leaving out the one scene where Willoughby in the book is redeemed? For someone who red and cherished the book long before the movie, those are the things always difficult to digest.<br /><br />As for the actors, I love Kate Winslet as Marianne. She is not given the best script in the world to work with but she still pulls it up gracefully, without too much sentimentality. Alan Rickman is great, a bit old perhaps, but he plays the role beautifully. And Elizabeth Spriggs, she is absolutely fantastic as always.

Model Prediction Probabilities:
('negative', 0.067198213044844413)
('positive', 0.93280178695515559)

```

前面的输出告诉我们，我们的模型预测电影评论表明积极的情绪，而事实上实际情绪标签对同一评论是消极的。图 [7-17](#Fig17) 中描绘的结果告诉我们，事实上影评人在影评中表现出积极情绪的迹象，尤其是在他/她告诉我们“我喜欢它”的部分。我仍然认为导演和摄影非常出色，音乐也是如此...艾伦·瑞克曼很棒，也许有点老，但他把这个角色演得很好。还有伊丽莎白·斯普里格斯，她一如既往地棒极了。”并且来自相同的特征词已经被描绘在有助于正面情绪的顶部特征中。模型解释也正确地识别了评论中导致负面情绪的方面，例如，“但是随着时间的推移，这个脚本真的开始越来越让我烦恼。”。因此，这是一篇比较复杂的评论，既有正面的也有负面的观点，最终的解释将掌握在读者手中。您现在可以使用这个相同的框架来解释您自己的分类模型，并了解您的模型在哪些地方表现良好，哪些地方需要改进！

### 分析主题模型

分析与情感相关的关键术语、概念或主题的另一种方法是使用一种不同的方法，称为主题建模。我们已经在第四章[的“文本数据的特征工程”中标题为“主题模型”的章节中介绍了主题建模的一些基础知识。主题模型的主要目的是提取和描述在巨大的文本文档语料库中潜在的和不太突出的关键主题或概念。在第四章](04.html)[中，我们已经看到了潜在狄利克雷分配(LDA)在主题建模中的应用。在本节中，我们使用另一个主题建模技术，称为非负矩阵分解。请参考名为`sentiment_causal_topic_models.py`的 Python 文件或名为`Sentiment Causal Analysis - Topic Models.ipynb`的 jupyter 笔记本，以获得更多交互体验。](04.html)

该分析的第一步是将我们所有的标准化`train`和`test`评论结合起来，并将这些评论分成正面和负面的情感评论。完成后，我们将使用 TF-IDF 特征矢量器从这两个数据集中提取特征。下面的片段有助于我们实现这一点。

```py
In [11]: from sklearn.feature_extraction.text import TfidfVectorizer
    ...:
    ...: # consolidate all normalized reviews
    ...: norm_reviews = norm_train_reviews+norm_test_reviews
    ...: # get tf-idf features for only positive reviews
    ...: positive_reviews = [review for review, sentiment in zip(norm_reviews, sentiments)
                                 if sentiment == 'positive']
    ...: ptvf = TfidfVectorizer(use_idf=True, min_df=0.05, max_df=0.95,
                                ngram_range=(1,1), sublinear_tf=True)
    ...: ptvf_features = ptvf.fit_transform(positive_reviews)
    ...: # get tf-idf features for only negative reviews
    ...: negative_reviews = [review for review, sentiment in zip(norm_reviews, sentiments)
                                 if sentiment == 'negative']
    ...: ntvf = TfidfVectorizer(use_idf=True, min_df=0.05, max_df=0.95,
                                ngram_range=(1,1), sublinear_tf=True)
    ...: ntvf_features = ntvf.fit_transform(negative_reviews)
    ...: # view feature set dimensions
    ...: print(ptvf_features.shape, ntvf_features.shape)

(25000, 331) (25000, 331)

```

从前面的输出维度中，您可以看到我们已经过滤掉了许多以前在构建分类模型时使用的特征，方法是将`min_df`设为`0.05`，将`max_df`设为`0.95`。这是为了加速主题建模过程，并删除出现过多或过少的特性。现在让我们为主题建模过程导入必要的依赖项。

```py
In [12]: import pyLDAvis
    ...: import pyLDAvis.sklearn
    ...: from sklearn.decomposition import NMF
    ...: import topic_model_utils as tmu
    ...:
    ...: pyLDAvis.enable_notebook()
    ...: total_topics = 10

```

来自`scikit-learn`的`NMF`类将帮助我们进行主题建模。我们还使用`pyLDAvis`来构建主题模型的交互式可视化。非负矩阵分解(NNMF)背后的核心原理是将矩阵分解(类似于 SVD)应用于非负特征矩阵 X，使得分解可以表示为 X ≈ WH，其中 W & H 都是非负矩阵，如果相乘，应该近似地重构特征矩阵 X。可以使用像 L2 范数这样的成本函数来获得这个近似。现在让我们应用 NNMF 从我们的积极情绪评论中获得 10 个话题。我们还将利用`topic_model_utils`模块中的一些实用函数，以简洁的格式显示结果。

```py
In [13]: # build topic model on positive sentiment review features
    ...: pos_nmf = NMF(n_components=total_topics,
    ...:           random_state=42, alpha=0.1, l1_ratio=0.2)
    ...: pos_nmf.fit(ptvf_features)      
    ...: # extract features and component weights
    ...: pos_feature_names = ptvf.get_feature_names()
    ...: pos_weights = pos_nmf.components_
    ...: # extract and display topics and their components
    ...: pos_topics = tmu.get_topics_terms_weights(pos_weights, pos_feature_names)
    ...: tmu.print_topics_udf(topics=pos_topics, total_topics=total_topics,
    ...:                  num_terms=15, display_weights=False)
Topic #1 without weights
['like', 'not', 'think', 'really', 'say', 'would', 'get', 'know', 'thing', 'much', 'bad', 'go', 'lot', 'could', 'even']

Topic #2 without weights
['movie', 'see', 'watch', 'great', 'good', 'one', 'not', 'time', 'ever', 'enjoy', 'recommend', 'make', 'acting', 'like', 'first']

Topic #3 without weights
['show', 'episode', 'series', 'tv', 'watch', 'dvd', 'first', 'see', 'time', 'one', 'good', 'year', 'remember', 'ever', 'would']

Topic #4 without weights
['performance', 'role', 'play', 'actor', 'cast', 'good', 'well', 'great', 'character', 'excellent', 'give', 'also', 'support', 'star', 'job']
...
Topic #10 without weights
['love', 'fall', 'song', 'wonderful', 'beautiful', 'music', 'heart', 'girl', 'would', 'watch', 'great', 'favorite', 'always', 'family', 'woman']

```

我们描述了前面输出中生成的 10 个主题中的一些主题。您现在可以利用`pyLDAvis`在交互式可视化中可视化这些主题。参见图 [7-18](#Fig18) 。

![A448827_1_En_7_Fig18_HTML.jpg](A448827_1_En_7_Fig18_HTML.jpg)

图 7-18。

Visualizing topic models on positive sentiment movie reviews

```py
In [14]: pyLDAvis.sklearn.prepare(pos_nmf, ptvf_features, ptvf, R=15)

```

图 [7-18](#Fig18) 中描绘的可视化向我们展示了正面电影评论中的 10 个主题，我们可以看到在输出中突出显示了主题 6 的最高相关术语。从主题和术语中，我们可以看到像电影演员、演员、表演、戏剧、人物、音乐、精彩、好等等术语对各种主题的积极情绪做出了贡献。这很有意思，让你很好地了解了评论的组成部分，这些部分有助于评论的积极情绪。如果您使用 jupyter 笔记本，这种可视化是完全交互式的，您可以单击左侧主题间距离图中代表主题的任何气泡，并在右侧条形图中查看每个主题中最相关的术语。

左边的图是使用多维缩放(MDS)渲染的。相似的话题应该彼此靠近，不相似的话题应该远离。每个主题气泡的大小基于该主题及其组件在整个语料库中的频率。

右侧的可视化显示了排名靠前的术语。当没有选择主题时，它显示语料库中前 15 个最显著的主题。术语的显著性被定义为术语在语料库中出现的频率的度量，以及当用于区分主题时的区分因素。当选择某个主题时，图表会发生变化，显示类似于图 [7-13](#Fig13) 的内容，其中显示了与该主题最相关的前 15 个术语。相关性指标由λ控制，可以基于条形图顶部的滑块进行更改(请参考笔记本以进行交互)。如果您对这些可视化背后的更多数学理论感兴趣，我们鼓励您在 [`https://cran.r-project.org/web/packages/LDAvis/vignettes/details.pdf`](https://cran.r-project.org/web/packages/LDAvis/vignettes/details.pdf) 查看更多细节，这是 R 包`LDAvis`的一个小插曲，它已经作为`pyLDAvis`移植到 Python。

现在，让我们从电影评论数据集中提取主题，并对负面情绪评论进行同样的分析。

![A448827_1_En_7_Fig19_HTML.jpg](A448827_1_En_7_Fig19_HTML.jpg)

图 7-19。

Visualizing topic models on positive sentiment movie reviews

```py
In [15]: # build topic model on negative sentiment review features
    ...: neg_nmf = NMF(n_components=10,
    ...:           random_state=42, alpha=0.1, l1_ratio=0.2)
    ...: neg_nmf.fit(ntvf_features)      
    ...: # extract features and component weights
    ...: neg_feature_names = ntvf.get_feature_names()
    ...: neg_weights = neg_nmf.components_
    ...: # extract and display topics and their components
    ...: neg_topics = tmu.get_topics_terms_weights(neg_weights, neg_feature_names)
    ...: tmu.print_topics_udf(topics=neg_topics,
    ...:                  total_topics=total_topics,
    ...:                  num_terms=15,
    ...:                  display_weights=False)
Topic #1 without weights
['get', 'go', 'kill', 'guy', 'scene', 'take', 'end', 'back', 'start', 'around', 'look', 'one', 'thing', 'come', 'first']

Topic #2 without weights
['bad', 'movie', 'ever', 'acting', 'see', 'terrible', 'one', 'plot', 'effect', 'awful', 'not', 'even', 'make', 'horrible', 'special']
...
Topic #10 without weights
['waste', 'time', 'money', 'watch', 'minute', 'hour', 'movie', 'spend', 'not', 'life', 'save', 'even', 'worth', 'back', 'crap']

In [16]: pyLDAvis.sklearn.prepare(neg_nmf, ntvf_features, ntvf, R=15)

```

图 [7-19](#Fig19) 中描绘的可视化向我们展示了负面电影评论中的 10 个主题，我们可以看到在输出中突出显示了主题 8 的最高相关术语。从主题和术语中，我们可以看到像浪费、时间、金钱、废话、情节、可怕、表演等术语在各种主题中导致了负面情绪。当然，正面和负面情感评论的主题重叠的可能性很高，但会有可区分的不同主题，进一步帮助我们进行解释和因果分析。

## 摘要

这一面向案例研究的章节介绍了 IMDb 电影评论数据集，目的是基于文本内容预测评论的情绪。我们在本章中涵盖了自然语言处理(NLP)、文本分析、机器学习和深度学习的概念和技术。我们涵盖了自然语言处理的多个方面，包括文本预处理、规范化、特征工程以及文本分类。使用 Afinn、SentiWordNet 和`VADER`等情感词汇的无监督学习技术得到了广泛的详细介绍，以展示我们如何在缺乏标记训练数据的情况下分析情感，这是当今组织中一个非常有效的问题。详细的工作流程图将文本分类描述为有监督的机器学习问题，帮助我们将 NLP 与机器学习相关联，以便我们可以使用机器学习技术和方法来解决当有标记数据可用时预测情感的问题。

对监督方法的关注有两个方面。这包括传统的机器学习方法和模型，如逻辑回归和支持向量机，以及更新的深度学习模型，包括深度神经网络、RNNs 和 LSTMs。详细的概念，工作流程，实践的例子和比较分析与多监督模型和不同的特征工程技术已经涵盖的目的是预测情绪的电影评论与最大的模型性能。本章的最后一节涵盖了机器学习的一个非常重要的方面，这个方面在我们的分析中经常被忽略。我们研究了分析和解释积极或消极情绪原因的方法。分析和可视化模型解释和主题模型已经通过几个例子进行了介绍，让您深入了解如何在自己的数据集上重用这些框架。本章中使用的框架和方法应该对你将来处理自己的文本数据的类似问题有用。