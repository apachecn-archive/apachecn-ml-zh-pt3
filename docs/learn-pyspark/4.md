# 4.气流

本章重点介绍气流以及如何使用它来处理复杂的数据工作流。Airflow 由 Airbnb 的工程师在内部开发，以高效的方式管理内部工作流程。Airflow 后来在 2016 年成为 Apache 的一部分，并作为开源提供给用户。基本上，Airflow 是一个用于执行、调度、分发和监控各种作业的框架，其中可以有多个相互依赖或相互独立的任务。使用 Airflow 运行的每个作业都必须通过有向无环图(DAG)定义文件进行定义，该文件包含您要运行的集合，并按关系和依赖关系进行分组。

这一章集中讨论三个主题。我将从检查工作流开始，然后讨论气流的基本构件:DAG。然后，您将了解气流的用户界面方面。在最后一节中，我将介绍为作业定义 DAG 的代码，以及如何使用 Airflow 来执行和监控它。

## 工作流程

我们周围看到的大多数事物都有一个过程。火车在固定的时间间隔运行，飞机在固定的时间飞行，道路上的信号在有规律的周期变化。如果需要一致性，过程是至关重要的，尤其是当不同任务之间存在依赖关系时。在软件或技术领域，在构建或执行项目时，也遵循一套固定的流程。如果我们再往下一些，我们可以称这些过程为工作流。为了达到预期的效果，必须设计和执行适当的工作流程。很少看到开发人员或工程师不遵循标准的过程来构建解决方案或应用程序。例如，在数据处理工作流的典型场景中，开发人员将在执行任务之前定义步骤，如图 [4-1](#Fig1) 所示。这些步骤通常被称为管道，由必须完成的任务序列组成。

![../images/478390_1_En_4_Chapter/478390_1_En_4_Fig1_HTML.jpg](../images/478390_1_En_4_Chapter/478390_1_En_4_Fig1_HTML.jpg)

图 4-1

示例工作流程

第一项任务是从源文件中读取数据，然后将其复制到您的平台或所需的位置。一旦数据可用，您就可以接收它，并通过多个步骤对其进行清理和转换。然后执行分析并计算结果。最后，将输出保存到所需的位置。传统上，执行这些步骤的方式是借助 cron 作业(由 cron 守护进程以预定的时间间隔运行的命令)。因此，所有任务都是作为 cron 作业运行的脚本的一部分。尽管它服务于以特定顺序执行事物的目的，但它仍然面临许多实际挑战。最常见的是脚本执行的中断。没有明确的方法来重试脚本运行。另一个挑战是监控正在运行的作业的状态。很难确定执行时的阶段和每个阶段的持续时间。还存在其他挑战，例如通过集中式调度程序运行多个 cron 作业，用于更大和更复杂的管道，以及适应工作流中的持续变化。由于上面提到的所有困难，Airflow 作为一个框架诞生了，它可以用来调度和监控这类任务，并平稳地运行管道，以获得一致的输出。要真正理解气流和 Dag 是如何工作的，您首先必须从总体上理解图形。

## 图表概述

典型的图形数据结构由两个实体组成，如图 [4-2](#Fig2) 所示。

![../images/478390_1_En_4_Chapter/478390_1_En_4_Fig2_HTML.jpg](../images/478390_1_En_4_Chapter/478390_1_En_4_Fig2_HTML.jpg)

图 4-2

图的结构

1.  优势

2.  节点/顶点

边本质上是节点/顶点之间的连接，而节点是实际数据驻留的地方。我们可以将基于图的网络分为两大类:

1.  无向图

2.  有向图

### 无向图

在这种图结构中，边或连接没有任何方向，如图 [4-2](#Fig2) 所示。这种关系将存在于两端。例如，如果节点 1 中的人 1 是节点 2 中的人 2 的朋友，那么人 2 也将是人 1 的朋友。

### 有向图

有向图要么是循环的，要么是非循环的。边的方向起着重要的作用，因为图中所有的边都是单向的，如图 [4-3](#Fig3) 所示。

![../images/478390_1_En_4_Chapter/478390_1_En_4_Fig3_HTML.jpg](../images/478390_1_En_4_Chapter/478390_1_En_4_Fig3_HTML.jpg)

图 4-3

有向图

循环图有一个或多个循环。一个循环是一条路径，起点和终点都在同一个节点，如图 [4-4](#Fig4) 所示。信息从节点 1 流向节点 2，但从节点 2 返回到节点 1 还有另一条路。这就是所谓的循环图。

![../images/478390_1_En_4_Chapter/478390_1_En_4_Fig4_HTML.jpg](../images/478390_1_En_4_Chapter/478390_1_En_4_Fig4_HTML.jpg)

图 4-4

循环图

Dag 中没有周期，因此其优势包括:

*   动态框架(作为代码的配置)

*   可扩展性——它们支持不同类型的任务执行。

*   可伸缩性—它们可以执行无限多的任务(工作节点)。

现在让我们把注意力转向 DAGs。

## DAG 概述

因为 DAG 是一个有向图，信息只能向一个方向流动，那就是向前，如图 [4-5](#Fig5) 所示。因此，如果必须到达节点 4，则路径是 1 ➤ 2 ➤ 4。在 Dag 中，没有返回起始节点的反向路径。

![../images/478390_1_En_4_Chapter/478390_1_En_4_Fig5_HTML.jpg](../images/478390_1_En_4_Chapter/478390_1_En_4_Fig5_HTML.jpg)

图 4-5

DAG 中的信息流

气流中作业的所有任务必须在 DAG 中定义。因此，执行顺序是以 DAG 形式定义的。例如，如果必须执行任务 8，则必须首先完成任务 1 和任务 3，而对于要完成的任务 7，除了任务 3 之外，不必依赖于其他任务。因此，如图 [4-5](#Fig5) 所示，一些独立任务(2，3)可以不考虑彼此的状态而发生。在使用气流执行任务之前，可以很好地定义任务的执行顺序和相互依赖关系。

所有与 DAG 相关的配置都在一个 DAG 定义文件中定义，这是一个 Python 扩展。它包含所有的依赖项和配置参数，例如失败时要发送的电子邮件、开始时间、结束时间和重试次数。除了任务的依赖关系或顺序之外，我们还必须定义作为 DAG 一部分的所有任务。

### 经营者

如前所述，DAG 可以包含多个任务。这些任务可能完全不同。其中一个任务可以是简单的 Python 脚本；另一个可以是外壳脚本或 SQL 查询；另一个可以是基于云的 Spark 作业。这些任务是在 DAG 定义文件中使用运算符定义的。气流为不同类型的任务提供了一系列操作员。最常见的有以下几种:

1.  Python 运算符(Python 脚本)

2.  Bash 操作符(Shell 脚本)

3.  SQL 运算符

4.  码头操作员

5.  云运营商(S3、Azure、谷歌)

与其他调度程序相比，Airflow 运行任何类型任务的灵活性使它非常强大。

DAG 文件只是一个包含运行 DAG 所需的所有配置参数的 Python 脚本。要创建 DAG，必须执行几个标准步骤，如下所示:

1.  导入所需模块

2.  声明默认参数

3.  实例化 DAG 对象

4.  定义所有任务

5.  声明执行顺序/任务依赖关系

在某些领域，就更智能地处理上游和下游依赖关系以及运行历史负载的能力而言，与替代方案相比，Airflow 脱颖而出。它还以完全透明的方式处理失败和阻塞。

## 安装气流

有多种方式可以使用气流，因为它的设计可以轻松地与不同的环境相结合。如果我们想在本地使用气流，我们可以在本地安装和配置气流环境。另一个选择是利用 Docker，将 Airflow 应用程序容器化，并在任何平台上运行，而不管环境如何。使用 Docker 的核心好处是它自己承担了管理依赖性和部署的额外负担。

### 使用 Docker 的气流

运行 Airflow 的一种方法是创建自己的 Docker 映像，其中包含所有的依赖项和组件，但是可以从 Docker Hub 中获得一个 Airflow Docker 映像，使其非常容易运行。运行气流的步骤如下:

```
[In]: docker pull puckel/docker-airflow
[In]:docker run -d -p 8080:8080 puckel/docker-airflow webserver

```

一旦你在终端中运行了前面的命令，你就可以通过`http://127.0.0.1:8080`访问端口 8080，如图 [4-6](#Fig6) 所示。

![../images/478390_1_En_4_Chapter/478390_1_En_4_Fig6_HTML.png](../images/478390_1_En_4_Chapter/478390_1_En_4_Fig6_HTML.png)

图 4-6

气流 UI

这就是气流 UI 的样子。它目前没有 Dag，是一个普通版本。如果您想查看默认情况下在气流中出现的示例 Dag，您只需在运行 Docker 时添加一个额外的参数。要查看哪些容器正在运行，我们可以使用以下代码:

```
[In]: docker ps

```

列出所有容器后，您可以使用以下命令停止/终止之前容器运行的气流

```
[In]: docker kill <containerID>

```

现在我们运行下面的命令，将`LOAD_EX=y`作为附加参数，如下所示:

```
[In]: docker run -d -p 8080:8080 -e LOAD_EX=y puckel/docker-airflow

```

如果我们现在访问 Airflow UI，我们会得到一个所有默认 Dag 的列表，如图 [4-7](#Fig7) 所示。

![../images/478390_1_En_4_Chapter/478390_1_En_4_Fig7_HTML.png](../images/478390_1_En_4_Chapter/478390_1_En_4_Fig7_HTML.png)

图 4-7

气流 DAGs

#### 气流设置(Mac)

第一步是确保机器上安装了 Python，我们可以使用`brew install`命令安装`python3`。一旦安装了 Python，我们就可以安装气流。它需要一个主目录。`~/airflow`是默认位置，但也可以根据喜好选择不同的位置。

```
[In]:  brew install python python3
[In]: pip install airflow
[In]: mkdir ~/airflow
[In]: export AIRFLOW_HOME=~/airflow
 [In]: cd ~/airflow
[In]: airflow initdb
[In]: airflow webserver -p 8080

```

最后两步是使用`initdb`初始化 Airflow，并在首选端口上访问 UI。

## 创建您的第一个 DAG

正如本章前面所讨论的，DAG 由按特定顺序排列的多个任务组成，如图 [4-8](#Fig8) 所示。

![../images/478390_1_En_4_Chapter/478390_1_En_4_Fig8_HTML.jpg](../images/478390_1_En_4_Chapter/478390_1_En_4_Fig8_HTML.jpg)

图 4-8

任务

为了创建 DAG，您必须定义一个包含与 DAG 任务相关的所有详细信息的 DAG 文件，并且必须在文件(Python 脚本)中定义依赖关系。这是一个将 DAG 的结构指定为代码的配置文件。运行 DAG 必须采取的五个步骤如图 [4-9](#Fig9) 所示。

![../images/478390_1_En_4_Chapter/478390_1_En_4_Fig9_HTML.png](../images/478390_1_En_4_Chapter/478390_1_En_4_Fig9_HTML.png)

图 4-9

气流步骤

为了更好地理解内部原理，让我们来详细介绍一下这些步骤。

### 步骤 1:导入所需的库

第一步是导入运行 Airflow 所需的所有库。一些常见的包括 datetime、不同的操作符(Bash/Python)和 Airflow 本身。

```
[In]: from datetime import timedelta
[In]: import airflow
[In]: from airflow import DAG
[In]: from airflow.operators.bash_operator import BashOperator

```

### 步骤 2:定义默认参数

下一步是定义一些重要的参数，以确保 Airflow 以指定的时间间隔和适当的次数执行 Dag。

```
 [In]: args = {
    'owner': 'Pramod',
    'start_date': airflow.utils.dates.days_ago(3),
    # 'end_date': datetime(2018, 12, 30),
    'depends_on_past': False,
    'email': ['airflow@example.com'],
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
    }

```

### 步骤 3:创建 DAG

第三步是创建 DAG 本身，它由 DAG 的名称和计划间隔组成，如下所示。您可以根据自己的需求决定何时运行作业。

```
 [In]: dag = DAG(
    'pramod_airflow_dag',
    default_args=args,
    description='A simple DAG',
    # Continue to run DAG once per day
    schedule_interval=timedelta(days=1)

```

### 步骤 4:声明任务

下一步是声明要执行的任务(实际工作)。所有任务都可以声明，并成为上一步中创建的同一 DAG 的一部分。

```
 [In]: t1 = BashOperator(
    task_id='print_date',
    bash_command='date',
    dag=dag,
)

t2 = BashOperator(
    task_id='sleep',
    depends_on_past=False,
    bash_command='sleep 5',
    dag=dag,
) 

```

### 步骤 5:提及依赖关系

最后一步是设置任务执行的顺序。它们可以是并行任务，也可以是顺序任务。有多种方法可以定义任务。

```
 [In]: t1 >> t2

```

一旦前面的所有步骤都完成了，我们就可以启动 Airflow 并访问 web UI 了。图 [4-10](#Fig10) 所示的屏幕可用于刚刚创建的 DAG 文件。

![../images/478390_1_En_4_Chapter/478390_1_En_4_Fig10_HTML.png](../images/478390_1_En_4_Chapter/478390_1_En_4_Fig10_HTML.png)

图 4-10

气流 DAG

目前，它处于关闭阶段，我们可以手动或通过命令行界面(CLI)触发它。如果我们单击 DAG 本身，它会将我们带到 DAG 的默认树视图，其中列出了 DAG 中的所有任务，如图 [4-11](#Fig11) 所示。

![../images/478390_1_En_4_Chapter/478390_1_En_4_Fig11_HTML.png](../images/478390_1_En_4_Chapter/478390_1_En_4_Fig11_HTML.png)

图 4-11

树形视图

现在打开 DAG，启动任务，如图 [4-12](#Fig12) 所示。

![../images/478390_1_En_4_Chapter/478390_1_En_4_Fig12_HTML.jpg](../images/478390_1_En_4_Chapter/478390_1_En_4_Fig12_HTML.jpg)

图 4-12

DAG 初始化

然后点击触发 Dag 图标，开始执行，如图 [4-13](#Fig13) 所示。

![../images/478390_1_En_4_Chapter/478390_1_En_4_Fig13_HTML.jpg](../images/478390_1_En_4_Chapter/478390_1_En_4_Fig13_HTML.jpg)

图 4-13

DAG 触发器

DAG 被触发的那一刻，我们可以在最近的任务选项卡下看到变化，DAG 运行，如图 [4-14](#Fig14) 所示。

![../images/478390_1_En_4_Chapter/478390_1_En_4_Fig14_HTML.png](../images/478390_1_En_4_Chapter/478390_1_En_4_Fig14_HTML.png)

图 4-14

运行 DAG

一旦 DAG 开始运行，我们可以用不同的方式查看它，第一种形式是如图 [4-15](#Fig15) 所示的树形视图。

![../images/478390_1_En_4_Chapter/478390_1_En_4_Fig15_HTML.png](../images/478390_1_En_4_Chapter/478390_1_En_4_Fig15_HTML.png)

图 4-15

气流 UI

另一个视图是图形视图，以稍微不同的方式显示任务执行的顺序，任务的颜色表示其进度(成功/正在运行/失败等。)，如图 [4-16](#Fig16) 所示。

![../images/478390_1_En_4_Chapter/478390_1_En_4_Fig16_HTML.png](../images/478390_1_En_4_Chapter/478390_1_En_4_Fig16_HTML.png)

图 4-16

图表视图

我们还可以转到 DAG details 选项卡，更深入地了解 DAG 的其他详细信息，如图 [4-17](#Fig17) 所示。

![../images/478390_1_En_4_Chapter/478390_1_En_4_Fig17_HTML.png](../images/478390_1_En_4_Chapter/478390_1_En_4_Fig17_HTML.png)

图 4-17

日期详细信息选项卡

最后，在 Code 选项卡下，我们可以查看在运行 DAG 之前最初创建的 DAG Python 脚本，如图 [4-18](#Fig18) 所示。

![../images/478390_1_En_4_Chapter/478390_1_En_4_Fig18_HTML.png](../images/478390_1_En_4_Chapter/478390_1_En_4_Fig18_HTML.png)

图 4-18

DAG 代码

如果我们等待一段时间并重新检查图形视图，我们将观察到两个任务都已成功完成，如图 [4-19](#Fig19) 所示。在树形视图页签中，我们可以看到三天(最近两天和今天)的任务都已经完成，如图 [4-20](#Fig20) 所示。

![../images/478390_1_En_4_Chapter/478390_1_En_4_Fig20_HTML.png](../images/478390_1_En_4_Chapter/478390_1_En_4_Fig20_HTML.png)

图 4-20

树形视图

![../images/478390_1_En_4_Chapter/478390_1_En_4_Fig19_HTML.png](../images/478390_1_En_4_Chapter/478390_1_En_4_Fig19_HTML.png)

图 4-19

图表视图

## 结论

在本章中，您学习了如何定义 DAG 并使用 Airflow 运行不同的作业。还讲述了实施气流和监控不同任务状态的步骤。除了界面中的不同组件之外，还向您介绍了气流的 web UI。