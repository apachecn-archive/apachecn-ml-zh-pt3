# 4.文本分类和情感分析

在前一章中，我们重点介绍了如何使用图像数据来了解更多关于机器学习的知识，并构建一个图像分类器。在本章中，我们将讨论如何使用文本数据，涵盖自然语言处理的一些概念，并围绕情感分析进行一些实验。

## 4.1 什么是情感分析？

情感分析有时也被称为情感分类、意见挖掘或情感人工智能，是对一段文本中表达的情感进行解释和分类的过程，以确定写作者的整体情感——积极、消极或中性。

它使用自然语言处理来识别、提取和研究情感状态和主观信息。

自然语言处理(NLP)是人工智能的一个分支，其目标是给计算机编程以处理、分析和理解自然语言数据。

赋予计算机理解人类语言细微差别的能力是一项复杂的任务。它不仅仅是识别和提取句子中的关键词，而是分析和解释这些词背后的含义，例如，能够识别修辞格，检测讽刺，等等。

在这一章中，我们将主要关注将文本数据分为三类:阳性、阴性和中性，并研究毒性检测。

在深入研究如何使用 TensorFlow.js 在 JavaScript 中实现情感分析之前，让我们试着了解更多关于这项技术的机制。

## 4.2 自然语言处理是如何工作的？

我们表达自己的方式承载了大量的语境信息。从我们对词汇的选择到我们的语气，我们的词汇范围，以及我们构造句子的方式，人类的语言极其复杂，但也足够丰富，可以揭示我们的许多信息。

为了让计算机发展对语言及其复杂性的理解，自然语言处理使用了一些不同的技术和算法。我们先来定义一些概念。

### 4.2.1 常见概念-自然语言处理的基础

在深入探讨如何在 JavaScript 中实现一些自然语言处理之前，让我们先了解一些基本概念。

#### 词汇袋

如果你决定对 NLP 做一些额外的研究，你可能会遇到单词袋模型，因为它非常常用。

这是一种简化的表示，用于统计一段文本中所有单词的出现次数，不考虑语法。

这种方法似乎有点简单，因为它没有考虑任何语义和上下文，但它旨在根据文本中不同术语的使用频率来增加它们的权重。该信息然后被用作训练分类器的特征。

这个过程有时也被称为**矢量化**，因为它旨在将文本片段转换为固定长度的向量。

没有例子的概念很难理解，所以让我们用下面的四个句子来看看单词袋模型是如何应用的。

假设我们希望能够检测一段文本是否是垃圾邮件，我们已经做到了

*   赢得数百万美元

*   赢得一辆特斯拉

*   请求帮助

*   帮助数百万开发者

第一步是确定什么叫做我们的**词汇表**或**语料库**，意思是我们将要使用的所有单词的集合，在我们的例子中是

*   胜利

*   数百万

*   关于

*   美元

*   A

*   特斯拉

*   请求

*   为

*   帮助

*   开发商

一旦我们有了完整的词汇，我们就可以开始计算每个单词的出现次数。

表 4-1

代表前面列表中每个单词出现次数的表

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"> <col class="tcol5 align-left"> <col class="tcol6 align-left"> <col class="tcol7 align-left"> <col class="tcol8 align-left"> <col class="tcol9 align-left"> <col class="tcol10 align-left"> <col class="tcol11 align-left"></colgroup> 
| 

**文件**

 | 

**获胜**

 | 

**百万**

 | 

**共**

 | 

美元

 | 

**答**

 | 

**特斯拉**

 | 

**请求**

 | 

**为**

 | 

**帮助**

 | 

**开发者**

 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **赢得数百万美元** | one | one | one | one | Zero | Zero | Zero | Zero | Zero | Zero |
| **赢得一辆特斯拉** | one | Zero | Zero | Zero | one | Zero | Zero | Zero | Zero | Zero |
| **求助** | Zero | Zero | Zero | Zero | Zero | Zero | one | one | one | Zero |
| **帮助百万开发者** | Zero | one | one | Zero | Zero | Zero | Zero | Zero | one | one |

使用这种数据表示，我们能够创建以下向量:

*   **赢得数百万美元** : [1，1，1，1，0，0，0，0，0]

*   **赢一辆特斯拉** : [1，0，0，0，1，0，0，0，0，0，0]

*   **求助** : [0，0，0，0，0，0，1，1，1，0]

*   **帮助百万开发者**:【0，1，1，0，0，0，0，0，0，1，1】

然后，这些向量可以用作训练算法的特征。

前两句(“赢得数百万美元”和“赢得一辆特斯拉”)可以被标记为“垃圾邮件”，后两句(“请求帮助”和“帮助数百万开发者”)可以被标记为“非垃圾邮件”。

因此，用于训练算法的数据集可能如下所示。

表 4-2

代表垃圾邮件短语与非垃圾邮件短语中每个单词出现次数的表格

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"> <col class="tcol5 align-left"> <col class="tcol6 align-left"> <col class="tcol7 align-left"> <col class="tcol8 align-left"> <col class="tcol9 align-left"> <col class="tcol10 align-left"> <col class="tcol11 align-left"></colgroup> 
| 

标签

 | 

**获胜**

 | 

**百万**

 | 

**共**

 | 

美元

 | 

**答**

 | 

**特斯拉**

 | 

**请求**

 | 

**为**

 | 

**帮助**

 | 

**开发者**

 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 垃圾邮件 | one | one | one | one | Zero | Zero | Zero | Zero | Zero | Zero |
| 垃圾邮件 | one | Zero | Zero | Zero | one | Zero | Zero | Zero | Zero | Zero |
| 非垃圾邮件 | Zero | Zero | Zero | Zero | Zero | Zero | one | one | one | Zero |
| 非垃圾邮件 | Zero | one | one | Zero | Zero | Zero | Zero | Zero | one | one |

考虑到相似类型的单词在相似的文档中使用，单词袋方法可以帮助我们基于我们之前的示例数据集确定一个句子是否是垃圾邮件的可能性。

如果单词“win”经常包含在标记为垃圾邮件的文本中，则诸如“Win the trip of your dreams”之类的新句子是垃圾邮件的概率高于诸如“Feedback on performance”之类的另一个句子的概率。

需要注意的是，文中单词的顺序并不重要；只有这些词被使用的次数。

在实际应用中，数据集应该更大，包含更多样化的语料库，以提高预测的准确性。

#### 标记化

在自然语言处理中，两种常见的标记化类型包括句子标记化和单词标记化。

**句子标记化**，也称为句子切分，是将一个字符串分割成其组成句子的过程。一种方法是每当我们看到句号(。).

例如，像这样的段落

"*第 13 部*是 2016 年美国[纪录片](https://en.wikipedia.org/wiki/Documentary_film)导演[艾娃·德约列](https://en.wikipedia.org/wiki/Ava_DuVernay)。这部电影探索了“美国种族、正义和大规模监禁的交集；它是以 1865 年通过的美国宪法第十三修正案命名的，该修正案废除了美国各地的奴隶制，并终止了非自愿劳役，但作为对犯罪的惩罚除外

会被分割成以下两句话:

1.  “13 号是 2016 年美国[纪录片](https://en.wikipedia.org/wiki/Documentary_film)导演[艾娃·德约列](https://en.wikipedia.org/wiki/Ava_DuVernay)”

2.  这部电影探索了“美国种族、正义和大规模监禁的交集；它以 1865 年通过的美国宪法第十三修正案命名，该修正案废除了美国各地的奴隶制，并结束了除了作为对犯罪定罪的惩罚之外的[非自愿奴役](https://en.wikipedia.org/wiki/Involuntary_servitude)

**分词**，也叫分词，是把一个字符串分割成它的组成词的过程。这可以通过使用空格字符作为分隔符来拆分句子来实现。

例如，我们前面的第一句话“13 号是导演[艾娃·德约列](https://en.wikipedia.org/wiki/Ava_DuVernay)执导的 2016 年美国[纪录片](https://en.wikipedia.org/wiki/Documentary_film)”将导致以下输出。

```
["13th", "is", "a", "2016", "American", "documentary", "film", "by", "director", "Ava", "DuVernay"]

Listing 4-1Example array representing the output of word tokenization on the sentence “13th is a 2016 American documentary film by director Ava DuVernay”

```

#### 文本词汇化和词干化

文本词汇化和词干化是将单词的屈折形式简化为普通基本形式的技术。

由于相关单词可能有相似的意思，这些工具有助于将它们简化为一个单词。

例如:

*   “吃”，“吃”，“吃”变成了“吃”。

*   “计算机”，“计算机”，“计算机的”变成了“计算机”。

这种映射的结果看起来会像这样:

“都是**在自己**电脑**前吃**”=>“都是**在自己**电脑**前吃**”。

这种技术有助于我们寻找比精确输入更多的结果，例如，用搜索引擎。

当我们执行搜索时，我们通常感兴趣的是获得相关的结果，不仅是我们使用的确切搜索术语，还包括这些单词的其他可能形式。

例如，如果我使用单词“徒步欧洲”进行搜索，我也会对包含单词“徒步旅行”、“徒步旅行”或“徒步旅行者”等的结果感兴趣。

#### 停止言语

停用词是可以增加很多噪音的词，在文本中被认为是不相关的。它们在处理文本之前或之后被过滤掉。

停用词的示例包括“and”、“the”和“a”，但没有确定的列表，因为它会因语言和应用而异。

在过滤掉停用词的文本后，类似“他们明天上午 10 点在车站见面”的句子将会变成[“他们”、“正在”、“开会”、“车站”、“明天”、“上午 10 点”]。

正如我们所看到的，去掉停用词后，这个句子并没有失去任何意义。

由于机器学习操作可能很耗时，因此移除不改变文本语义的单词可以提高性能，而不会对预测的准确性产生负面影响。

## 4.3 在 TensorFlow.js 中实现情感分析

既然我们已经介绍了自然语言处理的一些基础知识，那么让我们使用 TensorFlow.js 研究几个用 JavaScript 实现情感分析的应用程序。

### 4.3.1 正极、负极和中性

作为第一个项目，让我们构建一个应用程序，它可以预测一段文本的整体情绪，并将其分为三类:积极、消极和中性。

#### 导入模型

与前一章中的其他项目类似，您需要做的第一件事是导入 TensorFlow.js 库，作为脚本标记或 npm 包。

```
<script src='https://cdn.jsdelivr.net/npm/@tensorflow/tfjs'></script>

Listing 4-2Importing TensorFlow.js as a script tag in an HTML file

```

或者

```
const tf = require('@tensorflow/tfjs');

Listing 4-3Importing TensorFlow.js as a package in a JavaScript file

```

#### 加载模型

然后，我们需要加载预训练的模型及其元数据。为此，我们可以创建两个不同的函数。

```
const loadMetadata = async () => {
  const url = 'https://storage.googleapis.com/tfjs-models/tfjs/sentiment_cnn_v1/metadata.json';
  const metadata = await fetch(url);
  return metadata.json();
};

Listing 4-5Function named loadMetadata to load the machine learning metadata

```

```
const loadModel = async () => {
  const url = `https://storage.googleapis.com/tfjs-models/tfjs/sentiment_cnn_v1/model.json`;
  const model = await tf.loadLayersModel(url);
  return model;
};

Listing 4-4Function named loadModel to load the machine learning model

```

#### 预言

现在我们有了运行预测所需的主要工具，我们还需要编写一些帮助函数，将输入文本转换为向量，就像我们在本章上一节中讨论的那样。

输入文本不能作为字符串输入算法，因为机器学习模型主要处理数字，所以让我们看看如何在 JavaScript 中执行矢量化。

要将一个字符串转换成固定长度的向量，我们需要首先将它分解成一个数组，数组中的元素将是所有的子字符串。

```
const text = 'Hello world';
const trimmed = text
  .trim()
  .toLowerCase()
  .replace(/(\.|\,|\!|\?)/g, "")
  .split(" ");

Listing 4-6Code sample to vectorize a string in JavaScript

```

这段代码会把一个类似“我从这次谈话中学到了很多”的字符串变成[“我”、“学到了”、“一个”、“很多”、“从”、“这个”、“谈话”]。

我们首先调用`trim()`函数来删除字符串开头和结尾潜在的空白。然后，我们将所有内容都变成小写，删除所有标点符号，并使用空格字符作为分隔符将其拆分为一个子字符串数组。

完成后，我们需要使用之前加载的元数据将这个数组转换成一个数字数组。

该元数据是一个 JSON 文件，其中包含用于训练模型的样本数据，我们正在将该模型加载到我们的应用程序中。它包含大约 20，000 个单词。

这一步的目标是将字符串中的每个单词映射到文件中的一个索引，代码如下。

```
const loadMetadata = async () => {
  const metadata = await fetch(
    "https://storage.googleapis.com/tfjs-models/tfjs/sentiment_cnn_v1/metadata.json"
  );
  return metadata.json();
};
const sequence = trimmed.map(async(word) => {
  const metadata = await loadMetadata();
  const wordIndex = metadata.word_index[word];
  if (typeof wordIndex === "undefined") {
    return 2; //oov index
  }
  return wordIndex + metadata.index_from;
});

Listing 4-7Code sample to map words to their index in the metadata file

```

该代码示例所做的是遍历我们之前创建的子字符串数组，并查看每个元素是否存在于元数据中。如果是，它将变量`wordIndex`设置为在元数据中找到的索引；否则，如果在用于训练模型的数据中没有找到来自我们输入文本的单词，它将把`wordIndex`的值设置为 2。

这个数字 2 将会是我们的索引，用来查找**未收录的** (OOV)单词。

在这一步之后，这个序列变量将类似于下面的示例。

```
[13, 12037, 6, 176, 39, 14, 740]

Listing 4-8Sample output produced by the code earlier

```

这些数字是元数据文件中每个单词的索引。正如我们所看到的，数字 2 不存在，这意味着句子“我从这次演讲中学到了很多”中的每个单词都存在于用于训练模型的数据集中。

在我们可以使用它来运行预测并获得整体情绪之前，我们需要做最后一步来转换数据。

如前所述，在训练机器学习模型时，您需要确保使用的数据具有相同的形状。

例如，如果您正在处理图像，您不能使用不同大小的图像(280x280 像素，然后 1200x800 像素，等等。)在您的数据集中。

同样的原则也适用于文本数据。我们的示例文本“我从这次谈话中学到了很多”的长度为 7；然而，我们的模型已经用长度为 100 的向量进行了训练。

这个值可以在 metadata.json 文件中找到，作为属性`max_len`的值。

这意味着用于训练模型的数据集中最长的字符串包含 100 个单词。

因为我们需要使用固定长度的向量，所以我们需要将长度为 7 的向量转换为长度为 100 的向量。

为此，我们需要编写一个函数，在向量长度等于 100 之前，预先添加一定数量的 0。

在清单 [4-7](#PC7) 中的代码示例之后，您可以编写下面的函数。

```
const padSequences = (sequences, metadata) => {
  return sequences.map((seq) => {
    if (seq.length > metadata.max_len) {
      seq.splice(0, seq.length - metadata.max_len);
    }
    if (seq.length < metadata.max_len) {
      const pad = [];
      for (let i = 0; i < metadata.max_len - seq.length; ++i) {
        pad.push(0);
      }
      seq = pad.concat(seq);
    }
    return seq;
  });
};

padSequences([sequence], metadata);

Listing 4-9Function to transform the data and create fixed-length vectors

```

这个函数应该用于长度小于 100 个单词的文本数据，但是长度超过 100 的字符串怎么办？

这种情况下的过程有点相反，我们循环遍历索引数组，当我们达到最大长度时，我们对数组进行切片并去掉其余的。

完成这个过程后，我们将用于机器学习模型的数组应该如下所示。

```
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 12037, 6, 176, 39, 14, 740]

Listing 4-10Output array after prepending 0s to create a fixed-length vector

```

正如我们所看到的，我们仍然有七个索引来代表我们的句子“我从这个演讲中学到了很多，但是加上了正确数量的 0，使得这个向量的长度为 100。

现在我们已经将数据转换成正确的向量，我们可以使用`tensor2d`方法将其转换成张量，并使用它来预测输入文本的情感。

```
const input = tf.tensor2d(paddedSequence, [1, metadata.max_len]);

const prediction = model.predict(input);
const score = prediction.dataSync()[0];
prediction.dispose();
return score;

Listing 4-11Code sample to transform the vector into a tensor and generate predictions

```

该分数将是一个介于 0 和 1 之间的浮点数。分数越接近 0，预测越负，越接近 1，预测越正。

我们的输入文本“我从这次谈话中学到了很多”的得分是 0.9912545084953308，这意味着为其预测的情绪是“积极的”。

像“这真的很糟糕”这样的句子产生的分数是 0.007734981831163168，这是“负面的”。

#### 完整示例

如果我们想把这段代码放在一个从用户那里收集输入文本的应用程序中，它应该是这样的。

如果我们假设在一个 HTML 文件中有一个简单的带有按钮的输入字段，就像这样。

```
<label for="text">Text</label>
<input type="text" name="text" />
<button>Predict</button>

Listing 4-12HTML tags to get text input from users and a button

```

对用户编写的文本进行情感分析的 JavaScript 代码如下。

```
const loadMetadata = async () => {
  const metadata = await fetch(
    "https://storage.googleapis.com/tfjs-models/tfjs/sentiment_cnn_v1/metadata.json"
  );
  return metadata.json();
};

const loadModel = async () => {
  const url = `https://storage.googleapis.com/tfjs-models/tfjs/sentiment_cnn_v1/model.json`;
  const model = await tf.loadLayersModel(url);
  return model;
};

const padSequences = (sequences, metadata) => {
  return sequences.map((seq) => {
    if (seq.length > metadata.max_len) {
      seq.splice(0, seq.length - metadata.max_len);
    }
    if (seq.length < metadata.max_len) {
      const pad = [];
      for (let i = 0; i < metadata.max_len - seq.length; ++i) {
        pad.push(0);
      }
      seq = pad.concat(seq);
    }

    return seq;
  });
};

const predict = (text, model, metadata) => {
  const trimmed = text
    .trim()
    .toLowerCase()
    .replace(/(\.|\,|\!|\?)/g, "")
    .split(" ");

  const sequence = trimmed.map((word) => {
    const wordIndex = metadata.word_index[word];
    if (typeof wordIndex === "undefined") {
      return 2; //oov_index
    }
    return wordIndex + metadata.index_from;
  });
  const paddedSequence = padSequences([sequence], metadata);
  const input = tf.tensor2d(paddedSequence, [1, metadata.max_len]);

  const predictOut = model.predict(input);
  const score = predictOut.dataSync()[0];
  predictOut.dispose();
  return score;
};

const getSentiment = (score) => {
  if (score > 0.66) {
    return `Score of ${score} is Positive`;
  } else if (score > 0.4) {
    return `Score of ${score} is Neutral`;
  } else {
    return `Score of ${score} is Negative`;
  }

};

const run = async (text) => {
  const model = await loadModel();
  const metadata = await loadMetadata();
  let sum = 0;
  text.forEach(function (prediction) {
    perc = predict(prediction, model, metadata);
    sum += parseFloat(perc, 10);
  });
  console.log(getSentiment(sum / text.length));
};

window.onload = () => {
  const inputText = document.getElementsByTagName("input")[0];
  const button = document.getElementsByTagName("button")[0];
  button.onclick = () => {
    run([inputText.value]);
  };
};

Listing 4-13JavaScript code to process user input and run predictions

```

在这个代码示例中，我将用户的输入作为一个单独的字符串，它将被转换并用于情感分析。但是，如果您想将一个段落分成不同的句子，并对每个句子分别进行情感分析，那么您需要首先创建一个函数，将该段落分成一系列句子。

如果您决定实现这一点，并尝试对各种文本进行情感分析，您可能会意识到预测的准确性并不总是最好的。

例如，一个句子，像“我真的很讨厌这个”，得分为 0.9253836274147034，意味着其情绪被预测为“积极的”，这似乎是不正确的。

这主要是因为用于训练模型的数据是来自 IMDB 的一组 25，000 条电影评论，IMDB 是与电影、电视节目等相关的信息的在线数据库。

尽管对人类来说，像“我真的讨厌这个”这样的句子似乎非常明显地是负面的，但机器学习模型只查看句子中每个单词的出现情况，与它从训练数据中学习到的情况进行比较。

如果“我”、“真的”和“这”这些词在更多的句子中出现，并且这些被标为“积极的”，那么它就超过了“恨”这个词在我们看来是一种消极情绪的事实。这个词可能在数据集中较少的句子中使用。

所有这些都是为了提醒你，永远不要完全依赖机器学习模型生成的预测。尽管算法在处理大量数据并从中提取模式方面比人强得多，但预测应该被用作增强我们决策方式的一种方式，而不是完全取代它。

如果你想改善这些预测，你可以寻找其他用于情感分析的开源数据集或预训练模型。

### 毒性分类器

既然我们已经研究了情感分析分类器的实现，让我们使用一些稍微不同的东西来产生更多的特定预测。

在这一小节中，我们将使用 TensorFlow 的毒性分类器根据文本的毒性类型来标记文本。

不同的标签是

*   侮辱

*   身份攻击

*   猥亵的

*   严重毒性

*   露骨的性

*   威胁

*   毒性

#### 导入模型

要开始使用这个模型，我们需要导入 TensorFlow.js 库和用于毒性识别的预训练模型。

```
<script src='https://cdn.jsdelivr.net/npm/@tensorflow/tfjs'></script>
<script src='https://cdn.jsdelivr.net/npm/@tensorflow-models/toxicity'></script>

Listing 4-14Import TensorFlow.js and the Toxicity Classifier in your HTML file using script tags

```

或者

```
// In your terminal
npm install @tensorflow/tfjs @tensorflow-models/toxicity

// In your JavaScript file
const toxicity = require('@tensorflow-models/toxicity');

Listing 4-15Install and import TensorFlow.js and the Toxicity Classifier in your JavaScript file

```

#### 预言

导入我们需要的工具后，对一段文本运行预测的代码实际上非常小！

我们需要加载模型，并用我们想要运行预测的句子作为参数调用`classify()`函数，如下所示。

```
toxicity.load().then((model) => {
  const sentences = ['this is really the most useless talk I have ever watched.'];

  model.classify(sentences).then((predictions) => {
    return predictions;
  });
});

Listing 4-16Loading the model and classifying new sentences

```

对于类似于前面代码示例中所示的句子，预测将作为下面的数组返回。

![../images/496132_1_En_4_Chapter/496132_1_En_4_Fig1_HTML.jpg](../images/496132_1_En_4_Chapter/496132_1_En_4_Fig1_HTML.jpg)

图 4-1

前面的代码示例返回的预测数组

一开始你可以认为是指“这真的是我看过的最没用的废话”这句话已经被预言属于“身份 _ 攻击”标签；然而，并不是这样。

这个特定模型的预测结果是一个包含每个标签数据的对象数组，按字母顺序排序。

这可能有点令人困惑，因为与 TensorFlow.js 一起使用的其他模型通常会生成按分数排序的预测。

为了更好地理解，让我们更深入地了解一下我们之前记录的预测数组。

![../images/496132_1_En_4_Chapter/496132_1_En_4_Fig2_HTML.jpg](../images/496132_1_En_4_Chapter/496132_1_En_4_Fig2_HTML.jpg)

图 4-2

由前面的代码示例返回的预测数组的详细视图

该屏幕截图显示了预测数组中的前四个条目。正如我们所见，它们是按标签的字母顺序排列的。

为了理解哪个标签是输入文本的正确标签，我们需要查看“概率”数组和“匹配”值。

概率数组包含两个值，第一个值表示标签为假的概率，意味着输入文本没有被该标签分类，第二个值表示标签为真的概率，意味着输入文本被分类为这种类型的有毒内容。

“匹配”值是更直接的表示。如果其值为“true”，则表示该文本对应于该标签；如果为“假”，则不会。

有时，“匹配”的值被设置为“空”。当两个预测都没有超过提供的阈值时，就会发生这种情况。

默认情况下，此阈值不是必需的，其值为 0.85。但是，它可以设置为另一个值，并作为参数传递给模型，就像这样。

```
const threshold = 0.7;

toxicity.load(threshold).then((model) => {
  const sentences = [
    "This is really the most useless talk I have ever watched.",
  ];

  model.classify(sentences).then((predictions) => {
    return predictions;
  });
});

Listing 4-17Passing a threshold as argument to the model

```

该阈值用于确定“匹配”属性的值。

如果“概率”数组中的第一个值超过阈值，则将“匹配”设置为“假”；相反，如果第二个值超过阈值，则将“匹配”设置为真。并且，如前所述，如果没有一个概率值超过阈值，“匹配”被设置为“空”。

如果您只关心某些标签而不是所有的标签，那么标签也可以作为另一个参数传递给模型。

例如，如果我们只想检测标签为“identity_attack”的文本，我们也要传递这个标签。

```
const threshold = 0.7;

// Labels have to be passed as an array, even if you only pass a single one.
toxicity.load(threshold, ["identity_attack"]).then((model) => {
  const sentences = [
    "This is really the most useless talk I have ever watched.",
  ];

  model.classify(sentences).then((predictions) => {
    return predictions;
  });
});

Listing 4-18Passing a label as argument to the model

```

提供您只感兴趣的标签将返回过滤后的预测。

![../images/496132_1_En_4_Chapter/496132_1_En_4_Fig3_HTML.jpg](../images/496132_1_En_4_Chapter/496132_1_En_4_Fig3_HTML.jpg)

图 4-3

传递特定标签后返回的预测数组

与本章上一节中构建的情感分类器类似，预测的准确性在很大程度上取决于用于训练模型的数据。

TensorFlow.js 的毒性模型是在 2015 年至 2017 年发表的约 200 万条用户生成的在线新闻评论的数据集上训练的。

一个有趣的方面是，数据集通常最初是由人类标记的，这意味着人们必须检查所有的条目，并根据提供的一组标签为每个条目标记相应的标签。

在用于毒性模型的数据的情况下，这意味着人们必须浏览 200 万条文本，并根据标签“身份 _ 攻击”、“侮辱”、“淫秽”、“严重 _ 毒性”、“性 _ 露骨”、“威胁”和“毒性”，给每条文本贴上他们认为最接近该评论所属毒性类型的标签。

这方面的一个潜在问题是，不同的人对他们可能归类为“侮辱”或“侮辱”的内容有不同的看法，或者他们会将哪些内容标记为“毒性”而不是“严重毒性”，这给将用于训练模型的数据增加了一定程度的偏差。

因此，预测的准确性不仅取决于收集的数据(在线评论)的质量，还取决于它们是如何被标记的。

如果您可以检查用于训练应用程序中使用的模型的数据，我真的建议您这样做。

现在，我们已经通过几个例子了解了 TensorFlow.js 的情感分析功能，让我们来看看一些潜在的应用。

## 4.4 应用

我们制作和分享的很多内容都是文本内容。从新闻文章和博客帖子到评论、聊天机器人互动、社交媒体更新等等，如果与机器学习结合使用，这些大量的文本数据可以提供一些真正有趣的新机会。

### 4.4.1 认知助手和计算机治疗

无论是聊天机器人还是 Siri 这样的语音助手，某些对话代理都可以从整合情感分析中受益。

在过去的几年里，一些公司试图开发以聊天机器人的形式提供心理帮助和指导的系统。

这些公司专注于提供量身定制的建议和支持，旨在让人们进行某种 DIY 认知行为治疗(CBT)。

CBT 使用结构化的练习来鼓励一个人质疑和改变他们的思维习惯。这种循序渐进的形式似乎非常适合聊天机器人。

Orexo、Woebot、Pear 和 Wysa 等公司根据每个人对问题的回答，为他们提供个性化服务。

Orexo 专注于帮助用户改变饮酒习惯，方法是询问一系列关于当前行为模式的问题，并根据提供的答案量身定制一个程序。

Woebot 是一个基于斯坦福研究的聊天机器人，旨在通过提供个性化的专家制作的工具来了解你自己，并在你需要的时候改善你的情绪，从而让每个人都可以获得精神保健。

![../images/496132_1_En_4_Chapter/496132_1_En_4_Fig4_HTML.jpg](../images/496132_1_En_4_Chapter/496132_1_En_4_Fig4_HTML.jpg)

图 4-4

应用程序 Woebot 的屏幕截图

Pear Therapeutics 是一家位于生物学和软件交叉点的公司，旨在创造下一代疗法。它发布了两项名为 reSET 和 reSET-0 的数字服务，旨在为物质滥用障碍患者提供支持和 CBT。

Wysa 是一个基于人工智能的“情绪智能”聊天机器人，它提供分组组织的自我护理练习，以帮助处理诸如管理情绪、克服孤独、改善睡眠等问题。与其他应用程序不同，它还让你有机会付费与应用程序内的专业治疗师进行真正的会话。

![../images/496132_1_En_4_Chapter/496132_1_En_4_Fig6_HTML.jpg](../images/496132_1_En_4_Chapter/496132_1_En_4_Fig6_HTML.jpg)

图 4-6

在应用程序 Wysa 中找到的自我保健包的屏幕截图

![../images/496132_1_En_4_Chapter/496132_1_En_4_Fig5_HTML.jpg](../images/496132_1_En_4_Chapter/496132_1_En_4_Fig5_HTML.jpg)

图 4-5

应用程序 Wysa 的主屏幕截图

其中一些申请甚至得到了美国食品药品监督管理局食品和药物管理局的批准。

其中另一个是 Akili Interactive 公司的一款名为“努力 Rx”的游戏，试验表明它可以帮助患有 ADHD(注意缺陷多动障碍)的儿童提高注意力水平。这个游戏是基于研究建立的，旨在提供感官和运动刺激，以选择性地瞄准和激活大脑中特定的认知神经系统。

尽管这些应用程序不能取代与治疗师的面对面交流，但它们的一个好处是它们的持续可用性。每天找一个真正的医生咨询将会非常昂贵和耗时；然而，手机上的数码相机可以让你更容易跟踪你的进展，并在紧急时刻提供帮助。

此外，可能没有足够的临床医生来帮助大量有需要的人。例如，聊天机器人 Woebot 每周与人交换约 470 万条消息；没有足够的从业者来处理这个问题。

尽管这些自助数字服务有潜力，但记住技术并不完美是非常重要的。

随着机器学习算法在分析和理解我们交流方式中包含的所有信息方面变得越来越好，未来只会有改进，但目前来看，许多这些应用程序的能力有限，应该记住这一点。

如果这是您感兴趣的领域，我强烈建议您尝试其中的一些应用程序，以更好地了解当前可用的功能和交互。

### 社交媒体监控

另一个有趣的机会是通过提供某种监控工具来改善用户在社交媒体上的互动。

如果你经常使用脸书或 Twitter 等社交媒体平台，你可能很熟悉用户决定分享的一些内容的毒性，无论是以状态更新还是帖子评论的形式。

这种类型的有害互动会对人们产生负面的心理影响，这可以通过情绪分析来避免。

此刻，如果有人在一个平台上以有害的方式与你互动，你真的没有选择去避免它。你可能会决定忽略它，但只有在你至少看过一次内容之后，这通常已经对你产生了负面影响。

然而，如果分享的每条内容都首先由机器学习模型运行，以检测毒性水平，社交媒体平台可以就用户即将看到的内容发出警告，并让他们决定是否要观看。

与被描述为“成人内容”的内容通常隐藏在某种警告背后一样，平台可以让用户做出自己的决定。

最近，推特发布了警告，认为有可能传播关于新冠肺炎疾病的不正确信息。

![../images/496132_1_En_4_Chapter/496132_1_En_4_Fig7_HTML.jpg](../images/496132_1_En_4_Chapter/496132_1_En_4_Fig7_HTML.jpg)

图 4-7

tweets 上显示的潜在传播错误信息的警告示例。来源: [www。vox。com/recode/2020/5/11/21254889/Twitter-冠状病毒-covid-误传-警告-标签](https://www.vox.com/recode/2020/5/11/21254889/twitter-coronavirus-covid-misinformation-warnings-labels)

如果用户想阅读内容，他们仍然可以点击“查看”，但会被警告说这是潜在有害的，因为它违反了公共卫生专家的指导。

此外，这种技术还可以用于通过向将要发布的人提供警告来试图防止有毒内容的共享。

当使用社交媒体平台时，你可以想象在通常的“添加表情符号”或“添加图片”图标旁边有一个图标，如果用户将要发送或分享的推文被分类为有毒，该图标将进入活动状态。这不会阻止任何人分享，但会给人们提供一个机会，让他们退后一步，三思自己的话对他人的影响。

这两个机会都没有完全解决互联网上有毒内容的问题，而是使用机器学习和情感分析来帮助使网络成为一个更安全的地方。

### 自动化工具

在我们的职业生活中，有些情况下一些任务仍然是手动完成的，可以使用情绪分析来自动完成，从而腾出一些时间来关注更有趣的挑战。这方面的一个例子是客户对产品的反馈。

如果你在一家产品公司工作，你可能很熟悉询问客户对你正在开发的产品的反馈。

这种反馈通常存储为数据的电子表格，存储在 Google Sheets、数据库或其他平台中。

然后，公司的员工通常会检查所有这些数据，以了解客户的需求、投诉等等。这些任务可能需要很多时间；然而，情感分析可以用于对数据应用第一过滤器，并通过看起来积极、消极和中立的反馈对它们进行分组。

人们仍然应该手动读取数据，以更好地了解客户的想法，但它可以提供关于产品的整体情绪的想法。

这种方法可能有用的另一种调查是公司内部调查。

当一家公司的领导层想要了解员工对他们的工作、文化或整体体验的感受时，就会共享一项调查来收集反馈。

一些调查相当简单，主要是复选框，人们通过选择“非常同意”、“同意”、“不同意”或“非常不同意”来回答问题或陈述；然而，其他一些调查为员工提供了用自己的话进一步表达自己的机会。

后者将是情感分析的一个很好的用例。从每个人那里收集反馈后，所有的数据都可以输入到情绪分析模型中，以确定员工对公司的总体感觉。

与前面的产品调查示例类似，反馈仍然应该手动读取和分析，但是对数据的初步了解可能会影响最初的决策。如果预测结果过于负面，那么尽快根据反馈采取行动以避免员工决定离开公司可能是很重要的。

最后，情绪分析可以用于自动化的另一个场景是帮助支持团队根据客户投诉的毒性来分类票证。这种方法也可以被开发者体验团队使用，他们通常需要跟踪社交媒体上关于一家公司的言论。

使用毒性分类器或情绪分析分类器对数据进行初步检查，可以帮助优先考虑哪些客户的反馈应该更紧急地处理。

总而言之，使用情感分析作为自动化工具并不能完全取代应该由人来完成的工作，它只是提供了一种帮助来获得一些早期的见解并指导决策。

除了情感分析之外，其他类型的技术也可用于更深入地理解文本数据。

## 4.5 其他类型的文本分类工具

尽管情感分析提供了一些关于收集的数据的有用信息，但它也可以与其他类型的文本分类工具配对，以生成更好的预测并提取更有意义的见解。

### 意图分析

意图分析，也称为意图分类，更进一步，试图分析和理解用户在一条消息背后的**意图**，并识别它是否与某个观点、新闻、营销、查询、投诉、建议等相关。它还有助于按照购买、降级、演示请求等主题对客户的意图进行分类。

要做到这一点，需要用从用户那里收集的现有数据来训练一个模型，并用我们希望用于未来预测的不同意图来标记它。

它的工作原理有点类似于我在本章前面谈到的毒性分类器，但不是使用“严重 _ 毒性”或“威胁”等标签，而是使用“购买”、“信息需求”、“取消”等标签来训练模型。

将这些来自真实顾客的评论、请求和投诉的标记数据输入算法，可以让算法发现人们在表达类似意图时使用的词汇、语义和句子中单词排列的模式。

### 4.5.2 命名实体识别

命名实体识别(NER)，也称为实体识别、实体分块或实体提取，从文本中提取诸如人员、位置、组织和日期等实体。

举例来说，如果我们从罗莎·帕克斯的维基百科页面中选取以下示例段落:

> *罗莎·路易斯·麦考利·帕克斯(1913 年 2 月 4 日—*2005 年 10 月 24 日*)是美国* [活动家](https://en.wikipedia.org/wiki/Activism) *在* [民权运动](https://en.wikipedia.org/wiki/Civil_rights_movement) *中最为人所知的是她在* [蒙哥马利公交车抵制](https://en.wikipedia.org/wiki/Montgomery_bus_boycott) *中的关键角色。美国国会称她为“民权第一夫人”和“自由运动之母”*
> 
> —引用来源: [`https://en.wikipedia.org/wiki/Rosa_Parks`](https://en.wikipedia.org/wiki/Rosa_Parks)

命名实体识别将允许我们提取并分类以下术语:

*   人物:罗莎·路易斯·麦考利·帕克斯

*   **地点**:美国蒙哥马利

*   **日期**:1913 年 2 月 4 日，2005 年 10 月 24 日

*   **组织**:美国国会

NER 模型有着广泛的应用，包括自动汇总简历，旨在通过自动扫描大量文档并根据其中的术语筛选候选人来简化招聘过程。

### 4.5.3 文本摘要

顾名思义，文本摘要是一种技术，通常用于创建准确的摘要，以捕捉较长文本中的主要信息。

这些摘要通过减少阅读时间和帮助研究文档的选择过程，使人们能够更有效地浏览内容。

这种技术的目标不仅是捕获文档的主要单词并生成一个较短的句子，而且是创建一个新的独立内容，读起来很流畅。它应该产生一个和人类写的一样好的摘要。

我们已经熟悉的日常文本摘要的例子包括

*   新闻标题

*   会议记录

*   新思科技

*   传记

对于使用机器学习的自动文本摘要，存在两种方法:**抽取**和**抽象**。

**摘录文本摘要**是在源文档中选择短语以生成摘要的过程。它包括对源中短语的相关性进行排序，并且只选择与文档含义最相关的短语。

**抽象文本摘要**包括生成全新的短语，传达来自源文档的最关键信息。它使用先进的自然语言处理技术来解释和检查文本，并以新的方式生成较短的句子。

### 4 . 5 . 4 tensor flow . js 问答

问题回答是自然语言处理领域中的一门学科，它涉及构建自动回答人类用自然语言提出的问题的系统。

机器学习模型将一段文章和一个问题作为输入，并能够返回可能回答所提问题的一段文章作为输出。

在接下来的几页中，我们将使用 MobileBERT 模型，这是 Google 的 BERT(来自变压器的双向编码器表示)模型的一个轻量级版本，来构建一个能够根据一组段落回答人类提交的问题的系统。

#### 导入模型

要设置我们的项目，我们需要从导入 TensorFlow.js 和模型开始。

```
const qna = require('@tensorflow-models/qna');

Listing 4-20Importing TensorFlow.js and the QNA model as package in a JavaScript file

```

```
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/qna"></script>

Or

Listing 4-19Importing TensorFlow.js and the QNA model in an HTML file

```

如果决定将其作为 NPM 模块使用，则不需要导入@tensorflow/tfjs 库；但是，您需要确保已经安装了 tfjs-core 和 tfjs-converter 的对等依赖项。

#### 加载模型

一旦模型被导入，我们需要将它加载到我们的应用程序中。有两种方法可以做到这一点。

首先，您可以在不提供配置对象的情况下加载它。

```
const model = await qna.load();

Listing 4-21Default way to load the model

```

如果您想使用托管在谷歌云平台(GCP)提供商上的谷歌问答模型，这种加载模型的方式可能是您应该使用的方式。

如果您居住的地区或国家无法访问托管在 GCP 上的模型，您可以提供一个配置对象，该对象将包含托管在您自己的服务器上的模型的自定义 URL。

```
const config = { modelUrl: "https://yourown-server/qna/model.json" };
const customModel = await qna.load(config);

Listing 4-22Loading the model using custom configurations

```

这两种加载模型的方式将返回一个模型对象，我们可以对其调用方法来预测我们的答案。

#### 预言

使用模型对象上的`findAnswers()`方法来生成答案。这个方法接受两个参数:第一个是用户想问的问题，第二个是需要从中提取内容的相关段落。

```
const answers = await model.findAnswers(question, passage);

Listing 4-23Generating predictions

```

**这两个参数需要是字符串。**

保存预测结果的答案变量将是一个元素数组，其形状如下:

```
[
  {
    text: "Angela Davis",
    startIndex: 1143,
    endIndex: 1156,
    score: 0.8380282521247864
  }
]

```

属性表示这个人可能会问的问题的答案。`score`是预测的置信水平。越高，模型越有信心这个答案是正确的。`startIndex`和`endIndex`表示表达式在文章中出现的起始和结束字符的索引。

#### 完整示例

让我们把所有这些代码样本放在一起，重用前几节中的一个例子，并询问有关 Rosa Parks 的问题。

```
const init = async () => {

  const passage = "Rosa Louise McCauley Parks (February 4, 1913 – October 24, 2005) was an American activist in the civil rights
    movement best known for her pivotal role in the Montgomery bus boycott. The United States Congress has called her 'the first lady of civil rights' and 'the mother of the freedom movement'";

  const question = "When was Rosa born?";

  const model = await qna.load();

  const answers = await model.findAnswers(question, passage);

  console.log(answers);

};

init();

Listing 4-25JavaScript code in the index.js file

```

```
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Question Answering</title>
  </head>
  <body>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/qna"></script>
    <script src="index.js"></script>
  </body>
</html>

Listing 4-24HTML code

```

这段代码将在您的浏览器控制台中记录以下输出。

![../images/496132_1_En_4_Chapter/496132_1_En_4_Fig8_HTML.jpg](../images/496132_1_En_4_Chapter/496132_1_En_4_Fig8_HTML.jpg)

图 4-8

浏览器控制台中对问题“罗莎何时出生？”的预测输出

正如我们在前面的截图中看到的，答案以五个元素的数组形式返回。得分最高的是“1913 年 2 月 4 日”，这是“罗莎出生于何时”这个问题的正确答案。！

此外，如果我们观察随后的预测，它们都有些正确，因为它们要么包含出生日期的一部分，要么包含出生和死亡日期。

我们可能会想，也许我们只是运气好，所以让我们尝试另一个问题，例如:“谁是罗莎·帕克斯？”。

在问这个问题的时候，我们得到了以下的答案。

![../images/496132_1_En_4_Chapter/496132_1_En_4_Fig9_HTML.jpg](../images/496132_1_En_4_Chapter/496132_1_En_4_Fig9_HTML.jpg)

图 4-9

浏览器控制台中对问题“谁是罗莎·帕克斯？”的预测输出

这一次，我们的答案数组只包含两个对象。但是，这些预测都是正确的！

一个有趣的方面是，我们的问题提到了“罗莎·帕克斯”，而我们的文章提到了她的全名“罗莎·路易斯·麦考利·帕克斯”，模特仍然能够理解我们的问题是关于谁的。

这非常令人印象深刻，具有巨大的潜力，但是，正如每一个机器学习模型一样，它也有其局限性。

比如把问题改成“罗莎·帕克斯是怎么叫的？”，期望得到“民权第一夫人”或“自由运动之母”的答案，但预测数组返回的是空的，这意味着模型无法在文章中找到该问题的答案。

然而，当把问题修改得更精确一点(“美国国会把罗莎·帕克斯叫做什么？”)，模型设法提供了正确的答案——第一个是这样的。

![../images/496132_1_En_4_Chapter/496132_1_En_4_Fig10_HTML.jpg](../images/496132_1_En_4_Chapter/496132_1_En_4_Fig10_HTML.jpg)

图 4-10

浏览器控制台中对问题“美国国会称罗莎·帕克斯为什么？”

不幸的是，以这种方式提问可能需要用户具备某种知识。一个不熟悉罗莎·帕克斯生活细节的人很可能会以类似于“罗莎·帕克斯叫什么？”的方式问这个问题，没有回答。

#### 构建交互式教育工具

在前面的代码示例中，我们仅使用该模型在浏览器的开发人员工具中记录结果。然而，让我们使用这段代码来构建一个交互式教育工具，在这个工具中，用户可以通过问答来了解历史人物。

对于这个项目，为了使它更简单，我们将把一些预先选择的人的数据作为 JSON 文件存储在我们的代码库中。如果你不熟悉的话，JSON 代表 JavaScript Object Notation，指的是一种存储数据的文件格式。

如果你想更进一步，你可以尝试使用 MediaWiki API 让用户请求他们想要的任何公众人物并动态获取数据。

下面的应用程序将有关于三个历史人物的信息，让用户决定他们想了解哪一个，并提供一个输入字段来询问不同的问题，以显示由机器学习模型预测的最高概率的答案。

这个项目的最终状态将包含三个屏幕，看起来像这样。

![../images/496132_1_En_4_Chapter/496132_1_En_4_Fig13_HTML.jpg](../images/496132_1_En_4_Chapter/496132_1_En_4_Fig13_HTML.jpg)

图 4-13

页面提出问题并显示预测的最佳答案

![../images/496132_1_En_4_Chapter/496132_1_En_4_Fig12_HTML.jpg](../images/496132_1_En_4_Chapter/496132_1_En_4_Fig12_HTML.jpg)

图 4-12

页面选择公众人物了解更多信息

![../images/496132_1_En_4_Chapter/496132_1_En_4_Fig11_HTML.jpg](../images/496132_1_En_4_Chapter/496132_1_En_4_Fig11_HTML.jpg)

图 4-11

项目主页

你可能已经注意到了，我把设计保持得非常简洁，因为我想把重点放在功能上。这个项目的重要收获是如何使用问答模型创建一个快速的用户界面。

现在，您对我们将要构建的内容有了更好的了解，让我们深入研究不同的特性和代码示例。

##### 步骤 1:加载页面

![../images/496132_1_En_4_Chapter/496132_1_En_4_Fig14_HTML.jpg](../images/496132_1_En_4_Chapter/496132_1_En_4_Fig14_HTML.jpg)

图 4-14

项目主页

将预先训练好的机器学习模型加载到您的应用程序中总是会对性能产生影响，因为它们往往非常繁重。因此，提前思考你想要创造什么样的用户体验来提高感知性能是很重要的。

这可能包括早期在后台加载模型，因此当用户获得体验时，它已经被加载并准备好使用；或者提供加载动画来指示用户需要等待界面可用。

后者不是最好的选择，因为用户在能够与体验交互之前显然被迫等待；然而，在这个项目的情况下，这是我们将要使用的方法，因为应用程序的唯一特征是与模型的交互。

为了显示这个加载状态，我们在 HTML 文件中有一个默认状态为 disabled 的按钮元素，以防止用户在模型可用之前试图运行预测。

```
<section class="intro">
   <h1>Hidden figures</h1>
   <h3>
     Using machine learning, learn about 3 NASA engineers by asking questions about their lives!
   </h3>
   <button disabled>Loading...</button>
 </section>

Listing 4-26HTML code sample to show some intro text and a button with initial loading state

```

然后，在 JavaScript 文件中，我们可以在页面加载后立即开始加载模型，并在模型准备就绪后更改按钮的状态。

```
let model;
const loadModel = async () => await qna.load();

const init = async () => {
  model = await loadModel();

  const startButton = document.querySelector(".intro button");

  startButton.removeAttribute("disabled");
  startButton.innerHTML = "Start";
};

init();

Listing 4-27JavaScript code sample to load the model and update the state of the button when the model is loaded

```

前面的代码示例显示，一旦`loadModel`函数完成加载模型，我们就移除按钮的禁用状态，使其成为交互式的，并将其内容更改为“Start ”,以指示用户可以开始体验。

在这个阶段，一旦用户点击开始按钮，我们隐藏这个内容，以显示三个可用的选项。

##### 步骤 2:选择页面

![../images/496132_1_En_4_Chapter/496132_1_En_4_Fig15_HTML.jpg](../images/496132_1_En_4_Chapter/496132_1_En_4_Fig15_HTML.jpg)

图 4-15

页面选择要了解更多信息的工程师

为了这个小演示的目的，我在 HTML 文件的按钮元素中硬编码了三个工程师的名字；但是，如果您正在构建具有更多条目的东西，或者如果它们是动态生成的，那么您也可以在 JavaScript 中动态替换按钮的内容。

```
<section class="selection">
   <h1>Who would you like to learn about?</h1>
   <section class="buttons">
     <button class="figure">Katherine Johnson</button>
     <button class="figure">Dorothy Vaughan</button>
     <button class="figure">Mary Jackson</button>
   </section>
</section>

Listing 4-28HTML code sample with buttons containing the name of the three NASA engineers

```

在我们的 JavaScript 文件中，我们需要为点击这些按钮添加一个事件监听器，并获取 JSON 数据。

为了避免一次加载所有内容，我为每个人创建了一个 JSON 文件，这样代码将只获取用户请求的数据。

因此，我将三个 JSON 文件命名为:

*   dorothyVaughan.json

*   凯瑟琳·约翰森

*   玛莉杰克森，json

这样，当用户单击三个按钮中的一个时，下面的代码将执行获取并为下面的预测页面做准备。

```
const engineers = {
  "Katherine Johnson": "katherineJohnson",
  "Dorothy Vaughan": "dorothyVaughan",
  "Mary Jackson": "maryJackson",
};

figureButtons.forEach(button => {
  button.onclick = e => {
    const dataFile = engineers[e.target.textContent];

    fetch(`${window.location.href}${dataFile}.json`)
      .then(response => response.json())
      .then(data => {
        figureData = data;
        const label = document.getElementsByTagName("label")[0];
        label.innerHTML = `What would you like to know about ${e.target.textContent}?`;
      });
  };
});

Listing 4-29JavaScript code to fetch data when clicking one of the buttons

```

在前面的代码示例中，我首先创建一个对象，将 UI 中显示的名称映射到相关联的 JSON 文件的名称。

然后，对于这三个按钮中的每一个，我监听点击事件，查看被点击按钮的内容以获取 JSON 文件的名称，并使用`fetch`函数获取数据并将其存储在一个`figureData`变量中。

我还使用用户选择的人的名字，将其显示在标题“你想了解什么…”中。

当我们浏览页面时，还有一些关于显示和隐藏 HTML 元素的代码，但是我会在本章的最后分享这个项目的完整代码。

现在我们知道了用户有兴趣更多地了解哪个人，并且我们已经获取了相关数据，让我们继续到预测页面。

##### 第三步:预测

![../images/496132_1_En_4_Chapter/496132_1_En_4_Fig16_HTML.jpg](../images/496132_1_En_4_Chapter/496132_1_En_4_Fig16_HTML.jpg)

图 4-16

页面提出问题并显示预测的最佳答案

***清单 4-31。*** JavaScript 代码示例获取输入字符串，将其馈送给模型，并显示输出

我们的最后一页有一个输入框，一个运行预测的按钮，以及一个输出答案的段落。

```
<section class="question">
  <label for="question"></label>
  <input type="text" name="question" placeholder="Who was she?" />
  <button class="ask">Ask</button>
</section>

<section class="answer-block">
  <p class="input-question"></p>
  <p class="answer"></p>
</section>

Listing 4-30HTML code sample to display an input field and a section to display the prediction

```

在我们的 JavaScript 文件中，我们需要监听按钮上的 click 事件，获取用户输入的值，将它与作为参数获取的数据一起发送给方法，以从模型中获取答案，并在页面上显示第一个答案。

下面是实现这一点的代码示例。

![../images/496132_1_En_4_Chapter/496132_1_En_4_Figa_HTML.gif](../images/496132_1_En_4_Chapter/496132_1_En_4_Figa_HTML.gif) ![../images/496132_1_En_4_Chapter/496132_1_En_4_Figb_HTML.gif](../images/496132_1_En_4_Chapter/496132_1_En_4_Figb_HTML.gif)

***清单 4-31。*** JavaScript 代码示例获取输入字符串，将其馈送给模型，并显示输出

在前面代码的第一部分中，我们侦听 click 事件，获取输入问题，并使用问题和我们在上一节中使用的`figureData`变量调用`findAnswers`方法，以存储从 JSON 文件中获取的数据。

然后我们调用一个名为`displayAnswer`的函数，将模型返回的答案传递给它，并在页面上显示出来。

正如本章前面提到的，有时，模型不会找到问题的答案，会返回一个空数组。我们需要首先处理这个案例，在这里，我们显示一个通用消息。

然后，如果模型找到了答案，我们显示数组中的第一个答案，因为它是正确概率最高的一个。

就是这样！

在不到 100 行的 JavaScript 中，您可以创建一个小型的交互式项目，允许用户提出问题，并使用机器学习了解不同的主题！

如果您想要完整的代码示例，可以在下面的清单中找到 HTML 和 JavaScript。

```
"Dorothy Johnson Vaughan (September 20, 1910 – November 10, 2008) was an American mathematician and human computer who worked for the National Advisory Committee for Aeronautics (NACA), and NASA, at Langley Research Center in Hampton, Virginia. In 1949, she became acting supervisor of the West Area Computers, the first African-American woman to supervise a group of staff at the center. She later was promoted officially to the position. During her 28-year career, Vaughan prepared for the introduction of machine computers in the early 1960s by teaching herself and her staff the programming language of Fortran. She later headed the programming section of the Analysis and Computation Division (ACD) at Langley. Vaughan is one of the women featured in Margot Lee Shetterly's history Hidden Figures: The Story of the African-American Women Who Helped Win the Space Race (2016). It was adapted as a biographical film of the same name, also released in 2016\. In 2019, Vaughan was awarded the Congressional Gold Medal posthumously."

Listing 4-33Example JSON data for the file katherineJohnson.json

```

```
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Interactive education tool</title>
    <link rel="stylesheet" href=" styles.css" />
  </head>
  <body>
    <section class="intro">
      <h1>Hidden figures</h1>
      <h3>
        Using machine learning, learn about 3 NASA engineers by asking questions about their lives!
      </h3>
      <button disabled>Loading...</button>
    </section>
    <main>
      <section class="selection">
        <h1>Who would you like to learn about?</h1>
        <section class="buttons">
          <button class="figure">Katherine Johnson</button>
          <button class="figure">Dorothy Vaughan</button>
          <button class="figure">Mary Jackson</button>
        </section>
      </section>

      <section class="question">
        <label for="question"></label>
        <input type="text" name="question" placeholder="Who was she?" />
        <button class="ask">Ask</button>
      </section>

      <section class="answer-block">
        <p class="input-question"></p>
        <p class="answer"></p>
      </section>
    </main>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/qna"></script>
    <script src="index.js"></script>
  </body>
</html>

Listing 4-32Complete HTML code

```

```
"Dorothy Johnson Vaughan (September 20, 1910 – November 10, 2008) was an American mathematician and human computer who worked for the National Advisory Committee for Aeronautics (NACA), and NASA, at Langley Research Center in Hampton, Virginia. In 1949, she became acting supervisor of the West Area Computers, the first African-American woman to supervise a group of staff at the center. She later was promoted officially to the position. During her 28-year career, Vaughan prepared for the introduction of machine computers in the early 1960s by teaching herself and her staff the programming language of Fortran. She later headed the programming section of the Analysis and Computation Division (ACD) at Langley. Vaughan is one of the women featured in Margot Lee Shetterly's history Hidden Figures: The Story of the African-American Women Who Helped Win the Space Race (2016). It was adapted as a biographical film of the same name, also released in 2016\. In 2019, Vaughan was awarded the Congressional Gold Medal posthumously."

Listing 4-35Example JSON data for the file dorothyVaughan.json

```

```
"Mary Jackson (née Winston, April 9, 1921 – February 11, 2005) was an American mathematician and aerospace engineer at the National Advisory Committee for Aeronautics (NACA), which in 1958 was succeeded by the National Aeronautics and Space Administration (NASA). She worked at Langley Research Center in Hampton, Virginia, for most of her career. She started as a computer at the segregated West Area Computing division in 1951\. She took advanced engineering classes and, in 1958, became NASA's first black female engineer. After 34 years at NASA, Jackson had earned the most senior engineering title available. She realized she could not earn further promotions without becoming a supervisor. She accepted a demotion to become a manager of both the Federal Women's Program, in the NASA Office of Equal Opportunity Programs and of the Affirmative Action Program. In this role, she worked to influence the hiring and promotion of women in NASA's science, engineering, and mathematics careers. Jackson's story features in the 2016 non-fiction book Hidden Figures: The American Dream and the Untold Story of the Black Women Who Helped Win the Space Race. She is one of the three protagonists in Hidden Figures, the film adaptation released the same year. In 2019, Jackson was posthumously awarded the Congressional Gold Medal. In 2020 the Washington, D.C. headquarters of NASA was renamed the Mary W. Jackson NASA Headquarters."

Listing 4-34Example JSON data for the file maryJackson.json

```

![../images/496132_1_En_4_Chapter/496132_1_En_4_Figc_HTML.gif](../images/496132_1_En_4_Chapter/496132_1_En_4_Figc_HTML.gif)![../images/496132_1_En_4_Chapter/496132_1_En_4_Figd_HTML.gif](../images/496132_1_En_4_Chapter/496132_1_En_4_Figd_HTML.gif)T2】

***清单 4-36。*** 完整的 JavaScript 代码

在我们刚刚浏览的代码示例中，问题是在用户必须输入的输入字段中捕获的。然而，使用另一个 Web API，还有其他方法可以获得相同类型的信息。

在我们刚刚浏览的代码示例中，问题是在用户必须输入的输入字段中捕获的。然而，使用另一个 Web API，还有其他方法可以获得相同类型的信息。

##### 从 Web 语音 API 获取输入数据

让这个项目更具互动性的一个方法是允许人们用自己的声音提问，而不是敲键盘。

支持语音识别的 Web API 是 Web 语音 API。使用这个 API，我们可以为这个项目添加语音到文本的功能，如果我们想大声读出答案，甚至可以使用语音合成进行文本到语音的转换。

添加这个特性所需的代码量相对较少。考虑到我们已经检查了应用程序的核心，它只会影响捕获用户输入的部分。

要开始使用 Web Speech API，您需要在 JavaScript 文件中包含以下几行。

```
var SpeechRecognition = SpeechRecognition || webkitSpeechRecognition;
var SpeechRecognitionEvent = SpeechRecognitionEvent || webkitSpeechRecognitionEvent;

Listing 4-37Initial setup to use the Web Speech API

```

这几行将允许您访问语音识别界面。

然后，要开始使用这个接口，您需要使用下面的代码创建一个语音识别实例。

```
const recognition = new SpeechRecognition();

Listing 4-38Instantiate a new SpeechRecognition instance

```

在开始识别之前，可以在识别实例上设置一些参数。我个人设定了以下几个。

```
recognition.continuous = false;
recognition.lang = "en-US";
recognition.interimResults = false;

Listing 4-39Optional parameters

```

第一个问题表明倾听和识别不是连续的，这意味着每当您想要倾听用户的问题时，您将需要用户交互。将它设置为 false 允许您仅在用户想要与界面交互时进行监听，而不是不停地监听。

第二个设置是识别请求的语言。如果未设置，它将默认使用在您的`lang`属性中定义的 HTML 文档根元素的语言。

目前，可供 SpeechRecognition API 使用的语言包括

![../images/496132_1_En_4_Chapter/496132_1_En_4_Figf_HTML.gif](../images/496132_1_En_4_Chapter/496132_1_En_4_Figf_HTML.gif)![../images/496132_1_En_4_Chapter/496132_1_En_4_Figg_HTML.gif](../images/496132_1_En_4_Chapter/496132_1_En_4_Figg_HTML.gif)![../images/496132_1_En_4_Chapter/496132_1_En_4_Figh_HTML.gif](../images/496132_1_En_4_Chapter/496132_1_En_4_Figh_HTML.gif)T3】

最后，第三个设置`interimResults`被设置为`false`表示我只对获得识别的最后结果感兴趣，而不是在我说话时的所有中间结果。

设置这些属性后，我们可以使用`recognition.start()`开始识别。

如果您还没有在网页上启用麦克风，系统会提示您这样做，否则，麦克风将开始监听输入。

要访问识别的结果，您需要调用`onresult`方法，就像这样。

```
recognition.onresult = function (event) {
   if (event.results[0][0]){
      var result = event.results[0][0].transcript;
   }
   console.log("result", result);
};

Listing 4-40Getting results from the Web Speech API

```

调用`onresult`会返回一个回调，带有一个如下形状的事件对象。

![../images/496132_1_En_4_Chapter/496132_1_En_4_Fig17_HTML.jpg](../images/496132_1_En_4_Chapter/496132_1_En_4_Fig17_HTML.jpg)

图 4-17

调用 onresult 方法的输出

查看这个输出有助于理解我们在前面的代码示例`event.results[0][0].transcript`中设置`result`变量的方式。

我们可以调用的另一个有用的方法是`onspeechend`。

`onspeechend`在停止检测语音时触发。为了避免在不需要时运行识别，我们可以使用`onspeechend`来完全停止识别。

```
recognition.onspeechend = function () {
   recognition.stop();
};

Listing 4-41Code sample to stop the recognition when the API has detected that the user has stopped talking

```

综合起来，语音识别的代码示例如下所示:

```
var SpeechRecognition = SpeechRecognition || webkitSpeechRecognition;
var SpeechRecognitionEvent =
  SpeechRecognitionEvent || webkitSpeechRecognitionEvent;

var recognition = new SpeechRecognition();

const startSpeechRecognition = () => {
  recognition.continuous = false;
  recognition.lang = "en-US";
  recognition.interimResults = false;

  recognition.onspeechend = () => recognition.stop();

  recognition.onresult = function (event) {
    if (event.results[0][0]) var result = event.results[0][0].transcript;
    console.log("result", result);
  };
  recognition.start();
};
startSpeechRecognition();

```

仅用 20 行 JavaScript 代码，一个 web 应用程序就可以监听用户的语音命令！

如果您想将它添加到我们之前构建的项目中，那么您可以在我们添加了“ask”按钮点击事件监听器的地方实现它。

您可以不使用输入字段中的输入，而是通过单击触发语音识别，听用户的语音输入，并将其提供给模型，就像我们发送输入字符串一样。

假设您已经从前面的代码示例中添加了 SpeechRecognition 实例的基本设置，那么您需要对项目代码做的唯一更改就是在函数中监听 askButton 元素上的点击。

```
askButton.onclick = async () => {
  recognition.start();

  recognition.onresult = async (event) => {
    if (event.results[0][0]) {
        var result = event.results[0][0].transcript;
    }
    inputQuestion = result;

    const answers = await model.findAnswers(inputQuestion, figureData);
    displayAnswer(answers);
    document.getElementsByTagName("input")[0].value = "";
  };
};

Listing 4-42User voice commands with the QNA model

```

当用户点击按钮时，这段代码启动语音识别，结果是将最终的文本存储在`inputQuestion`变量中。在这个项目的原始代码中，这个变量已经被发送给了`findAnswers`方法，但是现在它包含了来自用户语音命令的输入。

需要对 UI 进行一些更改来反映这种功能更改(例如，不再需要输入字段)，但是总的来说，我们必须进行的从书面输入到口头输入的更改只需要几行代码！

最后，如果您想更进一步，除了在屏幕上显示之外，还想将输出大声读给用户，您可以使用下面的三行代码来实现。

```
let speechSynth = window.speechSynthesis;
var result = new SpeechSynthesisUtterance(answers[0].text);
speechSynth.speak(result);

Listing 4-43Code sample to get the output prediction read out loud using the SpeechSynthesis Web API

```

这三行代码创建了一个 speechSynthesis 实例，执行一个传递来自模型的答案的语音请求，并调用`speak`方法让语音服务大声读出信息。

默认的声音感觉相当机器人，但一些参数可以设置来改变这一点。我不会在这里详细介绍，但是可以随意查看 MDN Web Docs for Web Speech API 以获得更多信息。

如果您想进一步探索这个 API，最后要记住的一点是**浏览器支持不是 100%** 。目前，它似乎在 Chrome 和 Edge 上得到很好的支持，但在 Safari 和 Firefox 上没有得到支持。

尽管它仍处于实验阶段，但如果你感兴趣的话，我鼓励你去研究一下。

这一章包含了很多信息。

我们研究了自然语言处理的基础知识、不同类型的文本分类工具、各种应用程序，以及如何使用 TensorFlow.js 实现情感分析、毒性分类和问题回答，并尝试使用语音命令作为获取文本数据来运行预测的方法。

如果这是你第一次投入机器学习，那么这么多的信息会让你感到有些不知所措。然而，因为所有新的东西都需要时间去理解，所以如果你愿意，可以休息一下，稍后再回到这一章。

下一章将深入探讨机器学习中使用其他类型的数据输入。