# 4.人体姿态分类

本章涵盖了各种人体姿态估计实验。在前一章中，您学习了浏览器中人体姿态估计的基础知识。

这个讨论首先回答了为什么我们需要在浏览器中进行人体姿态估计，然后讨论转向了可以在浏览器中执行的各种人工智能(AI)和机器学习(ML)分类技术。

本章还提供了开源 JavaScript (JS)库 TensorFlow.js 的高级概述。您将学习如何使用它在浏览器中实现和部署深度学习(DL)系统。讨论涵盖 TensorFlow.js 框架的架构及其构造块 tensors，并包括两个使用该库在浏览器上运行神经网络程序的实际示例。请注意，TensorFlow.js 是 js 中 ML 的库，使您能够在 JS 中开发 ML 模型，并直接在浏览器或 Node.js 中使用 ML。

这一章还包括实际例子，包括通过浏览器网络摄像头和本地存储的图片(图像)检测个人的关键点。

## 需要在浏览器中进行人体姿态估计

人体姿态估计是个人评估人体姿态分类以预测可能很快出现的异常所需的一项任务。人体姿态评估将指示个人在执行他或她的日常活动中的分类级别。人们更喜欢在不失去隐私的情况下计算他们的姿势；因此，人体姿态计算优选在客户端而不是在数据收集的服务器端进行。因此，借助于 AI 方法的人体姿态分类(确定)将在客户端侧(即，在浏览器应用处)执行。

对用于估计人体姿态和评估浏览器中分类性能的 ML 技术的需求如下:

*   *隐私*:在浏览器上执行 ML 方法和用户数据的规定将确保数据不会移动到服务器。与敏感文档相关的数据、医疗应用数据(如用户标识)以及特定于域的用户文本将仅在客户端(用户)进行处理。因此，通过在客户端应用本身(即，在浏览器)实现 ML 方法来维护用户隐私。

*   *不需要跨几个软件共享数据(分布)*:可以避免要在几个软件/工具上执行的数据的依赖性。不需要安装额外的软件/工具。应用程序将在用户端执行，因此导航到几种方法将很容易。

*   *低延迟* : ML 模型可以针对高效存储和速度进行优化，以便在资源受限的设备上非常高效地运行。因此，可以减少/避免服务器响应的等待时间(客户机/服务器模型 web 应用程序中的往返时间)。如果应用程序只在客户端执行，运行速度会更快。

*   *可靠性*:可靠性问题可以避免，因为没有间歇性的连接步骤。数据不会传输到另一个位置(服务器)。因此，在客户端处理数据是非常可靠的。

*   *用户交互性*:今天的技术浏览器与输入和输出设备如照相机和屏幕集成在一起。这种集成支持丰富的用户交互体验。ML 可以很容易地增强用户的交互性，尤其是在实时操作中。

此外，在浏览器上(在客户端)执行 ML 方法(模型)适用于迁移学习、现有模型的参数调整和输出解释等任务。

## 浏览器中的 ML 分类技术

神经网络概念是一组 ML 方法/算法，其行为类似于大脑如何工作，使用人工神经元结构。神经网络是可以帮助解决分类问题的几种 ML 方法之一。它的新颖之处在于它有能力做出强有力的详细预测，并在合理的执行时间内模仿人类的推测。这一章没有详细介绍神经网络，但是你将学习神经网络的基础知识，以便更好地理解所提出的问题。

有许多强大的方法可以自动对实体进行分类。应用需求决定了解决分类问题的理想选择，以及应用神经系统是否值得。人工神经网络(ann)和深度神经网络(DNNs)在解决复杂维度问题方面是成功的；然而，它们本身也是假设复杂的。一些深度学习系统是 DL 框架，如 TensorFlow，可以帮助你更快地设置深度神经系统，只需几行代码。

分类模型预测类别标签，使其属于特定的实体。一些分类器被配对，产生是/否选择。其他的是多类的，准备把一个东西归入几个分类中的一个。人物塑造是人工智能的另一个常见用例。例如，利用排列计算来处理垃圾邮件分离、记录分类、话语确认、图片确认和笔迹识别。在这种特定情况下，神经系统是一些人工智能计算，可以帮助处理分组问题。它的独特之处在于，它有能力逐步做出详细的预测，并模仿人类的推理，这是其他任何计算都无法做到的。神经系统已经在许多与分类问题相关的案例中产生了最好的结果。

为了理解神经系统的分类问题，有必要弄清楚其他顺序计算是如何工作的，并理解它们的特殊性质。对于某些问题，神经系统可能是不可接受的或无意义的练习。对于其他人来说，可能是中央的安排。人工神经网络是由被称为神经元的基本组件组成的，这些组件接受值，通过权重增加值，并通过非直接的制定工作来运行它。如果存在足够的计算能力，神经网络可以有效地学习非线性特性。该系统可以学习异常复杂的能力。假设，给定足够的计算能力，神经系统可以学习几乎任何能力的状态。

*   *ANN Positives* :对于解决大维度问题非常强大，随时可以管理因素之间的复杂关系、不彻底的分类集以及与产量因素相关的复杂能力。优秀的调谐选择，以防止过度和欠拟合。

*   *人工神经网络缺点*:假设复杂，难以实现，并且需要专业知识来调整参数以实现更好的分类。有时，为了更好地实现(为了有更好的输出)，需要一个大的样本训练集。

Note

制作你的神经网络，用 TensorFlow.js 库在程序中训练。收集数据并准备你的神经组织，或者利用现有的信息逐步准备你的神经组织。当它准备好时，你的神经网络将相应地执行分类或回归任务。

通过浏览器在客户端完全运行 AI/ML 程序是一种交互式应用，这很聪明。使用开源的 JS 库 TensorFlow.js 可以实现人体姿态估计等应用。

## 使用 TensorFlow.js 的 ML

TensorFlow.js 用于通过利用 js 和应用程序编程接口(API)方法完全在浏览器中表征、训练和运行 AI 模型。如果您是一名 JS web 开发人员，并且是 ML 的新手，TensorFlow.js 是开始学习和开发在浏览器中集成智能的应用程序的绝佳方式。然而，如果你是一个 ML 设计者，又是 JS 新手，这本书里的材料会让你快速入门 TensorFlow.js 资源将如何帮助你开发智能应用。

使用 TensorFlow.js 开发应用程序时，您可能更喜欢以下方法之一:

*   您可以导入一个预训练模型进行推导(推理)。如果您有一个 TensorFlow 或 Keras 现有模型，并且该模型是在离线模式下准备的，则可以切换到 TensorFlow.js 并将其加载到浏览器中进行推理。

*   对于快速开发的应用程序，迁移学习方法可能是合适的。这种方法允许您使用 TensorFlow.js 通过 js 和 API 层完全在浏览器中表征、训练和运行模型。如果您熟悉 Keras，那么应该熟悉 API 的各个层，以便转换成新的模型。

*   Web 开发人员可以使用 TensorFlow.js 在使用 js 特性的浏览器中描述、训练和执行模型。

TensorFlow.js 是一个用于 AI 的 js 库系统，取代了 deeplearn.js，后者目前称为 TensorFlow.js Core。TensorFlow.js 还整合了 Layers API，这是一个更高级别的库，用于构建利用核心的 AI 模型(例如，用于移植 TensorFlow 和 Keras 模型的设备)。图 [4-1](#Fig1) 显示了 TensorFlow.js 的概况。

![../images/503949_1_En_4_Chapter/503949_1_En_4_Fig1_HTML.jpg](../images/503949_1_En_4_Chapter/503949_1_En_4_Fig1_HTML.jpg)

图 4-1

TensorFlow.js 概述

您可以在浏览器中合法地创建/构建模型。此外，您还可以从 Python 导入现有的先前准备好的模型，并对它们进行重新训练。如果您已经在 JS stack 下使用 SQL (NoSQL)和 JavaScript Object Notation (JSON)，您应该考虑的一个用例是利用 TensorFlow.js 通过浏览器构建模型。TensorFlow.js 包含 Keras API，这是一个用于构建 AI/ML 学习模型的简单软件工具。它同样包含一个低级 API，以前称为 deeplearn.js，可用于直接基于变量的数学和编程分离。Ops API 支持急切执行。在一切的基础上，TensorFlow.js 由 WebGL 提供支持，web GL 是一个 JS API，用于在任何互联网浏览器中提供 2D 和 3D 插图，而无需插件模块。

Note

TensorFlow eager execution 是一个命令式编程环境，可以立即计算操作，而无需构建图形。相反，操作返回具体的值，而不是构造一个计算图来稍后运行。这使得 TensorFlow 和调试模型很容易上手。TF CPU(中央处理单元)、TF GPU(图形处理单元)和 TF TPU(张量处理单元)是分布策略，其中模型可以在各自的设备上执行。

如果神经网络学习过程的信息有限，Tensorflow 之类的工具在计算上是高效的，可以更好地实现。假设需要处理大型数据集，那么就非常需要 NVIDIA GPU/Google TPUs 或现场可编程门阵列(FPGAs)等计算统一设备架构(CUDA)系统。基本上，Tensorflow 工具是基于 JavaScript (JS)编程执行的。它将通过比 CUDA 系统更好的 WebGL API 支持 GPU 进行高效的数据处理。

TensorFlow.js 是一个用于在 js 中创建和准备 AI 模型并将其发送到程序或 Node.js 上的库。您可以利用现有模型，转换 Python TensorFlow 模型，使用 move 计算如何使用您的信息重新训练现有模型，以及无需任何准备即可创建模型。TensorFlow.js Node.js 条件支持利用 Python/C TensorFlow 的引入作品作为后端，这可以利用机器的可访问设备提高速度，例如 CUDA。Node.js 也有一个基于 JS 的后端。但是，它的容量是有限的。TensorFlow.js 有几个具有各种属性的 back 闭包。WebGL 后端提供 GPU 支持，利用 WebGL 表面提供容量，利用 WebGL 着色器执行，它比直接 CPU 后端快 100 倍。WebGL 不需要 CUDA，所以它可以利用任何可用的 GPU。

该程序的 WebAssembly (WASM) TensorFlow.js 后端利用 XNNPACK 库来升级神经组织管理员的 CPU 执行。WASM 后端通常比 JS CPU 后端快很多(10 到 30 倍)，但是它通常比 WebGL 后端慢(除了小型模型)。您的里程数可能会有所不同，因此请在您的设备上测试您的型号的 WASM 和 WebGL 后盖。

示例:TensorFlow.js 的基本用法，考虑一个工资和经验属性关系的线性回归问题，如图 [4-2](#Fig2) 。

![../images/503949_1_En_4_Chapter/503949_1_En_4_Fig2_HTML.jpg](../images/503949_1_En_4_Chapter/503949_1_En_4_Fig2_HTML.jpg)

图 4-2

线性回归问题(工作年限与工资)

即使我们没有确切的数据，我们也可以从图 [4-2](#Fig2) 中推断出特定 x 值的 y 值。在 ML 中，我们可以基于输入数据训练一个模型，我们在 JS 特性的帮助下在浏览器中这样做。图 [4-3](#Fig3) 显示了趋势线以及 x 和 y 的关系

![../images/503949_1_En_4_Chapter/503949_1_En_4_Fig3_HTML.jpg](../images/503949_1_En_4_Chapter/503949_1_En_4_Fig3_HTML.jpg)

图 4-3

x 和 y 之间的关系(经验年数与工资)

清单 [4-1a](#PC1) 和 [4-1b](#PC2) 使用 TensorFlow.js 提供了相应的代码来说明前面的回归问题。主文件包括 TensorFlow.js 和对相应脚本文件的调用。

```py
async function learnLinear() {
      const model= tf.sequential();
      model.add(tf.layers.dense({units: 1,inputShape: [1]}));
      model.compile({
      loss: 'meanSquaredError',
      optimizer: 'sgd'
      });
      const

Listing 4-1bTF_JS_1.js

```

```py
<html>
<head>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@2.0.0/dist/tf.min.js">
</script>
</head>
<body>
<script src="TF_JS_1.js"></script>
      <div id="Predicted_Y_Value"></div>
</body>
</html>

Listing 4-1aTF_JS_1.html

```

![../images/503949_1_En_4_Chapter/503949_1_En_4_Figa_HTML.jpg](../images/503949_1_En_4_Chapter/503949_1_En_4_Figa_HTML.jpg)

```py
      await model.fit(xs,ys,{epochs: 400});
      document.getElementById('Predicted_Y_Value').innerText=model.predict(tf.tensor2d([11],[1,1]));
      }
learnLinear();

```

图 [4-4](#Fig4) 是回归表达式的截图(输出)。

![../images/503949_1_En_4_Chapter/503949_1_En_4_Fig4_HTML.jpg](../images/503949_1_En_4_Chapter/503949_1_En_4_Fig4_HTML.jpg)

图 4-4

与回归问题相关的源代码和相应输出的屏幕截图

### 将平面文件数据更改为 TensorFlow.js 格式

考虑 iris 数据集，它由与各种类型的花相关的 15 个样本(行)的数据项组成。虹膜数据集为 JSON 格式，如图 [4-5](#Fig5) 所示。为了将数据(即平面`file(Array`)转换为 TensorFlow.js 格式，`tf.tensor2D()`函数有助于创建 TensorFlow.js 可以理解的数据。`setup()`函数中的`loadJSON()`函数会将 iris.json 数据读入浏览器应用程序的模型中。浏览器图形用户界面(GUI)可以被定制为与用户交互输入，例如时期和其他参数值。

![../images/503949_1_En_4_Chapter/503949_1_En_4_Fig5_HTML.jpg](../images/503949_1_En_4_Chapter/503949_1_En_4_Fig5_HTML.jpg)

图 4-5

JSON 格式的 Iris 数据集

基本上，JSON 文件包含 iris flowers 的各种实例的属性值对。清单 [4-2a](#PC4) 是调用相应脚本文件的主文件，该脚本文件由清单 [4-2b](#PC5) 中给出的操作功能组成。

脚本文件中的函数`setup()`负责设置用户交互操作的画布窗口大小，加载 JSON 数据文件进行处理，提供用户交互按钮启动模型。

通过函数`loaddata()`将 JSON 数据文件内容加载到用户定义的临时变量中。保存在用户定义变量中的临时数据通过函数`convertToTensor()`转换成张量数据结构。

在神经网络学习过程完成后(即在执行`trainModel()`和`nn_model()`函数后)，模型数据被存储在张量数据结构中。该模型利用张量中存在的相应数据进行学习，这些数据由神经网络配置在`trainModel()`和`nn_model()`函数的帮助下执行。

**注意**可以从 [`https://www.kaggle.com/rtatman/iris-dataset-json-versio`](https://www.kaggle.com/rtatman/iris-dataset-json-versio) 下载 iris.json 数据集。

```py
let input, button
let IRIS_NUM_CLASSES =3
let nn_model;
let train_x;
let train_y;
let epoch_val;
function setup()
{
  createCanvas(710, 400);
  // Loading Data
  loadJSON('iris.json',loadData)
  // GUI Form Elements

  fill(0);
  textSize(30)
  text('Train Model',10,50)
  textSize(18)
  text('Train Epochs:',10,90)
  input = createInput();
  input.position(140, 80);
  button = createButton('Train Model From Scratch');
  button.position(20,110, 200);
  let col = color(255,127,80)
  button.style('background-color', col);
  button.size(200,40)
  button.mousePressed(greet);
 }
//The functions loaddata() and converttoTensor()to //convert the data into tensorflow objects(tensor2D() //objects):

function loadData(data)
{
  const values = data.map(item => ({
    a: item.sepalLength,
    b: item.sepalWidth,
    c: item.petalLength,
    d: item.petalWidth,
    label: item.species
  }));

  const dataset = values.filter(item => (

    item.a != null && item.b != null && item.c != null && item.d != null && item.label != null
  ));

  const {inputs, labels} = convertToTensor(dataset);
  train_x = inputs
  train_y = labels

  console.log(train_x.shape[0])
}

function convertToTensor(dataset)
{
  return tf.tidy(() => {
    tf.util.shuffle(dataset);
    const inputs = dataset.map(item => [item.a, item.b, item.c, item.d])
    const labels=[];
    for(i=0;i<dataset.length;i++)
    {
      if(dataset[i].label == 'setosa')
        labels.push(0)
      else if(dataset[i].label == 'versicolor')
        labels.push(1)
      else if(dataset[i].label == 'virginica')
        labels.push(2)
    }
    const inputTensor = tf.tensor2d(inputs, [inputs.length, 4]);
    const labelTensor = tf.oneHot(tf.tensor1d(labels).toInt(), IRIS_NUM_CLASSES);
    const inputMax = inputTensor.max();
    const inputMin = inputTensor.min();
    const normalizedInputs = inputTensor.sub(inputMin).div(inputMax.sub(inputMin));
    return {
      inputs: normalizedInputs,
      labels: labelTensor,
// Return the min/max bounds so we can use them //later.
      inputMax,
      inputMin,
   }
 });
}

//Function iris_nn_model() to invoke the //createmodel()and train the neural network model

function iris_nn_model()
{
      epoch_val = int(input.value())

      if(epoch_val>0)
      {
            nn_model = createModel()
            tfvis.show.modelSummary({name: 'Model Summary'}, nn_model);

            if(train_x.shape[0] >0 && train_y.shape[0] >0 )
                  trainModel(nn_model)
      }
}
// Function createModel() tf.sequential(),adding //input layers through tf.layers.dense and //trainModel() with the model.fit() methods
function createModel()
{
  const model = tf.sequential();
  model.add(tf.layers.dense({inputShape: [4], units: 50, useBias: true, activation:'relu'}));
  model.add(tf.layers.dense({units: 20, activation: 'relu'}));
  //model.add(tf.layers.dense({units: 10, activation: 'relu'}));
  model.add(tf.layers.dense({units: 3, activation: 'softmax'}));
  return model;
}

async function trainModel(model)
{
    model.compile({

      optimizer: tf.train.adam(),
      loss: tf.losses.softmaxCrossEntropy,
      metrics: ['accuracy'],
    });
   const batchSize = 32;
    const epochs = epoch_val;
    const validationSplit =0.3;
    return await model.fit(train_x, train_y, {
      batchSize,
      epochs,
      validationSplit,
      shuffle: true,
      callbacks: tfvis.show.fitCallbacks(
        { name: 'Training Performance' },
        ['loss', 'val_loss','acc','val_acc'],
        { height: 200, callbacks: ['onEpochEnd'] })
    });
}

Listing 4-2bscript10.js

```

```py
<!DOCTYPE html>
<html>
<head>
      <title>Iris Dataset Classification</title>
      <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.0/dist/tf.min.js"></script>
      <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-vis@1.0.2/dist/tfjs-vis.umd.min.js"></script>
      <script src="https://cdn.jsdelivr.net/npm/p5@1.1.9/lib/p5.js"></script>
      <script src="script10.js"></script>
</head>
<body>
</body>
</html>

Listing 4-2aTensorFlow.js. index.html function setup() to Load the .json Data

```

图 [4-6](#Fig6) 显示了与使用 TensorFlow.js 可视化的训练过程和历元精度相关的输出。

![../images/503949_1_En_4_Chapter/503949_1_En_4_Fig6_HTML.jpg](../images/503949_1_En_4_Chapter/503949_1_En_4_Fig6_HTML.jpg)

图 4-6

从 JSON 文件中读取的输入的屏幕截图(输出)

## 利用 TensorFlow.js 在浏览器中建立人工神经网络模型

1.  加载或准备数据。

2.  设置你的神经网络结构。

3.  向神经网络添加配置信息。

4.  训练你的神经组织。

5.  利用准备好的模型下订单。

6.  用获得的结果完成某事(分类/预测)。

下一节简要描述一个简单的神经网络，然后介绍通过 TensorFlow.js 编程原则开发 ANN 的复杂性。

### 平凡神经网络

考虑由函数 y(输出)= x '(x 的逆)的一个隐藏层组成的神经网络组织，其中隐藏层有四个神经元，输入层有两个神经元，输出层有一个神经元，其中 x 是输入的集合(见图 [4-7](#Fig7) )。

![../images/503949_1_En_4_Chapter/503949_1_En_4_Fig7_HTML.png](../images/503949_1_En_4_Chapter/503949_1_En_4_Fig7_HTML.png)

图 4-7

人工神经网络的基本结构

构建神经结构通常是通过堆叠层来完成的。TensorFlow.js 提供了一个 API 来堆叠各种类型的层。配置时要考虑的各种参数的数量超出了您的预期。一个原因是这个模型包含了权重和偏差值。暂时可以通过鼓励你改进模型的参数来考虑从一层到另一层的倾向。在整个训练过程中，错误不断减少；这意味着我们的模型正在被学习。

### 示例 TensorFlow.js 中的神经网络模型

清单 [4-3a](#PC6) 在主索引文件中，清单 [4-3b](#PC7) 是脚本文件，其中包含用于保存神经网络模型的张量、设置和配置中的数据的数据结构，以实现反向操作的功能。

```py
//Step 1:load data, xs=Input and ys=Output
const xs=tf.tensor2d([[0,0],[0.5,0.5],[1,1]]);
const ys=tf.tensor2d([[1],[0.5],[0]]);

//Step 2: Set your neural network structure
const model =tf.sequential();

const confighidden={
      inputShape:[2],
      units:4,
      activation:'sigmoid'
}

const configoutput={

      units:1,
      activation:'sigmoid'
}

const hidden =tf.layers.dense(confighidden);
const output=tf.layers.dense(configoutput);

model.add(hidden);
model.add(output);

//Step 3: add configuration information
const sgdopt=tf.train.sgd(0.1);

const config={
      optimizer:sgdopt,
      loss:'meanSquaredError'
}
//Step 4: Train your neural organization
model.compile(config);

async function train()
{
      for(let i=0;i<5000;i++) {
const response=await model.fit(xs,ys);
console.log(response.history.loss[0]);
} }

Step 5 and 6: Utilize the results (prediction)
train().then(() => {
      let outputs=model.predict(xs);
      outputs.print();
      console.log('training complete');
});

Listing 4-3bScript.js (Script File)

```

```py
<!DOCTYPE html>
<html>
<head>
  <title>A simple Neural Network model </title>
  <!-- Import TensorFlow.js -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.0/dist/tf.min.js"></script>
   <!-- Import the main script file -->
  <script src="script.js"></script>
</head>
<body>
<h2> Neural Network to demonstrate y=x' (Y is equal to inverse of X)
</body>
</html>

Listing 4-3aDemo1.html (Main File)

```

图 [4-8](#Fig8) 显示了上述代码的浏览器控制台输出。

![../images/503949_1_En_4_Chapter/503949_1_En_4_Fig8_HTML.jpg](../images/503949_1_En_4_Chapter/503949_1_En_4_Fig8_HTML.jpg)

图 4-8

使用 TensorFlow.js 的 y=x'through ANN 的屏幕截图(输出)

### 示例 2:实现“非与”(NAND)布尔运算的简单人工神经网络

Not 和(NAND)布尔运算规则很简单:给定两个布尔值(真/假)，如果只有两个都为真，则返回假；否则，返回 true。通过 TensorFlow.js 脚本库应用顺序模型，可以演示基于输入值实现此操作的神经网络。

图 [4-9](#Fig9) 显示了基本的逻辑 NAND 操作，其对应的功能如真值表所示。

![../images/503949_1_En_4_Chapter/503949_1_En_4_Fig9_HTML.jpg](../images/503949_1_En_4_Chapter/503949_1_En_4_Fig9_HTML.jpg)

图 4-9

基本逻辑与非门及其真值表

NAND 布尔运算实现的训练数据使用两个数组，一个用于输入(X0 和 X1)，另一个用于输出(Y)。这两个数组是可以在神经网络结构中使用的张量:

```py
//Step 1: Load or prepare the data
const xs=tf.tensor2d([[0,0],[0,1],[1,0],[1,1]],[4,2]);
const ys=tf.oneHot(tf.tensor1d([1,1,1,0]).toInt(),2);

```

因此，输入数组的形状是[4，2]，因为有一个由 4 个值组成的数组，每个数组有 2 个值。最好用适当的 TensorFlow.js 函数提到数组(输入和输出)。

一旦定义了输入和输出，神经系统就可以以层的形式构造。随着数据在一个方向上从输入层向前移动到输出层，我们可以考虑神经系统结构的一个*序列模型*，如前一个示例中所给出的。由 X0 和 X1 组成的输入被传递到下一层(隐藏层)，该层由 5 个神经元组成。然后，它们被传递到由 2 个神经元组成的输出层，这向我们显示了相关输出(真或假)的确定性百分比(1 到 0 之间的值):

```py
//Step 2: Set up the NN structure
const model =tf.sequential();

const confighidden={
      inputShape:[2],
      units:5,
      activation:'sigmoid'
}

const configoutput={
      units:2,
      activation:'sigmoid'
}

const hidden =tf.layers.dense(confighidden);
const output=tf.layers.dense(configoutput);

model.add(hidden);
model.add(output);

```

可以用优化器函数`Adam`以及损失函数`categoricalCrossentropy`来训练神经网络模型。这将使模型能够通过将给定的输入值与相应的输出值相关联来进行训练:

```py
//Step 3: Add configuration parameters to the NN //structure
const admopt=tf.train.adam(0.1);

const config={
      optimizer:admopt,
      loss:'categoricalCrossentropy' }
//Step 4: Train the NN organization
model.compile(config);

```

训练由模型对象的`.fit()`函数执行。这个方法接收 XS 和 YS 的训练数据和配置对象。配置包括纪元。当模型开始训练时,`.fit()`方法返回一个承诺函数。通过调用对训练方法的异步调用来检索输出数据:

```py
async function train()
{
      for(let i=0;i<200;i++) {
const response=await model.fit(xs,ys);
console.log(response.history.loss[0]);
} }
//Steps 5 and 6: Collect the results
train().then(() => {
      let outputs=model.predict(xs);
      outputs.print();
      console.log('training complete');
});

The output:
Tensor
    [[0, 1],
     [0.0004133, 0.9995866],
     [0.0004822 , 0.9995178],
     [0.9984748, 0.0015252]]

```

在这个例子中，对于[0，0]、[0，1]和[1，0]的输入，预测的输出是[0，1]、[0.0004153，0.9995866]和[0.0004822，0.9995178]意味着 0.0%的假确定性和 99.9%的真确定性；而对于输入[1，1]，输出为[0.9984748，0.0015252 表示 99%为假，0.0%为真。

图 [4-10](#Fig10) 显示了上述代码在浏览器控制台中的输出。

![../images/503949_1_En_4_Chapter/503949_1_En_4_Fig10_HTML.jpg](../images/503949_1_En_4_Chapter/503949_1_En_4_Fig10_HTML.jpg)

图 4-10

使用 TensorFlow.js 通过 ANN 进行 NAND 布尔运算的屏幕截图(输出)

## 基于 postnet 的人体姿态分类

“PoseNet 是一个视觉模型”，可以通过评估身体关键关节的位置来评估照片或视频中个人的姿势。型号术语见图 [4-11](#Fig11) 。

![../images/503949_1_En_4_Chapter/503949_1_En_4_Fig11_HTML.jpg](../images/503949_1_En_4_Chapter/503949_1_En_4_Fig11_HTML.jpg)

图 4-11

与 postnet 模型相关的术语

PoseNet 不会察觉照片/视频中的人是谁。该估计实际上是评估人体关键关节的位置。PoseNet 可用于评估图片/视频中出现的一个人的姿势或许多人的姿势。PoseNet 的估计可以仅区分图片/视频中的单个个体，并且还可以识别图片/视频中的不同人。单人姿势识别器更快更直接，但是只需要一个主体出现在照片中。姿势评估分两个阶段进行:

1.  通过卷积神经系统来处理信息 RGB 图像。

2.  姿态估计被用来解释来自模型输出的关键点位置和关键点确定性分数。

## 设置 posnet 项目

### 步骤 1:在 HTML 程序(主文件)中包含 TensorFlow.js 和 PoseNet 库

```py
<html>
  <body>
    <!-- Load TensorFlow.js -->
    <script src="https://unpkg.com/@tensorflow/tfjs"></script>
    <!-- Load Posenet -->
    <script src="https://unpkg.com/@tensorflow-models/posenet">
    </script>
    <script type="text/javascript">
      posenet.load().then(function(net) {
        // posenet model loaded
      });
    </script>
  </body>
</html>

```

图 [4-12](#Fig12) 显示了主文件中包含的库文件以及浏览器中相应的输出。ml5.js 和 TensorFlow.js 一起给出了 PoseNet 模型。一个内部有预先准备好的卷积神经网络(CNN)的现成模型接受图片作为信息，并产生关键点热图和相应的向量。

![../images/503949_1_En_4_Chapter/503949_1_En_4_Fig12_HTML.jpg](../images/503949_1_En_4_Chapter/503949_1_En_4_Fig12_HTML.jpg)

图 4-12

将库加载到浏览器中后，浏览器及其控制台窗口上呈现的输出文本如下所示

### 步骤 2:使用浏览器摄像头进行单人姿势估计

完整代码有两个文件:Demo_3.html(显示输出的主网页)和 Demo_3script.js(捕捉用户视频的 js 代码)。Demo_3.html 是显示带有关键点的输出的主页。因此，库被添加到该文件中:

```py
<html>
<head>
<title> Demo on Posenet Model </title>
<script src="p5.min.js"></script>
<script src="p5.dom.min.js"></script>
<script src="ml5.min.js" type="text/javascript"></script>
</head>
<body>
<h2> Demo of PoseNet ML model in the browser</h2>
<p id="uservideo"> Loading Model....</p>
<script src="Demo_3script.js"> </script>
</body>
</html>

```

Demo3_script.js 由三个方法(函数)组成:

![../images/503949_1_En_4_Chapter/503949_1_En_4_Fig13_HTML.jpg](../images/503949_1_En_4_Chapter/503949_1_En_4_Fig13_HTML.jpg)

图 4-13

使用浏览器摄像头的单人姿势估计

1.  `function setup()`: The initial setup to capture video using browser webcam and set the user video at the said location by calling the PoseNet model. This first function is executed and runs exactly once.

    ```py
    function setup() {
          createCanvas(640,480);
          webcam_output=createCapture(VIDEO);
          webcam_output.size=(width,height);
          myposenet=ml5.poseNet(webcam_output,function(){
          select('#uservideo').html('User Video Loaded')});
          myposenet.on('pose',function(results) {
          poses=results; });
          webcam_output.hide();
    }

    ```

    p5.js 库的`createCanvas(width, height)`是在浏览器中创建一个窗口(框)来显示输出。用`width:640px`和`height:480px`设置窗口(画布)的大小。

    `createCapture(VIDEO)`用于捕获网络摄像头的 feed 视频，并返回一个 p5 对象，该对象存储在自定义变量`webcam_output`中。网络摄像头视频的高度和宽度也与画布相同。

    `poseNet()`方法创建一个新的 PoseNet 模型，作为来自`webcam_output`的输入，并加载到 main 中。显示用户视频的 html 页面。

    `poseNet.on()`方法是一个事件监听器。每当用户位置/视频发生变化时，就会向 myposenet 模型提供新的图像。函数 poseNet 依次调用`function(results)`，其中模型给出关键点及其相应的分数。结果存储在名为`poses`的数组中。

    功能`webcam_output.hide()`，隐藏实际的网络摄像头输出，浏览器上只显示关键点输出的画布。

2.  `function draw ()` : The function is called and repeats forever until the browser is closed. This method in turn calls to identify the keypoints:

    ```py
    function draw() {
          image(webcam_output,0,0,width,height);
          displayKeypoints();
    }

    ```

    `draw ()`函数持续运行以在画布中显示图像。它有五个参数，分别是`webcam_output`(要显示的视频)、左上角相对于画布的 xy 坐标以及绘制视频的`width,height`。该函数调用`displayKeypoints()`将识别的关键点显示为点(椭圆)。

3.  `function displayKeypoints()` : This method displays the recognized keypoints from the array `poses`. The identified points are displayed in the form of circles to show that there is a keypoint:

    ```py
    function displayKeypoints() {
     for(let i=0;i<poses.length;i++) {
          let pose=poses[i].pose;
          for(let j=0;j<pose.keypoints.length;j++) {
          let point=pose.keypoints[j];
          fill(0,0,255);
          noStroke();
    ellipse(point.position.x,point.position.y,10,10);
                }
          }
    }

    ```

    图 [4-13](#Fig13) 显示了相应的输出。

使用图片进行单人姿势估计:`function setup()`包含一个`createImg`方法，用于将图像(图片)从本地硬盘加载到浏览器上，以识别图像上的关键点。图 [4-14](#Fig14) 显示了相应的输出。

![../images/503949_1_En_4_Chapter/503949_1_En_4_Fig14_HTML.jpg](../images/503949_1_En_4_Chapter/503949_1_En_4_Fig14_HTML.jpg)

图 4-14

显示图片中的关键点

函数中的以下指令集将在 Demo_4script.js 中编写。主文件 Demo_4.html 保持不变:

```py
function setup() {
  createCanvas(640, 360);
  img= createImg('pics/pexels-derick-santos-2773934.jpg');
  img.size(width, height);
  myposenet = ml5.poseNet(img, function(){
  select('#userpic').html('Image Loaded');
  myposenet.singlePose(img);});
  myposenet.on('pose', function (results) {
       poses = results; });
}

```

`function draw()`包含基于`poses`数组显示关键点以及显示骨架(与关键点连接相关的草图)的方法:

```py
function draw() {
    if (poses.length > 0) {
        image(img, 0, 0, width, height);
         displayKeypoints(poses);
         displaySkeleton(poses);
     }
}

```

`displayKeypoints`的逻辑与前面例子中讨论的相同。功能`displaySkeleton()`是在当前图像上绘制*线条*。`draw()`在一个无限循环中这样做，因此向用户显示一个连续的输出。

## postnet 模型置信度值

draw 函数执行并循环遍历作为主体一部分的每个关键点，关键点数组`poses`包含以下信息:

*   `"part"`:识别出的身体部位的名称。

*   `"position.x"`和`"position.y"`:图像中一点的值。

*   `"score"`:置信度值表示检测的准确度。

图 [4-15](#Fig15) 显示了浏览器控制台上的输出。

![../images/503949_1_En_4_Chapter/503949_1_En_4_Fig15_HTML.jpg](../images/503949_1_En_4_Chapter/503949_1_En_4_Fig15_HTML.jpg)

图 4-15

从浏览器控制台中的姿势看到的置信度值

如果检测精度大于某个值，我们可以画一个`point`(例如`0.2 or 0.3, or 0.7 and above when you are concerned about certain points).`图 [4-16](#Fig16) 显示了与所画骨架相关的分数。

![../images/503949_1_En_4_Chapter/503949_1_En_4_Fig16_HTML.jpg](../images/503949_1_En_4_Chapter/503949_1_En_4_Fig16_HTML.jpg)

图 4-16

在浏览器控制台的`poses`对象中看到的特定阈值的分数

Note

当使用与 PoseNet 模型输出相关的 JSON 格式存储数据时，应在 Demo_4script.js 中编写步骤。主文件 Demo_4.html 保持不变

要以 JSON 格式将关键点捕获到一个单独的文件中，可以使用 p5 库函数，如下所示:

第一步。声明一个全局变量:

```py
let writer;

```

第二步。在 setup 函数中，用`createWriter`和文件名初始化 writer 变量，以 JSON 格式存储数据:

```py
// writer object is initialized with createWriter function
writer=createWriter('data_keypoints.json');

```

第三步。在 displayKeypoints 方法中，通过使用`writer`对象调用函数`print`:

```py
writer.print("keypoint: "+keypoint.part+" x:"+keypoint.position.x+" y:"+keypoint.position.y);

```

第四步。为将要发生的事件(如`mouseclick`)定义一个函数，这样该事件将触发`print`方法来存储连续`draw()`方法的值:

```py
function mouseClicked() {
        writer.close();
      }

```

输出存储在一个. json 文件中，如图 [4-17](#Fig17) 所示。

![../images/503949_1_En_4_Chapter/503949_1_En_4_Fig17_HTML.jpg](../images/503949_1_En_4_Chapter/503949_1_En_4_Fig17_HTML.jpg)

图 4-17

关键点数据在。json 文件

## 摘要

本章介绍了人工神经网络的重要性及其在人体姿态估计的最大似然建模中的策略。通过本章的理论和实例，你学习了 ANN 的基础知识，以及如何通过 TensorFlow.js 编程在浏览器中实现。这样的理解一定会帮助你在浏览器中实现各种 ML 模型比如 PoseNet。

本章中介绍的 PoseNet 模型是一种机器学习模型，可以在浏览器上实时估计人体姿势关键点。本章将介绍相应的实施细节。

这些信息将作为在浏览器上执行复杂数据分析的基础(您将在以下章节中学习)。

## 参考

*   [T2`https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5`](https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5)

*   [T2`https://js.tensorflow.org/api/latest/`](https://js.tensorflow.org/api/latest/)

*   [T2`https://github.com/topics/neural-network`](https://github.com/topics/neural-network)

*   [T2`https://github.com/tensorflow/tfjs-models/tree/master/posenet`](https://github.com/tensorflow/tfjs-models/tree/master/posenet)

*   [T2`https://codelabs.developers.google.com/codelabs/neural-tensorflow-js/index.html?index=..%2F..index#0`](https://codelabs.developers.google.com/codelabs/neural-tensorflow-js/index.html%253Findex%253D..%252F..index%25230)

*   [T2`https://rubikscode.net/2019/03/25/image-classification-with-tensorflow-js/`](https://rubikscode.net/2019/03/25/image-classification-with-tensorflow-js/)

*   [T2`https://p5js.org/reference/#/p5/createWriter`](https://p5js.org/reference/%2523/p5/createWriter)

*   [T2`https://www.smashingmagazine.com/2019/09/machine-learning-front-end-developers-tensorflowjs/`](https://www.smashingmagazine.com/2019/09/machine-learning-front-end-developers-tensorflowjs/)

*   [T2`https://www.pexels.com/search/running/`](https://www.pexels.com/search/running/)

*   [T2`https://www.pexels.com/search/jogging/`](https://www.pexels.com/search/jogging/)

*   [T2`https://frl.nyu.edu/pose-estimation-in-javascript-with-tensorflow-js/`](https://frl.nyu.edu/pose-estimation-in-javascript-with-tensorflow-js/)

*   [T2`https://www.irenealvarado.com/tensorflowjs-posenet`](https://www.irenealvarado.com/tensorflowjs-posenet)

*   [T2`https://learn.ml5js.org/docs/#/reference/neural-network`](https://learn.ml5js.org/docs/%2523/reference/neural-network)

*   [T2`https://becominghuman.ai/machine-learning-in-the-browser-using-tensorflow-js-3e453ef2c68c`](https://becominghuman.ai/machine-learning-in-the-browser-using-tensorflow-js-3e453ef2c68c)